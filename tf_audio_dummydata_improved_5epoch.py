# -*- coding: utf-8 -*-
"""TF_Audio_DummyData_Improved_5epoch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w8MmGvbO1p3LoU0EywpbcjOZUk7Fg_-x

#  TensorFlow Audio

- Two models: **ResNet50Audio** (ImageNet backbone) & **CNN14Lite** (compact convnet)
- Config-driven loader (`get_config`, `load_model_from_config`)
- Dummy spectrogram dataset (no files needed)
- **5 training epochs**, history plots, inference demo
- Exports `.weights.h5` and a Keras 3 **SavedModel** via `model.export(...)`
- Rich inline comments so itâ€™s easy to present / hand off
"""

# =============================
# Q0 â€” Environment & Reproducibility
# =============================
import os, random, datetime
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Reproducibility: make results stable across runs (to the extent possible).
SEED = 1337
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)

# (Optional) Make CPU behavior more predictable on shared runtimes.
tf.config.threading.set_intra_op_parallelism_threads(2)
tf.config.threading.set_inter_op_parallelism_threads(2)

print("TensorFlow version:", tf.__version__)

"""##  Models (ResNet50Audio & CNN14Lite)"""

def ResNet50Audio(input_shape, num_classes, pretrained=True, pooling="avg", train_base=False, final_activation="softmax"):
    """Spectrogram classifier on top of ImageNet-pretrained ResNet50.

    - Accepts (H,W,1) spectrograms; we expand to 3 channels to match ImageNet backbones.
    - Applies simple per-sample normalization.
    - Freezes the backbone by default (train_base=False) for stability on small data.
    """
    inputs = keras.Input(shape=tuple(input_shape), name="spec")

    # Expand gray channel to 3 channels explicitly (more robust than tf.repeat in Lambda).
    x = inputs
    if input_shape[-1] == 1:
        x = layers.Concatenate(axis=-1, name="to_rgb")([x, x, x])

    # Simple per-sample normalization across time-frequency axes.
    x = layers.Lambda(lambda t: (t - tf.reduce_mean(t, axis=[1,2], keepdims=True)) /
                                (tf.math.reduce_std(t, axis=[1,2], keepdims=True) + 1e-6),
                      name="spec_norm")(x)

    # ResNet50 backbone (no top). Set weights='imagenet' for real use; using None avoids internet download.
    base = keras.applications.ResNet50(
        include_top=False,
        weights=None if not pretrained else "imagenet",
        input_shape=(input_shape[0], input_shape[1], 3),
        pooling=pooling
    )
    base.trainable = train_base  # freeze backbone by default
    x = base(x)
    if pooling is None:
        x = layers.GlobalAveragePooling2D(name="gap")(x)

    x = layers.Dropout(0.3, name="dropout")(x)
    outputs = layers.Dense(num_classes, activation=final_activation, name="logits")(x)
    return keras.Model(inputs, outputs, name="ResNet50Audio")


def _conv_block(x, filters, kernel=(3,3), pool=True, name_prefix="blk"):
    """Conv2D -> BN -> ReLU -> (optional) MaxPool convenience block."""
    x = layers.Conv2D(filters, kernel, padding="same", use_bias=False, name=f"{name_prefix}_conv")(x)
    x = layers.BatchNormalization(name=f"{name_prefix}_bn")(x)
    x = layers.ReLU(name=f"{name_prefix}_relu")(x)
    if pool:
        x = layers.MaxPool2D(pool_size=(2,2), name=f"{name_prefix}_pool")(x)
    return x


def CNN14Lite(input_shape, num_classes, final_activation="softmax"):
    """Compact CNN inspired by PANNs CNN14 (suitable for quick demos)."""
    inputs = keras.Input(shape=tuple(input_shape), name="spec")
    x = layers.Lambda(lambda t: (t - tf.reduce_mean(t, axis=[1,2], keepdims=True)) /
                                (tf.math.reduce_std(t, axis=[1,2], keepdims=True) + 1e-6),
                      name="spec_norm")(inputs)

    x = _conv_block(x, 64,  name_prefix="b1")
    x = _conv_block(x, 128, name_prefix="b2")
    x = _conv_block(x, 256, name_prefix="b3")
    x = _conv_block(x, 512, name_prefix="b4")
    x = layers.Conv2D(512, (3,3), padding="same", use_bias=False, name="b5_conv")(x)
    x = layers.BatchNormalization(name="b5_bn")(x)
    x = layers.ReLU(name="b5_relu")(x)
    x = layers.GlobalAveragePooling2D(name="gap")(x)
    x = layers.Dropout(0.4, name="dropout")(x)
    outputs = layers.Dense(num_classes, activation=final_activation, name="logits")(x)
    return keras.Model(inputs, outputs, name="CNN14Lite")

"""##  Model Config Loader"""

DEFAULT_CONFIG = {
    "model_name": "ResNet50Audio",   # or "CNN14Lite"
    "num_classes": 3,
    "input_shape": [224, 224, 1],
    "final_activation": "softmax",   # 'softmax' (multiclass) or 'sigmoid' (multilabel)
    "pretrained": False,             # set True when you want ImageNet weights (requires internet)
    "train_base": False,
}

def get_config(overrides=None):
    cfg = DEFAULT_CONFIG.copy()
    if overrides:
        cfg.update(overrides)
    return cfg

def load_model_from_config(cfg):
    name = cfg["model_name"]
    num_classes = int(max(1, cfg["num_classes"]))  # guard >=1
    input_shape = tuple(cfg["input_shape"])
    final_activation = cfg.get("final_activation", "softmax")

    if name == "ResNet50Audio":
        return ResNet50Audio(
            input_shape=input_shape,
            num_classes=num_classes,
            pretrained=bool(cfg.get("pretrained", False)),
            train_base=bool(cfg.get("train_base", False)),
            final_activation=final_activation,
        )
    elif name == "CNN14Lite":
        return CNN14Lite(
            input_shape=input_shape,
            num_classes=num_classes,
            final_activation=final_activation,
        )
    else:
        raise ValueError(f"Unknown model_name: {name}")

"""## Dummy Dataset"""

def make_dummy_dataset(num_samples=256, num_classes=3, batch_size=8, multilabel=False):
    """Generate random 'spectrograms' and labels.

    - X shape: (N, 224, 224, 1) to resemble grayscale spectrograms.
    - y: sparse integer labels if `multilabel=False`; otherwise multi-hot vectors.
    """
    X = tf.random.normal([num_samples, 224, 224, 1], seed=SEED)
    if multilabel:
        y = tf.cast(tf.random.uniform([num_samples, num_classes], minval=0, maxval=2, dtype=tf.int32, seed=SEED), tf.float32)
    else:
        y = tf.random.uniform([num_samples], minval=0, maxval=num_classes, dtype=tf.int32, seed=SEED)
    return tf.data.Dataset.from_tensor_slices((X, y)).shuffle(num_samples, seed=SEED).batch(batch_size).prefetch(tf.data.AUTOTUNE)

# quick sanity print
tmp = make_dummy_dataset(8, 3, 4)
for xb, yb in tmp.take(1):
    print("Dummy batch shapes:", xb.shape, yb.shape)

"""## Train for 5 Epochs + Export"""

# ===== Hyperparameters =====
CFG = get_config({
    "model_name": "ResNet50Audio",   # change to "CNN14Lite" to switch models
    "num_classes": 3,
    "input_shape": [224, 224, 1],
    "pretrained": False,             # keep False to avoid downloading ImageNet weights
    "train_base": False,
    "final_activation": "softmax",
})

EPOCHS      = 5           # ðŸ‘ˆ requested: 5 epochs
BATCH_SIZE  = 8
LR          = 1e-4
MULTILABEL  = False       # set True only if you generate multi-hot labels

# ===== Data =====
train_ds = make_dummy_dataset(num_samples=192, num_classes=CFG["num_classes"], batch_size=BATCH_SIZE, multilabel=MULTILABEL)
val_ds   = make_dummy_dataset(num_samples=48,  num_classes=CFG["num_classes"], batch_size=BATCH_SIZE, multilabel=MULTILABEL)

# ===== Model =====
model = load_model_from_config(CFG)
if MULTILABEL or CFG.get("final_activation") == "sigmoid":
    loss = keras.losses.BinaryCrossentropy()
    metrics = [keras.metrics.BinaryAccuracy(name="bin_acc")]
else:
    loss = keras.losses.SparseCategoricalCrossentropy()
    metrics = [keras.metrics.SparseCategoricalAccuracy(name="acc")]

model.compile(optimizer=keras.optimizers.Adam(LR), loss=loss, metrics=metrics)
model.summary()

# ===== Paths =====
CHECKPOINT_DIR = "/content/weights"
os.makedirs(CHECKPOINT_DIR, exist_ok=True)
timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
WEIGHTS_PATH   = os.path.join(CHECKPOINT_DIR, f"{CFG['model_name']}_{timestamp}.weights.h5")
SAVEDMODEL_DIR = os.path.join(CHECKPOINT_DIR, f"{CFG['model_name']}_{timestamp}_SavedModel")

# ===== Callbacks =====
cbs = [
    keras.callbacks.ModelCheckpoint(WEIGHTS_PATH, save_weights_only=True, monitor="val_acc" if not MULTILABEL else "val_bin_acc", mode="max", save_best_only=True, verbose=1),
    keras.callbacks.EarlyStopping(monitor="val_acc" if not MULTILABEL else "val_bin_acc", patience=2, mode="max", restore_best_weights=True),
]

# ===== Train =====
history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=cbs, verbose=1)

# ===== Export =====
model.save_weights(WEIGHTS_PATH)   # lightweight checkpoint for fine-tuning later
model.export(SAVEDMODEL_DIR)       # Keras 3 SavedModel export (TF-serving friendly)
print("Saved weights to:", WEIGHTS_PATH)
print("Exported SavedModel to:", SAVEDMODEL_DIR)

"""##  Plot Training Curves"""

import matplotlib.pyplot as plt

def plot_history(hist, multilabel=False):
    # Accuracy
    plt.figure()
    if multilabel:
        plt.plot(hist.history.get("bin_acc", []), label="train_bin_acc")
        plt.plot(hist.history.get("val_bin_acc", []), label="val_bin_acc")
        plt.title("Binary Accuracy")
        plt.ylabel("bin_acc")
    else:
        plt.plot(hist.history.get("acc", []), label="train_acc")
        plt.plot(hist.history.get("val_acc", []), label="val_acc")
        plt.title("Accuracy")
        plt.ylabel("acc")
    plt.xlabel("epoch")
    plt.legend()
    plt.show()

    # Loss
    plt.figure()
    plt.plot(hist.history.get("loss", []), label="train_loss")
    plt.plot(hist.history.get("val_loss", []), label="val_loss")
    plt.title("Loss")
    plt.xlabel("epoch")
    plt.ylabel("loss")
    plt.legend()
    plt.show()

plot_history(history, multilabel=MULTILABEL)

"""## Inference Demo"""

# Recreate the model and load the best weights, then predict on a dummy batch.
model_inf = load_model_from_config(CFG)
model_inf.load_weights(WEIGHTS_PATH)

X_demo = tf.random.normal([4, 224, 224, 1], seed=SEED)
preds = model_inf.predict(X_demo)
print("Preds shape:", preds.shape)
print("First row probabilities:", preds[0])