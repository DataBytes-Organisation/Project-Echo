{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5340546a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_hub in d:\\anaconda\\lib\\site-packages (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in d:\\anaconda\\lib\\site-packages (from tensorflow_hub) (1.24.3)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in d:\\anaconda\\lib\\site-packages (from tensorflow_hub) (4.23.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab99889f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in d:\\anaconda\\lib\\site-packages (0.25.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a8b042f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "be7c5c79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the YAMNet model\n",
    "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
    "yamnet_model = hub.load(yamnet_model_handle)\n",
    "\n",
    "# Read class name mapping file\n",
    "class_map_path = \"C:/Users/93978/Documents/GitHub/Project-Echo/Extracting Animal and Bird Sounds/yamnet_class_map/yamnet_class_map.csv\" \n",
    "class_names = pd.read_csv(class_map_path, sep=',', header=None).values.squeeze()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e03211cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_audio(file_path):\n",
    "    waveform, sample_rate = sf.read(file_path, dtype=np.float32)\n",
    "    if len(waveform.shape) > 1:\n",
    "        waveform = np.mean(waveform, axis=1)\n",
    "    scores, embeddings, log_mel_spectrogram = yamnet_model(waveform)\n",
    "    return scores.numpy(), class_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8b0c352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load audio file\n",
    "audio = AudioSegment.from_file(\"C:/Users/93978/Documents/GitHub/Project-Echo/Extracting Animal and Bird Sounds/original audio file/9.mp3\")\n",
    "\n",
    "# Set the parameter value according to the specific situation of the audio file\n",
    "min_silence_len = 500  \n",
    "silence_thresh = -30    \n",
    "\n",
    "# Extract non-silent segments\n",
    "non_silent_ranges = detect_nonsilent(\n",
    "    audio, \n",
    "    min_silence_len=min_silence_len, \n",
    "    silence_thresh=silence_thresh\n",
    ")\n",
    "\n",
    "# Create a directory to save the extracted audio segments\n",
    "os.makedirs(\"extracted_segments\", exist_ok=True)\n",
    "\n",
    "# Extract and save audio segments\n",
    "for i, (start, end) in enumerate(non_silent_ranges):\n",
    "    segment = audio[start:end]\n",
    "    segment.export(f\"extracted_segments/segment_{i}.wav\", format=\"wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "44edc180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment 0:\n",
      "  - ['66' '/t/dd00013' 'Children playing']: 0.455\n",
      "  - ['67' '/m/0jbk' 'Animal']: 0.363\n",
      "  - ['68' '/m/068hy' 'Domestic animals, pets']: 0.270\n",
      "Segment 1:\n",
      "  - ['66' '/t/dd00013' 'Children playing']: 0.369\n",
      "  - ['67' '/m/0jbk' 'Animal']: 0.313\n",
      "  - ['68' '/m/068hy' 'Domestic animals, pets']: 0.281\n",
      "Segment 2:\n",
      "  - ['index' 'mid' 'display_name']: 0.135\n",
      "  - ['67' '/m/0jbk' 'Animal']: 0.069\n",
      "  - ['68' '/m/068hy' 'Domestic animals, pets']: 0.064\n",
      "Segment 3:\n",
      "  - ['493' '/m/07s12q4' 'Crunch']: 0.191\n",
      "  - ['497' '/m/0hdsk' 'Chirp tone']: 0.190\n",
      "  - ['474' '/m/07qcx4z' 'Tearing']: 0.102\n",
      "Segment 4:\n",
      "  - ['499' '/m/07pt_g0' 'Pulse']: 0.047\n",
      "  - ['index' 'mid' 'display_name']: 0.046\n",
      "  - ['131' '/m/032n05' 'Whale vocalization']: 0.034\n",
      "Segment 5:\n",
      "  - ['66' '/t/dd00013' 'Children playing']: 0.628\n",
      "  - ['67' '/m/0jbk' 'Animal']: 0.504\n",
      "  - ['68' '/m/068hy' 'Domestic animals, pets']: 0.476\n",
      "Segment 6:\n",
      "  - ['66' '/t/dd00013' 'Children playing']: 0.519\n",
      "  - ['67' '/m/0jbk' 'Animal']: 0.366\n",
      "  - ['68' '/m/068hy' 'Domestic animals, pets']: 0.326\n",
      "Segment 7:\n",
      "  - ['66' '/t/dd00013' 'Children playing']: 0.262\n",
      "  - ['105' '/m/04cvmfc' 'Roar']: 0.205\n",
      "  - ['102' '/m/07qwf61' 'Honk']: 0.200\n",
      "Segment 8:\n",
      "  - ['index' 'mid' 'display_name']: 0.335\n",
      "  - ['66' '/t/dd00013' 'Children playing']: 0.262\n",
      "  - ['68' '/m/068hy' 'Domestic animals, pets']: 0.252\n",
      "Segment 9:\n",
      "  - ['66' '/t/dd00013' 'Children playing']: 0.440\n",
      "  - ['67' '/m/0jbk' 'Animal']: 0.408\n",
      "  - ['68' '/m/068hy' 'Domestic animals, pets']: 0.390\n",
      "Segment 10:\n",
      "  - ['34' '/m/07r4k75' 'Grunt']: 0.213\n",
      "  - ['499' '/m/07pt_g0' 'Pulse']: 0.130\n",
      "  - ['index' 'mid' 'display_name']: 0.085\n",
      "Segment 11:\n",
      "  - ['66' '/t/dd00013' 'Children playing']: 0.410\n",
      "  - ['102' '/m/07qwf61' 'Honk']: 0.314\n",
      "  - ['105' '/m/04cvmfc' 'Roar']: 0.300\n",
      "Segment 12:\n",
      "  - ['66' '/t/dd00013' 'Children playing']: 0.619\n",
      "  - ['67' '/m/0jbk' 'Animal']: 0.498\n",
      "  - ['68' '/m/068hy' 'Domestic animals, pets']: 0.402\n",
      "Segment 13:\n",
      "  - ['381' '/m/081rb' 'Writing']: 0.111\n",
      "  - ['316' '/m/03j1ly' 'Emergency vehicle']: 0.083\n",
      "  - ['499' '/m/07pt_g0' 'Pulse']: 0.076\n",
      "Segment 14:\n",
      "  - ['66' '/t/dd00013' 'Children playing']: 0.413\n",
      "  - ['67' '/m/0jbk' 'Animal']: 0.267\n",
      "  - ['68' '/m/068hy' 'Domestic animals, pets']: 0.221\n",
      "Segment 15:\n",
      "  - ['66' '/t/dd00013' 'Children playing']: 0.113\n",
      "  - ['index' 'mid' 'display_name']: 0.109\n",
      "  - ['12' '/m/02rtxlg' 'Whispering']: 0.092\n",
      "Segment 16:\n",
      "  - ['66' '/t/dd00013' 'Children playing']: 0.415\n",
      "  - ['67' '/m/0jbk' 'Animal']: 0.279\n",
      "  - ['68' '/m/068hy' 'Domestic animals, pets']: 0.267\n",
      "Segment 17:\n",
      "  - ['66' '/t/dd00013' 'Children playing']: 0.307\n",
      "  - ['67' '/m/0jbk' 'Animal']: 0.255\n",
      "  - ['68' '/m/068hy' 'Domestic animals, pets']: 0.207\n",
      "Segment 18:\n",
      "  - ['66' '/t/dd00013' 'Children playing']: 0.473\n",
      "  - ['68' '/m/068hy' 'Domestic animals, pets']: 0.395\n",
      "  - ['67' '/m/0jbk' 'Animal']: 0.387\n",
      "Segment 19:\n",
      "  - ['66' '/t/dd00013' 'Children playing']: 0.136\n",
      "  - ['518' '/m/07c52' 'Television']: 0.043\n",
      "  - ['497' '/m/0hdsk' 'Chirp tone']: 0.034\n",
      "Segment 20:\n",
      "  - ['12' '/m/02rtxlg' 'Whispering']: 0.554\n",
      "  - ['15' '/m/07r660_' 'Giggle']: 0.277\n",
      "  - ['17' '/m/07sq110' 'Belly laugh']: 0.069\n"
     ]
    }
   ],
   "source": [
    "# Analyze and annotate extracted audio segments\n",
    "for i, (start, end) in enumerate(non_silent_ranges):\n",
    "    segment_path = f\"extracted_segments/segment_{i}.wav\"\n",
    "    segment = audio[start:end]\n",
    "    segment.export(segment_path, format=\"wav\")\n",
    "    \n",
    "    # Analyze segment with YAMNet\n",
    "    scores, class_names = analyze_audio(segment_path)\n",
    "    \n",
    "    # Get the top 3 predictions\n",
    "    top_scores = scores.mean(axis=0)\n",
    "    top_class_indices = top_scores.argsort()[-3:][::-1]\n",
    "    top_class_names = class_names[top_class_indices]\n",
    "    top_scores = top_scores[top_class_indices]\n",
    "    \n",
    "    print(f\"Segment {i}:\")\n",
    "    for class_name, score in zip(top_class_names, top_scores):\n",
    "        print(f\"  - {class_name}: {score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f64c175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
