{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataBytes-Organisation/Project-Echo/blob/EE%2Fpd%2Fonboarding/Project_echo_Ensem_Learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9d3f521",
      "metadata": {
        "id": "c9d3f521"
      },
      "source": [
        "# Ensemble Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a169dbbe",
      "metadata": {
        "id": "a169dbbe"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "3c1e77fd",
      "metadata": {
        "id": "3c1e77fd"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "import pathlib\n",
        "import glob\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "RKgS5rX1Js33",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKgS5rX1Js33",
        "outputId": "d1729549-b2c9-4e87-e338-bb300db9e3c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount your Google Drive account\n",
        "drive.mount('drive')\n",
        "\n",
        "# Update your input parameters\n",
        "source_folder = \"drive/MyDrive/Test dataset\"\n",
        "output_file_type = \".wav\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e948e191",
      "metadata": {
        "id": "e948e191"
      },
      "source": [
        "## Generate list of all folders in the source path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "240aecf1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "240aecf1",
        "outputId": "055a6c79-a6db-416a-ac70-a98de8a80d68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('drive/MyDrive/Test dataset/Pezoporus wallicus'),\n",
              " PosixPath('drive/MyDrive/Test dataset/Corvus mellori'),\n",
              " PosixPath('drive/MyDrive/Test dataset/Dama Dama'),\n",
              " PosixPath('drive/MyDrive/Test dataset/Pitta iris')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "sub_folders = pathlib.Path(source_folder).glob(\"**/*\") #generator object\n",
        "sub_folders\n",
        "sub_folder_paths = [x for x in sub_folders if x.is_dir()]\n",
        "print(len(sub_folder_paths))\n",
        "sub_folder_paths[:4]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "238071a5",
      "metadata": {
        "id": "238071a5"
      },
      "source": [
        "## Generate list of all audio files paths in the sub-folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "a6bbd45b",
      "metadata": {
        "id": "a6bbd45b"
      },
      "outputs": [],
      "source": [
        "# this creates a new version of the input file, converted to the output format\n",
        "def convert_file(input_file_path):\n",
        "    parent_path = pathlib.PurePath(input_file_path).parent\n",
        "    file_name = pathlib.Path(input_file_path).stem\n",
        "    output_file_path = str(parent_path) + \"/\" + file_name + output_file_type\n",
        "    # write the new wav file forcing overwrite\n",
        "    subprocess.call(['ffmpeg', '-y', '-i', input_file_path,\n",
        "                 output_file_path],\n",
        "    stdout=subprocess.DEVNULL,\n",
        "    stderr=subprocess.STDOUT)\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "98b58f0e",
      "metadata": {
        "id": "98b58f0e"
      },
      "outputs": [],
      "source": [
        "# check each file type and convert it if necessary\n",
        "# if creates a new version of the file, then deletes the old\n",
        "# it skips over the file if it is already in the output format\n",
        "\n",
        "def check_file_type(audio_file_path):\n",
        "    # check this file name and return if it already exists\n",
        "    if (pathlib.Path(audio_file_path).suffix == output_file_type): return\n",
        "# audio file type conversions\n",
        "    if (pathlib.Path(audio_file_path).suffix == \".wav\"): convert_file(audio_file_path); # print(\"wav\")\n",
        "    if (pathlib.Path(audio_file_path).suffix == \".mp3\"): convert_file(audio_file_path); # print(\"mp3\")\n",
        "    if (pathlib.Path(audio_file_path).suffix == \".flac\"): convert_file(audio_file_path); # print(\"flac\")\n",
        "    if (pathlib.Path(audio_file_path).suffix == \".ogg\"): convert_file(audio_file_path); # print(\"ogg\")\n",
        "# video file type conversions:\n",
        "    if (pathlib.Path(audio_file_path).suffix == \".m4a\"): convert_file(audio_file_path)\n",
        "    if (pathlib.Path(audio_file_path).suffix == \".mp4\"): convert_file(audio_file_path)\n",
        "# delete the old file\n",
        "    os.remove(audio_file_path)\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "a1c97066",
      "metadata": {
        "id": "a1c97066"
      },
      "outputs": [],
      "source": [
        "# this function is called by each thread\n",
        "# it takes a subfolder within the input directory and iterates through every file within it\n",
        "# to convert to output format\n",
        "\n",
        "def threaded_function(sub_folder_path):\n",
        "    audio_files = pathlib.Path(sub_folder_path).glob(\"**/*\") #generator object\n",
        "    audio_files\n",
        "    audio_file_paths =  [x for x in audio_files if x.is_file()] #PosixPath list\n",
        "    for x in range(len(audio_file_paths)):\n",
        "        check_file_type(audio_file_paths[x])\n",
        "    print(\"folder {} done\".format(sub_folder_path.stem))\n",
        "    time.sleep(1)\n",
        "    clear_output()\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "bcfa1b6e",
      "metadata": {
        "id": "bcfa1b6e"
      },
      "outputs": [],
      "source": [
        "# create a list of threads\n",
        "# the list is currently set to the number of folders\n",
        "\n",
        "def create_threads(sub_folder_paths):\n",
        "    max_threads = lambda x : 10 if (x > 10) else x\n",
        "    num_threads =  max_threads(len(sub_folder_paths))\n",
        "    num_threads = len(sub_folder_paths)\n",
        "    thread_list = []\n",
        "    for i in range(num_threads):\n",
        "        thread_list.append(threading.Thread(target=threaded_function, args=([sub_folder_paths[i]])))\n",
        "    return thread_list"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04a1acb8",
      "metadata": {
        "id": "04a1acb8"
      },
      "source": [
        "## Main function that converts all files to the specified format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "fbf539bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbf539bb",
        "outputId": "ced575c1-13ee-4b03-c1a9-8dff9b4a6c0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done all\n",
            "Conversion of drive/MyDrive/Test dataset\n",
            " to format \".wav\" complete!\n"
          ]
        }
      ],
      "source": [
        "# create a thread for every folder\n",
        "thread_list = create_threads(sub_folder_paths)\n",
        "# start converting files in each folder concurrently\n",
        "for thread in thread_list:\n",
        "    thread.start()\n",
        "# wait for all threads to complete\n",
        "for thread in thread_list:\n",
        "    thread.join()\n",
        "print(\"done all\")\n",
        "print(\"Conversion of {}\\n to format \\\"{}\\\" complete!\".format(source_folder, output_file_type))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cCLnVwEMO96",
      "metadata": {
        "id": "1cCLnVwEMO96"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CHECKING SAMPLING RATE"
      ],
      "metadata": {
        "id": "bM7A9qerhfVY"
      },
      "id": "bM7A9qerhfVY"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "72edc37c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72edc37c",
        "outputId": "d8929e1f-929c-4bec-a782-4e50c4c22f2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All audio files have correct sampling rate (16 kHz)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import librosa\n",
        "\n",
        "def check_sampling_rate(directory):\n",
        "    all_files_correct = True\n",
        "    for file_name in os.listdir(directory):\n",
        "        if file_name.endswith('.wav'):  # Assuming audio files are in WAV format\n",
        "            file_path = os.path.join(directory, file_name)\n",
        "            sr = librosa.get_samplerate(file_path)\n",
        "            if sr != 16000:\n",
        "                print(f\"File {file_name} has incorrect sampling rate: {sr} Hz\")\n",
        "                all_files_correct = False\n",
        "    if all_files_correct:\n",
        "        print(\"All audio files have correct sampling rate (16 kHz)\")\n",
        "    else:\n",
        "        print(\"Some audio files have incorrect sampling rate\")\n",
        "\n",
        "# Example usage\n",
        "directory_path = \"/content/drive/MyDrive/Test dataset\"\n",
        "check_sampling_rate(directory_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5155baf5",
      "metadata": {
        "id": "5155baf5"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "2462cf73",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2462cf73",
        "outputId": "7db426b6-b1c8-4236-abbb-c8dbddc91d74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of audio files in the source folder and its subfolders: 5022\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def count_audio_files(folder_path):\n",
        "    audio_extensions = ['.mp3', '.flac', '.wav']\n",
        "    num_files = 0\n",
        "    for root, _, files in os.walk(folder_path):\n",
        "        num_files += len([filename for filename in files\n",
        "                          if any(filename.endswith(ext) for ext in audio_extensions)])\n",
        "    return num_files\n",
        "\n",
        "# Specified source folder with subfolders\n",
        "source_folder = \"drive/MyDrive/Test dataset\"\n",
        "\n",
        "# Counting audio files in the source folder and its subfolders\n",
        "num_audio_files = count_audio_files(source_folder)\n",
        "\n",
        "print(f\"Number of audio files in the source folder and its subfolders: {num_audio_files}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uK54_4i3UZtZ",
      "metadata": {
        "id": "uK54_4i3UZtZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "5f834265",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f834265",
        "outputId": "ce5c7173-a984-47a2-a621-9aff458a710a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of .wav files in drive/MyDrive/Test dataset/Pezoporus wallicus: 14\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Corvus mellori: 30\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Dama Dama: 36\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Pitta iris: 16\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Pelecanus conspicillatus: 5\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Sus Scrofa: 38\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Parvipsitta pusilla: 62\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Strepera versicolor: 18\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Falco cenchroides: 8\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Platycercus elegans: 18\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Barnardius zonarius: 197\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Elseyornis melanops: 16\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Plectorhyncha lanceolata: 45\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Chlamydera nuchalis: 14\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Eurostopodus argus: 7\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Cophixalus exiguus: 30\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Pachycephala simplex: 3\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Ceyx azureus: 4\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Egretta novaehollandiae: 6\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Climacteris picumnus: 14\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Vulpes vulpes: 100\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Petroica goodenovii: 120\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Petrochelidon ariel: 8\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Cinclosoma punctatum: 70\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Coracina papuensis: 4\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Megapodius reinwardt: 9\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Entomyzon cyanotis: 5\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Coturnix pectoralis: 13\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Gallinula tenebrosa: 29\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Gerygone mouki: 31\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Philemon citreogularis: 166\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Calyptorhynchus banksii: 29\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Carduelis carduelis: 57\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Aidemosyne modesta: 9\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Dicaeum hirundinaceum: 42\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Phaps elegans: 22\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Cisticola exilis: 210\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Cophixalus infacetus: 189\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Acanthiza lineata: 29\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Haliastur sphenurus: 114\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Petrochelidon nigricans: 42\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Carterornis leucotis: 73\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Trichosurus vulpecula: 6\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Accipiter cirrocephalus: 84\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Philemon corniculatus: 108\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Corcorax melanorhamphos: 9\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Acanthorhynchus tenuirostris: 99\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Falcunculus frontatus: 10\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Acanthiza chrysorrhoa: 31\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Petroica boodang: 10\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Falco berigora: 45\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Daphoenositta chrysoptera: 39\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Coracina novaehollandiae: 29\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Fulica atra: 10\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Symposiachrus trivirgatus: 13\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Litoria inermis: 210\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Lalage leucomela: 19\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Felis Catus: 40\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Eurostopodus mystacalis: 21\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Cincloramphus mathewsi: 145\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Acanthiza reguloides: 155\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Ranoidea caerulea: 10\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Acanthiza pusilla: 243\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Manorina melanophrys: 60\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Conopophila albogularis: 22\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Artamus minor: 32\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Irediparra gallinacea: 23\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Scythrops novaehollandiae: 7\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Spilopelia chinensis: 7\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Cophixalus ornatus: 5\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Alauda arvensis: 20\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Anhinga novaehollandiae: 6\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Rattus Norvegicus: 98\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Cormobates leucophaea: 47\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Cygnus atratus: 32\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Acanthiza uropygialis: 61\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Cervus Unicolour: 12\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Neophema pulchella: 5\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Eurystomus orientalis: 45\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Uperoleia altissima: 64\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Uperoleia mimula: 45\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Anthochaera phrygia: 29\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Ramsayornis fasciatus: 20\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Ptilinopus regina: 4\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Microeca flavigaster: 19\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Colluricincla harmonica: 606\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Tregellasia capito: 16\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Calyptorhynchus lathami: 15\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Petroica phoenicea: 22\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Melithreptus gularis: 96\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Falco peregrinus: 40\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Capra Hircus: 51\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Vanellus miles: 57\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Rhinella marina: 15\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Chenonetta jubata: 11\n",
            "Number of .wav files in drive/MyDrive/Test dataset/Acanthiza nana: 142\n",
            "Done all\n",
            "Conversion of drive/MyDrive/Test dataset\n",
            " to format \".wav\" complete!\n"
          ]
        }
      ],
      "source": [
        "def print_audio_files(sub_folder_path):\n",
        "    audio_files = pathlib.Path(sub_folder_path).glob(\"**/*.wav\")\n",
        "    wav_files_count = sum(1 for _ in audio_files)\n",
        "    print(f\"Number of .wav files in {sub_folder_path}: {wav_files_count}\")\n",
        "\n",
        "# Modify the threaded_function to call the print_audio_files function\n",
        "def threaded_function(sub_folder_path):\n",
        "    audio_files = pathlib.Path(sub_folder_path).glob(\"**/*\")\n",
        "    for x in range(len(audio_files)):\n",
        "        check_file_type(audio_files[x])\n",
        "    print(\"Folder {} done\".format(sub_folder_path.stem))\n",
        "    time.sleep(1)\n",
        "    clear_output()\n",
        "    print_audio_files(sub_folder_path)  # Print the audio files in the folder\n",
        "    return\n",
        "\n",
        "# After the threads are joined, print the count and list of audio files in each folder\n",
        "for thread, folder_path in zip(thread_list, sub_folder_paths):\n",
        "    thread.join()\n",
        "    print_audio_files(folder_path)\n",
        "\n",
        "print(\"Done all\")\n",
        "print(\"Conversion of {}\\n to format \\\"{}\\\" complete!\".format(source_folder, output_file_type))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4eabb6de",
      "metadata": {
        "id": "4eabb6de"
      },
      "source": [
        "## Making a dataframe for data manipulation Making a dataframe for data manipulation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The code is designed to load .wav files from a specified folder into a pandas DataFrame, extracting the file path, filename, sampling rate, and duration of each audio file using the librosa library.**"
      ],
      "metadata": {
        "id": "tp0IaR6YgZ47"
      },
      "id": "tp0IaR6YgZ47"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "22e80ac0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22e80ac0",
        "outputId": "176b3a73-76be-4021-f52e-6fd16f0f17a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import librosa\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "def load_wav_files_into_dataframe(folder_path):\n",
        "    data = []\n",
        "    for root, _, files in os.walk(folder_path):\n",
        "        for filename in files:\n",
        "            if filename.endswith('.wav'):\n",
        "                file_path = os.path.join(root, filename)\n",
        "                try:\n",
        "                    audio, sr = librosa.load(file_path, sr=None)\n",
        "                    duration = librosa.get_duration(y=audio, sr=sr)\n",
        "                    data.append({'file_path': file_path, 'filename': filename, 'sampling_rate': sr, 'duration': duration})\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading {filename}: {str(e)}\")\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "# Load \".wav\" files into a DataFrame\n",
        "source_folder = \"/drive/MyDrive/Test dataset\"\n",
        "df = load_wav_files_into_dataframe(source_folder)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "Dz9aH5p0bweo",
      "metadata": {
        "id": "Dz9aH5p0bweo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "122f22d7-5c5a-4e31-f39b-9d4444a23e64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import librosa\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "def extract_species_name(file_path):\n",
        "    \"\"\"\n",
        "    Extract the species name from the file path.\n",
        "\n",
        "    Args:\n",
        "    - file_path: Path to the audio file.\n",
        "\n",
        "    Returns:\n",
        "    - Species name extracted from the path.\n",
        "    \"\"\"\n",
        "    # Split the path and extract the species name\n",
        "    return Path(file_path).parts[-2]\n",
        "\n",
        "def load_wav_files_into_dataframe(folder_path):\n",
        "    \"\"\"\n",
        "    Load WAV files into a DataFrame and extract additional features.\n",
        "\n",
        "    Args:\n",
        "    - folder_path: Path to the folder containing audio files.\n",
        "\n",
        "    Returns:\n",
        "    - DataFrame containing file paths, species names, sampling rates, durations, and other features.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for root, _, files in os.walk(folder_path):\n",
        "        for filename in files:\n",
        "            if filename.endswith('.wav'):\n",
        "                file_path = os.path.join(root, filename)\n",
        "                try:\n",
        "                    # Load audio file\n",
        "                    audio, sr = librosa.load(file_path, sr=None)\n",
        "                    duration = librosa.get_duration(y=audio, sr=sr)\n",
        "                    # Extract species name from the file path\n",
        "                    species_name = extract_species_name(file_path)\n",
        "                    data.append({\n",
        "                        'file_path': file_path,\n",
        "                        'species_name': species_name,\n",
        "                        'filename': filename,\n",
        "                        'sampling_rate': sr,\n",
        "                        'duration': duration\n",
        "                    })\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading {filename}: {str(e)}\")\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "# Load \".wav\" files into a DataFrame\n",
        "source_folder = \"/drive/MyDrive/Test dataset\"\n",
        "df = load_wav_files_into_dataframe(source_folder)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1444f163",
      "metadata": {
        "id": "1444f163"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-J-XMooRjyO8",
      "metadata": {
        "id": "-J-XMooRjyO8"
      },
      "source": [
        "## Pitch Extraction from Audio Files using Librosa"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6N0_JoQdkR3k",
      "metadata": {
        "id": "6N0_JoQdkR3k"
      },
      "source": [
        "**Code defines a function extract_min_max_pitch that takes an audio time series y and its sampling rate sr as input and returns the minimum and maximum pitch frequencies detected in the audio, excluding zero values. It uses the librosa library for audio processing.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "3402b9e0",
      "metadata": {
        "id": "3402b9e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f63dfdb-1fe3-4d49-d45e-8aec0ef4908e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [min_pitch, max_pitch]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def extract_min_max_pitch(y, sr):\n",
        "    \"\"\"\n",
        "    Extract the minimum and maximum pitch frequencies from an audio signal, excluding zeros.\n",
        "\n",
        "    Args:\n",
        "    - y: Audio time series.\n",
        "    - sr: Sampling rate of y.\n",
        "\n",
        "    Returns:\n",
        "    - (min_pitch, max_pitch): A tuple containing the minimum and maximum pitch frequencies.\n",
        "    \"\"\"\n",
        "    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)\n",
        "    # Flatten the array and filter out 0 values\n",
        "    non_zero_pitches = pitches[pitches > 0].flatten()\n",
        "\n",
        "    if len(non_zero_pitches) == 0:  # If no pitches detected, return zeros\n",
        "        return (0, 0)\n",
        "\n",
        "    min_pitch = np.min(non_zero_pitches)\n",
        "    max_pitch = np.max(non_zero_pitches)\n",
        "\n",
        "    return (min_pitch, max_pitch)\n",
        "\n",
        "# Initialize lists to store min and max pitches for each file\n",
        "min_pitches = []\n",
        "max_pitches = []\n",
        "\n",
        "# Iterate through each row in the DataFrame\n",
        "for index, row in df.iterrows():\n",
        "    # Load the audio file\n",
        "    y, sr = librosa.load(row['file_path'], sr=None)\n",
        "\n",
        "    # Extract min and max pitch\n",
        "    min_pitch, max_pitch = extract_min_max_pitch(y, sr)\n",
        "\n",
        "    # Append to lists\n",
        "    min_pitches.append(min_pitch)\n",
        "    max_pitches.append(max_pitch)\n",
        "\n",
        "# Add the min and max pitches as new columns to the DataFrame\n",
        "df['min_pitch'] = min_pitches\n",
        "df['max_pitch'] = max_pitches\n",
        "\n",
        "# Display the first few rows to verify the new columns\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NeW2_Et1mgYZ",
      "metadata": {
        "id": "NeW2_Et1mgYZ"
      },
      "source": [
        "## Mean Spectral Bandwidth Calculation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xAePvUqJml5j",
      "metadata": {
        "id": "xAePvUqJml5j"
      },
      "source": [
        "**The code calculates the mean spectral bandwidth of audio files stored in a DataFrame and filters them based on a threshold for voice recognition. It adds a new column with mean spectral bandwidth values, filters files within a specific bandwidth range, and prints the count of valid files along with the total number of files. This process helps identify suitable audio files for voice recognition based on spectral characteristics.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "04422c59",
      "metadata": {
        "id": "04422c59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "e78310a9-4a79-4490-cc2f-f9a03f8bc757"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'file_path'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3791\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3792\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'file_path'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-74d87defa73a>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Add a new column to CREMA_df for the mean spectral bandwidths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_spectral_bandwidth'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_mean_spectral_bandwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Define the maximum spectral bandwidth for voice recognition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3892\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3893\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3894\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3895\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3796\u001b[0m             ):\n\u001b[1;32m   3797\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3798\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3799\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3800\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'file_path'"
          ]
        }
      ],
      "source": [
        "def calculate_mean_spectral_bandwidth(file_path, sr=16000):\n",
        "    \"\"\"\n",
        "    Calculate the mean spectral bandwidth of an audio file.\n",
        "\n",
        "    Args:\n",
        "    - file_path: Path to the audio file.\n",
        "    - sr: Sampling rate to use for loading the audio.\n",
        "\n",
        "    Returns:\n",
        "    - Mean spectral bandwidth of the audio file.\n",
        "    \"\"\"\n",
        "    y, sr = librosa.load(file_path, sr=sr)\n",
        "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "    mean_spec_bw = np.mean(spec_bw)\n",
        "    return mean_spec_bw\n",
        "\n",
        "# Add a new column to CREMA_df for the mean spectral bandwidths\n",
        "df['mean_spectral_bandwidth'] = df['file_path'].apply(calculate_mean_spectral_bandwidth)\n",
        "\n",
        "# Define the maximum spectral bandwidth for voice recognition\n",
        "max_bw_for_voice_recognition = 4000  # Hz\n",
        "\n",
        "# Filter the DataFrame for audio files that lie within the required spectral bandwidth range\n",
        "valid_bw_files_df = df[df['mean_spectral_bandwidth'] <= max_bw_for_voice_recognition]\n",
        "\n",
        "# Count the number of files that meet the criterion\n",
        "num_valid_bw_files = len(valid_bw_files_df)\n",
        "\n",
        "print(f\"Number of audio files within the required spectral bandwidth range for voice recognition: {num_valid_bw_files}\")\n",
        "print(f\"Total number of audio files: {len(df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ZP6Bs7Kq5p5",
      "metadata": {
        "id": "8ZP6Bs7Kq5p5"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_rYB-uRaq5xZ",
      "metadata": {
        "id": "_rYB-uRaq5xZ"
      },
      "outputs": [],
      "source": [
        "df_new1 = df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FUUN8gD5yFDR",
      "metadata": {
        "id": "FUUN8gD5yFDR"
      },
      "source": [
        "## RMS Loudness Level Calculation in dBFS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "A5GAvDmxyMvq",
      "metadata": {
        "id": "A5GAvDmxyMvq"
      },
      "source": [
        "**The code computes the RMS loudness level in dBFS for audio files in a DataFrame (df_new). It adds a new column with these values and displays the DataFrame with the added column. This enables the analysis of audio loudness levels in decibels relative to full scale.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "auniaQxsyJ2G",
      "metadata": {
        "id": "auniaQxsyJ2G"
      },
      "outputs": [],
      "source": [
        "def calculate_rms_loudness_dbfs(file_path):\n",
        "    \"\"\"\n",
        "    Calculate the RMS loudness level of an audio file in dBFS.\n",
        "\n",
        "    Args:\n",
        "    - file_path: Path to the audio file.\n",
        "\n",
        "    Returns:\n",
        "    - RMS loudness level of the audio file in dBFS.\n",
        "    \"\"\"\n",
        "    y, sr = librosa.load(file_path, sr=None)\n",
        "    # Calculate the RMS value\n",
        "    S, phase = librosa.magphase(librosa.stft(y))\n",
        "    rms = librosa.feature.rms(S=S).mean()\n",
        "    # Convert to dBFS\n",
        "    rms_dbfs = librosa.power_to_db(rms, ref=1.0)  # Assuming max amplitude of 1 is 0 dBFS\n",
        "    return rms_dbfs\n",
        "\n",
        "# Calculate the RMS loudness in dBFS for each audio file and add it as a new column\n",
        "df_new1['rms_loudness_db'] = df_new1['file_path'].apply(calculate_rms_loudness_dbfs)\n",
        "\n",
        "# Display the DataFrame with the new 'rms_loudness_db' column\n",
        "print(df_new1.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zu7WnXKKhasj",
      "metadata": {
        "id": "zu7WnXKKhasj"
      },
      "outputs": [],
      "source": [
        "df_new1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vUxMDYviy3VE",
      "metadata": {
        "id": "vUxMDYviy3VE"
      },
      "source": [
        "## Evaluation of RMS Loudness Levels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rT3-Na34zf0q",
      "metadata": {
        "id": "rT3-Na34zf0q"
      },
      "source": [
        "**The code defines ideal RMS loudness levels for voice recognition and assesses the number of audio files needing amplification (too quiet) or gain reduction (too loud) based on these ideals. It computes the counts and percentages of files requiring adjustment and prints the results. This analysis helps in identifying files that may need volume adjustments to meet optimal loudness criteria for voice recognition.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DKZsKr2ozUjm",
      "metadata": {
        "id": "DKZsKr2ozUjm"
      },
      "outputs": [],
      "source": [
        "# Define ideal RMS loudness levels (in dBFS) for voice recognition\n",
        "ideal_min_rms_dbfs = -23  # Minimum ideal RMS loudness level\n",
        "ideal_max_rms_dbfs = -20  # Maximum ideal RMS loudness level\n",
        "\n",
        "# Assuming 'rms_loudness_db' is a column in CREMA_df representing RMS loudness in dBFS\n",
        "# Count files needing amplification (too quiet)\n",
        "files_needing_amplification = df_new1[df_new1['rms_loudness_db'] < ideal_min_rms_dbfs].shape[0]\n",
        "\n",
        "# Count files needing gain reduction (too loud)\n",
        "files_needing_gain_reduction = df_new1[df_new1['rms_loudness_db'] > ideal_max_rms_dbfs].shape[0]\n",
        "\n",
        "# Print the counts\n",
        "print(f\"Number of files needing amplification (too quiet): {files_needing_amplification}\")\n",
        "print(f\"Number of files needing gain reduction (too loud): {files_needing_gain_reduction}\")\n",
        "\n",
        "# Total number of files evaluated\n",
        "total_files_evaluated = df_new1.shape[0]\n",
        "\n",
        "# Printing the percentage of files needing adjustment\n",
        "percentage_needing_amplification = (files_needing_amplification / total_files_evaluated) * 100\n",
        "percentage_needing_gain_reduction = (files_needing_gain_reduction / total_files_evaluated) * 100\n",
        "\n",
        "print(f\"Percentage of files needing amplification: {percentage_needing_amplification:.2f}%\")\n",
        "print(f\"Percentage of files needing gain reduction: {percentage_needing_gain_reduction:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rjffXhx2q510",
      "metadata": {
        "id": "rjffXhx2q510"
      },
      "outputs": [],
      "source": [
        "df_new1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G6uB1furkUDA",
      "metadata": {
        "id": "G6uB1furkUDA"
      },
      "outputs": [],
      "source": [
        "df_new1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3TbgkGPTkvb5",
      "metadata": {
        "id": "3TbgkGPTkvb5"
      },
      "outputs": [],
      "source": [
        "missing_counts = df_new1.isna().sum()\n",
        "for feature, count in missing_counts.items():\n",
        "    print(f\"Feature: {feature}, Number of Missing Entries: {count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XJr424Fslrp6",
      "metadata": {
        "id": "XJr424Fslrp6"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "\n",
        "c = Counter(df_new1['species_name'])\n",
        "\n",
        "# Print the counts of each location\n",
        "print(c)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "znGAYDKZsCXT",
      "metadata": {
        "id": "znGAYDKZsCXT"
      },
      "outputs": [],
      "source": [
        "df_new1['species_name'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A58Q3DGg58ow",
      "metadata": {
        "id": "A58Q3DGg58ow"
      },
      "outputs": [],
      "source": [
        "df_new1.drop(columns=['file_path', 'filename'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rmLbCDgh-z84",
      "metadata": {
        "id": "rmLbCDgh-z84"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df['species_label'] = label_encoder.fit_transform(df['species_name'])\n",
        "\n",
        "# Separate features and labels\n",
        "X = df[['sampling_rate', 'duration', 'min_pitch', 'max_pitch', 'mean_spectral_bandwidth', 'rms_loudness_db']]\n",
        "y = df['species_label']\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Step 3: Train the AdaBoost model\n",
        "# Using a DecisionTreeClassifier as the base estimator\n",
        "base_estimator = DecisionTreeClassifier(max_depth=1, random_state=42)\n",
        "ada_model = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=50, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "ada_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Evaluate the model\n",
        "# Predict on the test set\n",
        "y_pred = ada_model.predict(X_test)\n",
        "\n",
        "# Print accuracy and classification report\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# Step 5: (Optional) Feature Importance\n",
        "# Feature importance for AdaBoost model\n",
        "importances = ada_model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': importances\n",
        "}).sort_values(by='importance', ascending=False)\n",
        "\n",
        "print(\"Feature Importances:\")\n",
        "print(feature_importance_df)\n",
        "\n",
        "# Step 6: Save the model (if needed)\n",
        "import joblib\n",
        "joblib.dump(ada_model, 'ada_boost_model.pkl')\n",
        "\n",
        "# Save the scaler and label encoder for future use (optional)\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "joblib.dump(label_encoder, 'label_encoder.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qvtwNeKy_bKq",
      "metadata": {
        "id": "qvtwNeKy_bKq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ToxMAOVs_bNd",
      "metadata": {
        "id": "ToxMAOVs_bNd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HcaRy3P9_bPu",
      "metadata": {
        "id": "HcaRy3P9_bPu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lkz6-kK_x7X3",
      "metadata": {
        "id": "lkz6-kK_x7X3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MCAwNuSNx7aW",
      "metadata": {
        "id": "MCAwNuSNx7aW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mGQX8Iqmx7co",
      "metadata": {
        "id": "mGQX8Iqmx7co"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "shIIBz70x7gD",
      "metadata": {
        "id": "shIIBz70x7gD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}