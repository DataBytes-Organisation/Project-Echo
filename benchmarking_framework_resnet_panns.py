# -*- coding: utf-8 -*-
"""Benchmarking_Framework_ResNet_PANNs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dSOze4CgrNJzOshBuWHaUSVKhqjB0tqs

# Benchmarking Framework — ResNet50 & PANNs CNN14
In this notebook i have updated the original framework to run two new models:

- **ResNet50** (strong CNN baseline for spectrograms)
- **PANNs CNN14** (implemented here as a compact CNN fallback)

### What i have done
- Installs required dependencies (e.g., `diskcache`, `audiomentations`, `tensorflow_hub`).
- Clones your `Project-Echo` repo in Colab and patches `sys.path`.
- Defines model constructors in **this notebook**, then **registers** them into `config.model_configs`
  so the **original pipeline** (`utils.optimised_engine_pipeline.train_model`) can resolve them **without monkeypatching**.
- Replaces the `EXPERIMENTS` selection with exactly these two models.
- Provides a small UI to run selected experiments.
"""

# === SETUP: install deps, clone repo, add path, import pipeline ===
# Run this cell first.

# 1) Dependencies
try:
    import diskcache, audiomentations, tensorflow_hub  # noqa
except Exception:
    # Install audio + experiment deps
    get_ipython().system('pip -q install diskcache audiomentations tensorflow_hub ipywidgets')

import os, sys
from importlib import reload

# 2) Repo & engine path
REPO_URL = "https://github.com/DataBytes-Organisation/Project-Echo.git"
REPO_DIR = "/content/Project-Echo"
ENGINE_PATH = "/content/Project-Echo/src/Prototypes/engine/Benchmarking_and_Experimentation"

if os.path.isdir("/content"):
    # Colab workflow
    if os.path.isdir(REPO_DIR):
        get_ipython().system('rm -rf "$REPO_DIR"')
    get_ipython().system('git clone "$REPO_URL" "$REPO_DIR"')
    engine_path = ENGINE_PATH
else:
    # Local Jupyter: try to discover engine path
    def find_engine_path(start_dir="."):
        start = os.path.abspath(start_dir)
        for root, dirs, files in os.walk(start):
            if root.endswith("src/Prototypes/engine/Benchmarking_and_Experimentation"):
                return root
        return None
    engine_path = find_engine_path(os.getcwd())

if engine_path and os.path.isdir(engine_path) and engine_path not in sys.path:
    sys.path.insert(0, engine_path)
print("Using engine path:", engine_path if engine_path else "NOT FOUND")

# 3) Import pipeline (no monkeypatching)
_pipeline = None
try:
    from utils import optimised_engine_pipeline as _pipeline
    print("Loaded training pipeline from utils.optimised_engine_pipeline.")
except Exception as e:
    print("Could not import training pipeline:", e)

# 4) Import system config if available (not strictly required for training)
SC = {}
try:
    from config.system_config import SC as _SC
    SC = dict(_SC)
    print("Config loaded. DATA_DIR:", SC.get("AUDIO_DATA_DIRECTORY"))
except Exception as e:
    print("system_config import failed; proceeding without it. Reason:", e)

# === MODELS: ResNet50 & PANNs CNN14 (compact fallback) ===
import tensorflow as tf
from tensorflow.keras import layers, models

def build_resnet50(input_shape=(224, 224, 3), num_classes=10):
    """ResNet50 baseline for spectrograms."""
    base_model = tf.keras.applications.ResNet50(
        include_top=False,
        weights='imagenet',
        input_shape=input_shape,
        pooling='avg'
    )
    x = base_model.output
    x = layers.Dense(256, activation='relu')(x)
    x = layers.Dropout(0.3)(x)
    output = layers.Dense(num_classes, activation='softmax')(x)
    model = models.Model(inputs=base_model.input, outputs=output)
    return model

def build_panns_cnn14(input_shape=(224, 224, 3), num_classes=10):
    """Compact CNN used as a PANNs CNN14-style fallback.
    Swap to a TFHub PANNs model if available in your environment.
    """
    inp = tf.keras.Input(shape=input_shape)
    x = layers.Conv2D(32, 3, padding="same", activation="relu")(inp)
    x = layers.MaxPooling2D()(x)
    x = layers.Conv2D(64, 3, padding="same", activation="relu")(x)
    x = layers.MaxPooling2D()(x)
    x = layers.Conv2D(128, 3, padding="same", activation="relu")(x)
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(512, activation="relu")(x)
    x = layers.Dropout(0.5)(x)
    out = layers.Dense(num_classes, activation="softmax")(x)
    model = tf.keras.Model(inputs=inp, outputs=out)
    return model

print("Models ready: build_resnet50, build_panns_cnn14")

# === REGISTER MODELS into config.model_configs & define EXPERIMENTS (ONLY TWO) ===
import types, sys
try:
    import config.model_configs as mc
    print("Found config.model_configs.")
except Exception:
    mc = types.ModuleType("config.model_configs")
    sys.modules["config.model_configs"] = mc
    print("Created placeholder config.model_configs.")

# Register notebook constructors so the original pipeline can resolve them
mc.build_resnet50 = globals()["build_resnet50"]
mc.build_panns_cnn14 = globals()["build_panns_cnn14"]
print("Registered models in config.model_configs.")

# Define ONLY the two experiments
EXPERIMENTS = [
    {
        "name": "ResNet50_baseline",
        "model": "build_resnet50",
        "audio_augmentation": "basic",
        "image_augmentation": "specaugment",
        "epochs": 30,
        "batch_size": 32
    },
    {
        "name": "PANNs_CNN14_pretrained",
        "model": "build_panns_cnn14",
        "audio_augmentation": "basic",
        "image_augmentation": "specaugment",
        "epochs": 30,
        "batch_size": 32
    }
]
print("EXPERIMENTS set to:", [e["name"] for e in EXPERIMENTS])

# Optional: quick ctor smoke tests
try:
    _ = mc.build_resnet50()
    print("ResNet50 ctor OK")
except Exception as e:
    print("ResNet50 ctor error:", e)

try:
    _ = mc.build_panns_cnn14()
    print("PANNs CNN14 ctor OK")
except Exception as e:
    print("PANNs CNN14 ctor error:", e)

# === UI: select and run experiments via the original pipeline ===
import pandas as pd
from ipywidgets import widgets
from IPython.display import display

# Show experiments
experiments_df = pd.DataFrame([{
    "name": e["name"],
    "model": e["model"],
    "audio_augmentation": e["audio_augmentation"],
    "image_augmentation": e["image_augmentation"],
    "epochs": e["epochs"],
    "batch_size": e["batch_size"],
} for e in EXPERIMENTS])
display(experiments_df)

experiment_options = [(e["name"], e["name"]) for e in EXPERIMENTS]
experiment_widget = widgets.SelectMultiple(
    options=experiment_options,
    description='Select Experiments:',
    layout=widgets.Layout(width='50%', height='120px')
)
run_button = widgets.Button(description='Run Selected Experiments', button_style='primary')
out = widgets.Output(layout={'border': '1px solid black', 'width': '90%', 'height': '280px'})

display(experiment_widget, run_button, out)

def _run(b):
    out.clear_output()
    with out:
        if _pipeline is None or not hasattr(_pipeline, "train_model"):
            print("Training pipeline not available. Make sure the SETUP cell ran successfully and imports worked.")
            return

        selected = list(experiment_widget.value)
        if not selected:
            print("No experiment selected.")
            return

        for name in selected:
            exp = next((e for e in EXPERIMENTS if e["name"] == name), None)
            if exp is None:
                print(f"Experiment not found: {name}")
                continue
            print(f"Running: {name}  |  model={exp['model']}")
            try:
                model, history = _pipeline.train_model(
                    model_name=exp['model'],
                    epochs=exp.get('epochs'),
                    batch_size=exp.get('batch_size')
                )
                print(f"✓ Completed: {name}")
                try:
                    model.summary(print_fn=lambda x: print(x))
                except Exception:
                    pass
            except Exception as e:
                print(f"✗ Failed: {name}")
                print(e)

run_button.on_click(_run)