{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version        :  3.8.16\n",
      "TensorFlow Version    :  2.10.1\n",
      "TensorFlow IO Version :  0.27.0\n",
      "Librosa Version       :  0.10.0\n"
     ]
    }
   ],
   "source": [
    "########################################################################################\n",
    "# library imports\n",
    "########################################################################################\n",
    "\n",
    "# disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# generic libraries\n",
    "from platform import python_version\n",
    "import functools\n",
    "import diskcache as dc\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "# tensor flow / keras related libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import tensorflow_hub as hub\n",
    "from keras.utils import dataset_utils\n",
    "\n",
    "# image processing related libraries\n",
    "import librosa \n",
    "\n",
    "# print system information\n",
    "print('Python Version        : ', python_version())\n",
    "print('TensorFlow Version    : ', tf.__version__)\n",
    "print('TensorFlow IO Version : ', tfio.__version__)\n",
    "print('Librosa Version       : ', librosa.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "# system constants\n",
    "########################################################################################\n",
    "AUDIO_DATA_DIRECTORY = \"d:\\\\data\\\\bc\"\n",
    "CACHE_DIRETORY       = \"d:\\\\pipeline_cache\"\n",
    "\n",
    "AUDIO_NFFT = 512\n",
    "AUDIO_WINDOW = 512\n",
    "AUDIO_STRIDE = 512\n",
    "AUDIO_SAMPLE_RATE = int(44100/2)\n",
    "AUDIO_MELS = 128\n",
    "AUDIO_FMIN = 0\n",
    "AUDIO_FMAX = int(AUDIO_SAMPLE_RATE)/2\n",
    "AUDIO_TOP_DB = 80\n",
    "        \n",
    "MODEL_INPUT_IMAGE_WIDTH = 256\n",
    "MODEL_INPUT_IMAGE_HEIGHT = 256\n",
    "MODEL_INPUT_IMAGE_CHANNELS = 3\n",
    "\n",
    "SAMPLE_VARIANTS=20\n",
    "CLASSIFIER_BATCH_SIZE=32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "# Create a DiskCache instance\n",
    "# This cache will allow us store intermediate function results to speed up the \n",
    "# data processing pipeline\n",
    "########################################################################################\n",
    "cache = dc.Cache(CACHE_DIRETORY, cull_limit=0, size_limit=10**9) \n",
    "\n",
    "\n",
    "########################################################################################\n",
    "# a helper function to create a hash key from a function signature and arguments\n",
    "########################################################################################\n",
    "def create_function_key(func, *args, **kwargs):\n",
    "    partial_func = functools.partial(func, *args, **kwargs)\n",
    "    func_name = partial_func.func.__name__\n",
    "    func_module = partial_func.func.__module__\n",
    "    args_repr = repr(partial_func.args)\n",
    "    kwargs_repr = repr(sorted(partial_func.keywords.items()))\n",
    "\n",
    "    key = f\"{func_module}.{func_name}:{args_repr}:{kwargs_repr}\"\n",
    "    # Use hashlib to create a hash of the key for shorter and consistent length\n",
    "    key_hash = hashlib.sha256(key.encode()).hexdigest()\n",
    "\n",
    "    return key, key_hash, partial_func\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "# Execute a function and cache the result\n",
    "# If already executed, retrieve function output from the cache instead\n",
    "########################################################################################\n",
    "def execute_cached_function(func, *args, **kwargs):\n",
    "    key_string,key,partial_func = create_function_key(func, *args, **kwargs)\n",
    "    # Check if the result is in the cache\n",
    "    if key in cache:\n",
    "        result = cache[key]\n",
    "        # print(f\"Result loaded from cache key: {key}\")\n",
    "    else:\n",
    "        # If not in cache, call the slow operation and store the result in cache\n",
    "        result = partial_func()\n",
    "        cache[key] = result\n",
    "        print(f\"New result calculated and stored in cache key: {key}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "# these helper functions load the audio data into a 'dataset' using only paths\n",
    "# just dealing with paths at this early stage means the entire dataset can be shuffled in\n",
    "# memory and split before loading the actual audio data into memory\n",
    "########################################################################################\n",
    "def paths_and_labels_to_dataset(image_paths, labels, num_classes):\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "    label_ds = dataset_utils.labels_to_dataset(\n",
    "        labels, \n",
    "        'categorical', \n",
    "        num_classes)\n",
    "    zipped_path_ds = tf.data.Dataset.zip((path_ds, label_ds))\n",
    "    return zipped_path_ds\n",
    "\n",
    "def create_datasets(audio_files, train_split=0.7, val_split=0.2):\n",
    "    file_paths, labels, class_names = dataset_utils.index_directory(\n",
    "            audio_files,\n",
    "            labels=\"inferred\",\n",
    "            formats=('.ogg','.mp3','.wav','.flac'),\n",
    "            class_names=None,\n",
    "            shuffle=False,\n",
    "            seed=42,\n",
    "            follow_links=False)\n",
    "\n",
    "    dataset = paths_and_labels_to_dataset(\n",
    "        image_paths=file_paths,\n",
    "        labels=labels,\n",
    "        num_classes=len(class_names))\n",
    "    \n",
    "    # Calculate the size of the dataset\n",
    "    dataset_size = len(dataset)\n",
    "    \n",
    "    # Calculate the number of elements for each dataset split\n",
    "    train_size = int(train_split * dataset_size)\n",
    "    val_size = int(val_split * dataset_size)\n",
    "    test_size = dataset_size - train_size - val_size\n",
    "\n",
    "    # Shuffle the dataset\n",
    "    dataset = dataset.shuffle(buffer_size=dataset_size, seed=42)\n",
    "\n",
    "    # Split the dataset\n",
    "    train_ds = dataset.take(train_size)\n",
    "    val_ds = dataset.skip(train_size).take(val_size)\n",
    "    test_ds = dataset.skip(train_size + val_size).take(test_size)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 524 files belonging to 5 classes.\n",
      "Class names:  ['brant', 'jabwar', 'sheowl', 'spodov', 'wiltur']\n",
      "Training   dataset length: 419\n",
      "Validation dataset length: 99\n",
      "Test       dataset length: 6\n"
     ]
    }
   ],
   "source": [
    "# create the dataset\n",
    "train_ds, val_ds, test_ds, class_names = create_datasets(AUDIO_DATA_DIRECTORY,train_split=0.8, val_split=0.19)\n",
    "print(\"Class names: \", class_names)\n",
    "print(f\"Training   dataset length: {len(train_ds)}\")\n",
    "print(f\"Validation dataset length: {len(val_ds)}\")\n",
    "print(f\"Test       dataset length: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'd:\\\\data\\\\bc\\\\sheowl\\\\XC666501.ogg'>, <tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 0., 1., 0., 0.], dtype=float32)>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'd:\\\\data\\\\bc\\\\wiltur\\\\XC317966.ogg'>, <tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 0., 0., 0., 1.], dtype=float32)>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'd:\\\\data\\\\bc\\\\wiltur\\\\XC618595.ogg'>, <tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 0., 0., 0., 1.], dtype=float32)>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'd:\\\\data\\\\bc\\\\brant\\\\XC540354.ogg'>, <tf.Tensor: shape=(5,), dtype=float32, numpy=array([1., 0., 0., 0., 0.], dtype=float32)>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'd:\\\\data\\\\bc\\\\sheowl\\\\XC295378.ogg'>, <tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 0., 1., 0., 0.], dtype=float32)>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'd:\\\\data\\\\bc\\\\spodov\\\\XC443310.ogg'>, <tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 0., 0., 1., 0.], dtype=float32)>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'd:\\\\data\\\\bc\\\\sheowl\\\\XC607790.ogg'>, <tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 0., 1., 0., 0.], dtype=float32)>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'd:\\\\data\\\\bc\\\\spodov\\\\XC443311.ogg'>, <tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 0., 0., 1., 0.], dtype=float32)>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'd:\\\\data\\\\bc\\\\spodov\\\\XC491970.ogg'>, <tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 0., 0., 1., 0.], dtype=float32)>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'd:\\\\data\\\\bc\\\\spodov\\\\XC124409.ogg'>, <tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 0., 0., 1., 0.], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "# show what the pipeline looks like at this stage\n",
    "for item in train_ds.take(10):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_random_subsection(path, duration_secs):\n",
    "\n",
    "    # read the file data\n",
    "    file_contents=tf.io.read_file(path)\n",
    "\n",
    "    try:\n",
    "        tmp_audio_t = tfio.audio.decode_flac(input=file_contents)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        tmp_audio_t = tfio.audio.decode_vorbis(input=file_contents)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #print(tmp_audio_t)\n",
    "\n",
    "    # cast and keep left channel only\n",
    "    tmp_audio_t = tf.cast(tmp_audio_t, tf.float32)[:,-1]\n",
    "    \n",
    "    #print(tmp_audio_t.shape)\n",
    "\n",
    "    # resample the sample rate\n",
    "    tmp_audio_t = tfio.audio.resample(tmp_audio_t, tfio.audio.AudioIOTensor(path)._rate.numpy(), AUDIO_SAMPLE_RATE)\n",
    "\n",
    "    # Determine the audio file's duration in seconds\n",
    "    audio_duration_secs = tf.shape(tmp_audio_t)[0] / AUDIO_SAMPLE_RATE\n",
    "    \n",
    "    if audio_duration_secs>duration_secs:\n",
    "    \n",
    "        # print(f'duration {audio_duration_secs} {duration_secs}')\n",
    "\n",
    "        # Calculate the starting point of the 5-second subsection\n",
    "        max_start = tf.cast(audio_duration_secs - duration_secs, tf.float32)\n",
    "        start_time_secs = tf.random.uniform((), 0.0, max_start, dtype=tf.float32)\n",
    "        \n",
    "        #print(f'start_time_secs {start_time_secs} max_start_time {max_start}')\n",
    "\n",
    "        start_index = tf.cast(start_time_secs * AUDIO_SAMPLE_RATE, dtype=tf.int32)\n",
    "        #print(f'start_index {start_index}')\n",
    "\n",
    "        # Load the 5-second subsection\n",
    "        end_index = tf.cast(start_index + tf.cast(duration_secs, tf.int32) * AUDIO_SAMPLE_RATE, tf.int32)\n",
    "        \n",
    "        #print(f'end_index {start_index}')\n",
    "        \n",
    "        subsection = tmp_audio_t[start_index : end_index]\n",
    "    \n",
    "    else:\n",
    "        # print(f' padding it ')\n",
    "        # Pad the subsection with silence if it's shorter than 5 seconds\n",
    "        padding_length = duration_secs * AUDIO_SAMPLE_RATE - tf.shape(tmp_audio_t)[0]\n",
    "        padding = tf.zeros([padding_length], dtype=tmp_audio_t.dtype)\n",
    "        subsection = tf.concat([tmp_audio_t, padding], axis=0)\n",
    "\n",
    "    # print(f'subsection {subsection.shape}')\n",
    "\n",
    "    return subsection\n",
    "\n",
    "clip = load_random_subsection('d:\\\\data\\\\bc\\\\spodov\\\\XC441823.ogg', duration_secs=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_example_implementation(path, label, variant):\n",
    "    \n",
    "    print(f'processing path {path} variant {variant}')\n",
    "    \n",
    "    tmp_audio_t = load_random_subsection(path, duration_secs=5)\n",
    "    \n",
    "    # print(f'tmp_audio_t shape {tmp_audio_t}')\n",
    "        \n",
    "    # Convert to spectrogram\n",
    "    image = tfio.audio.spectrogram(\n",
    "        tmp_audio_t,\n",
    "        nfft=AUDIO_NFFT, \n",
    "        window=AUDIO_WINDOW, \n",
    "        stride=AUDIO_STRIDE)\n",
    "    \n",
    "    # Convert to melspectrogram\n",
    "    image = tfio.audio.melscale(\n",
    "        image, \n",
    "        rate=AUDIO_SAMPLE_RATE, \n",
    "        mels=AUDIO_MELS, \n",
    "        fmin=AUDIO_FMIN, \n",
    "        fmax=AUDIO_FMAX)\n",
    "    \n",
    "    # print(f'image shape {image.shape}')\n",
    "\n",
    "    # reshape into standard 3 channels to add the color channel\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    \n",
    "    # most pre-trained model expect 3 color channels\n",
    "    image = tf.repeat(image, MODEL_INPUT_IMAGE_CHANNELS, axis=2)\n",
    "    \n",
    "    # print(f'image shape {image.shape}')\n",
    "    \n",
    "    image = tf.ensure_shape(image, [216, 128, MODEL_INPUT_IMAGE_CHANNELS])\n",
    "    image = tf.image.resize(image, (MODEL_INPUT_IMAGE_WIDTH,MODEL_INPUT_IMAGE_HEIGHT), \n",
    "                            method=tf.image.ResizeMethod.LANCZOS5)\n",
    "\n",
    "    # rescale to range [0,1]\n",
    "    image = image - tf.reduce_min(image) \n",
    "    image = image / (tf.reduce_max(image)+0.00001)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "def dataset_example_pipeline(path, label):\n",
    "    #return dataset_example_implementation(path, label)\n",
    "    variant = random.randrange(0,SAMPLE_VARIANTS)\n",
    "    return execute_cached_function(dataset_example_implementation,path,label,variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will allow python execution within the tensorflow pipeline\n",
    "def dataset_example_pipeline_wrapper(path, label):\n",
    "    # Use a lambda function to pass two arguments to the dataset_example_pipeline function\n",
    "    image, label = tf.py_function(func=lambda x, y: dataset_example_pipeline(x, y), inp=(path, label), Tout=(tf.float32, label.dtype))\n",
    "\n",
    "    # Set the shape of the output tensors manually\n",
    "    image.set_shape([MODEL_INPUT_IMAGE_WIDTH, MODEL_INPUT_IMAGE_HEIGHT, MODEL_INPUT_IMAGE_CHANNELS])\n",
    "    label.set_shape([len(class_names),])  # Set the shape of the label tensor\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "# create the datasets useful for training a classification model\n",
    "########################################################################################\n",
    "train_dataset = (train_ds\n",
    "                 .map(dataset_example_pipeline_wrapper)\n",
    "                 .batch(CLASSIFIER_BATCH_SIZE)          \n",
    ")\n",
    "\n",
    "validation_dataset = (val_ds\n",
    "                      .map(dataset_example_pipeline_wrapper)\n",
    "                      .batch(CLASSIFIER_BATCH_SIZE)\n",
    ")\n",
    "\n",
    "test_dataset = (test_ds\n",
    "                .map(dataset_example_pipeline_wrapper)\n",
    "                .batch(CLASSIFIER_BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing path b'd:\\\\data\\\\bc\\\\sheowl\\\\XC431869.ogg' variant 16\n",
      "New result calculated and stored in cache key: eb6aff98252bbc914955c6d83c2d054ba1af8188ea35ba721888a182099bf79d\n",
      "processing path b'd:\\\\data\\\\bc\\\\jabwar\\\\XC282183.ogg' variant 14\n",
      "New result calculated and stored in cache key: 7a48f5bce9e8310209ef3a3d77b60577afd3331d7e7fcfae20cba73499eaaa78\n",
      "processing path b'd:\\\\data\\\\bc\\\\wiltur\\\\XC138164.ogg' variant 1\n",
      "New result calculated and stored in cache key: 325550a42ee8e26eac2d28f52ef98a7edfeb0d41c47554f4daa1db29cc50c5ed\n",
      "processing path b'd:\\\\data\\\\bc\\\\jabwar\\\\XC536947.ogg' variant 0\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x00000136298EE940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "New result calculated and stored in cache key: 146d8760fbfeb877cd26d2307016f8865c3d9186ce0ae7faf6a2bedd316b0823\n",
      "processing path b'd:\\\\data\\\\bc\\\\spodov\\\\XC260139.ogg' variant 5\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x00000136298EE790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "New result calculated and stored in cache key: 864a4957620ce1c6fd174f40315521420369716ed3734cbed4aa81cb38132191\n",
      "processing path b'd:\\\\data\\\\bc\\\\brant\\\\XC526264.ogg' variant 15\n",
      "New result calculated and stored in cache key: eafd5fe19f8df39b6623bdcce7cffc892bd66c9b0e235a06882978ee2ef92125\n",
      "processing path b'd:\\\\data\\\\bc\\\\brant\\\\XC508454.ogg' variant 15\n",
      "New result calculated and stored in cache key: ebdfbb39b25a3fe6a214e1fcaf305fa1b8ebddb12374083da5cae0568e4c62c3\n",
      "processing path b'd:\\\\data\\\\bc\\\\sheowl\\\\XC582788.ogg' variant 12\n",
      "New result calculated and stored in cache key: 3412cbc0eeba075e12bcae7da32b371f9a9b2f0a9f626f3c7e98576dc196ceb5\n",
      "processing path b'd:\\\\data\\\\bc\\\\wiltur\\\\XC598621.ogg' variant 8\n",
      "New result calculated and stored in cache key: 4bc715c4b0bdd82d48de31bfb73a87a7aae4a1c89eb3b56607fbae78c224f84d\n",
      "processing path b'd:\\\\data\\\\bc\\\\jabwar\\\\XC385100.ogg' variant 11\n",
      "New result calculated and stored in cache key: b662ceaf1a28cae666fb9480161e1359f0219e5375609b810e8b361d1ddaed02\n",
      "processing path b'd:\\\\data\\\\bc\\\\spodov\\\\XC190962.ogg' variant 5\n",
      "New result calculated and stored in cache key: 77304350d091153a2934d355a6e5b3f874e1f16a5c45783604aa7ccdc8483377\n",
      "processing path b'd:\\\\data\\\\bc\\\\brant\\\\XC349592.ogg' variant 3\n",
      "New result calculated and stored in cache key: fe14f29fb9413a522581ba9e288a7feff88a9392eb6c4c684a2c5eb0e8079c4c\n",
      "processing path b'd:\\\\data\\\\bc\\\\sheowl\\\\XC338389.ogg' variant 5\n",
      "New result calculated and stored in cache key: b05a5ad24bff0f52e585cce1c3b1f560578f5cdaee8cc3d952efcfa698077ab2\n",
      "processing path b'd:\\\\data\\\\bc\\\\spodov\\\\XC607186.ogg' variant 10\n",
      "New result calculated and stored in cache key: 5ecfcd26d0ed0a0d89f6f75e05b545034665d72b897732a85ab20b08e1edd89c\n",
      "processing path b'd:\\\\data\\\\bc\\\\jabwar\\\\XC385099.ogg' variant 7\n",
      "New result calculated and stored in cache key: f13aadff280b671ceda80fc6b3368fc54c664a18b438d0d7d61e4a6d25689413\n",
      "processing path b'd:\\\\data\\\\bc\\\\sheowl\\\\XC474679.ogg' variant 5\n",
      "New result calculated and stored in cache key: b2f93e7cade0a290db11baa072b1c3b5999a9b4021f79c454209bda12629add7\n",
      "processing path b'd:\\\\data\\\\bc\\\\wiltur\\\\XC433074.ogg' variant 18\n",
      "New result calculated and stored in cache key: 5adf8781fe9f1528332b432ff1c73d8442f7af6cd8db11b18d6f8324bd0451d1\n",
      "processing path b'd:\\\\data\\\\bc\\\\jabwar\\\\XC235544.ogg' variant 15\n",
      "New result calculated and stored in cache key: 86083f45d6077efd30739ec9ea6264c3b10a180c66e73cdbd0d7452be84d3a61\n",
      "processing path b'd:\\\\data\\\\bc\\\\brant\\\\XC500404.ogg' variant 16\n",
      "New result calculated and stored in cache key: f3b0b7246f4b217d940ead27513d781cbdebf28f1eb71af942a07d4784bfcc10\n",
      "processing path b'd:\\\\data\\\\bc\\\\sheowl\\\\XC474682.ogg' variant 1\n",
      "New result calculated and stored in cache key: 466c42e19d030bb53b550970e7247bd5d824a5c1351cb08062b52d29c0f44c14\n",
      "processing path b'd:\\\\data\\\\bc\\\\sheowl\\\\XC666502.ogg' variant 16\n",
      "New result calculated and stored in cache key: ba8ad9ca3f2367ea1f93b0abeac9c5a95dacad3338a6eedea3ef95a05b0b94bf\n",
      "processing path b'd:\\\\data\\\\bc\\\\sheowl\\\\XC522576.ogg' variant 14\n",
      "New result calculated and stored in cache key: a61e7f712e2a54dd129049785e64393a4639d4c9a758782360425df31c92ad8a\n",
      "processing path b'd:\\\\data\\\\bc\\\\spodov\\\\XC304101.ogg' variant 9\n",
      "New result calculated and stored in cache key: 87c1eb12b7d2012b59bb5114d1e91d47165f7ebaf6656ffc48932aed8314713a\n",
      "processing path b'd:\\\\data\\\\bc\\\\brant\\\\XC353619.ogg' variant 14\n",
      "New result calculated and stored in cache key: 6d061ef267765286d2b2c47a450ac593ecfe76d9870197bafe50994dd8b18046\n",
      "processing path b'd:\\\\data\\\\bc\\\\spodov\\\\XC443312.ogg' variant 9\n",
      "New result calculated and stored in cache key: 3a4412968f0a04a186b6c7f152f965a7d10d0e03fae37f1062354b69dd8e9a5c\n",
      "processing path b'd:\\\\data\\\\bc\\\\sheowl\\\\XC139414.ogg' variant 1\n",
      "New result calculated and stored in cache key: 21692a733b7538e17714ddccfc6565dabfa6367126df3ae071e26a9a112e30a4\n",
      "processing path b'd:\\\\data\\\\bc\\\\wiltur\\\\XC283329.ogg' variant 16\n",
      "New result calculated and stored in cache key: 396ed708244ed185ea89797aba22900f12675ef5a2bbe8b8d974134ca3ab7da9\n",
      "processing path b'd:\\\\data\\\\bc\\\\spodov\\\\XC401213.ogg' variant 19\n",
      "New result calculated and stored in cache key: 28ee52de0a10ea200bff5c92481275ac455736c528bb6887860329f7d206a8b5\n",
      "processing path b'd:\\\\data\\\\bc\\\\spodov\\\\XC484953.ogg' variant 3\n",
      "New result calculated and stored in cache key: c3ca45cfc8a9f8ffa4a16038de50596bf1429c377ae99b60c4d7ac08307d121e\n",
      "processing path b'd:\\\\data\\\\bc\\\\spodov\\\\XC291105.ogg' variant 17\n",
      "New result calculated and stored in cache key: 6257e896c0f35219f633b24f09021857447beef7646fa77f33a21f978fc4a1f2\n",
      "processing path b'd:\\\\data\\\\bc\\\\wiltur\\\\XC451611.ogg' variant 7\n",
      "New result calculated and stored in cache key: a43d6ba8dda669f43177446071e157ac59ec49919b2f5a36999569e85abfa140\n",
      "processing path b'd:\\\\data\\\\bc\\\\sheowl\\\\XC637496.ogg' variant 16\n",
      "New result calculated and stored in cache key: 4d09b24aa160f44b260bf86c4d983ddf3991185f32c894e02d6a964ac621968d\n",
      " sample info: (32, 256, 256, 3), [[0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]]\n",
      "processing path b'd:\\\\data\\\\bc\\\\spodov\\\\XC181467.ogg' variant 7\n",
      "New result calculated and stored in cache key: 9672782831f195d972433e2027869b3499651213d2c37505ede9112b0ec84e27\n"
     ]
    }
   ],
   "source": [
    "# show what the pipeline looks like at this stage\n",
    "for melspectrogram,label in train_dataset.take(1):\n",
    "    print(f' sample info: {melspectrogram.shape}, {label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(trainable):\n",
    "    # build a really simple classification model using a pre-training Efficientnet V2\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            # input layer\n",
    "            tf.keras.layers.InputLayer(input_shape=(MODEL_INPUT_IMAGE_HEIGHT, MODEL_INPUT_IMAGE_WIDTH,3)),\n",
    "  \n",
    "            # use the model as a feature generator only\n",
    "            # use pre-trained mobilenet v2 as the feature layer (less parameters, more accessible)\n",
    "            # hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\", trainable),  \n",
    "            \n",
    "            hub.KerasLayer(\"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b1/feature_vector/2\", trainable), \n",
    "            \n",
    "            # much larger model to see if more parameters matters...\n",
    "            #hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_152/feature_vector/5\", trainable),  \n",
    "                        \n",
    "            # add the classification layer here       \n",
    "            tf.keras.layers.Flatten(), \n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            \n",
    "            tf.keras.layers.Dense(len(class_names)*3, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L1(1e-2)),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            \n",
    "            tf.keras.layers.Dense(len(class_names)*2, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L1(1e-2)),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            \n",
    "            tf.keras.layers.Dropout(0.50),\n",
    "            tf.keras.layers.Dense(len(class_names)*1, activation=None),\n",
    "        ]\n",
    "    )\n",
    "    # need to tell the model what the input shape is\n",
    "    model.build([None, \n",
    "                 MODEL_INPUT_IMAGE_HEIGHT,\n",
    "                 MODEL_INPUT_IMAGE_WIDTH, \n",
    "                 MODEL_INPUT_IMAGE_CHANNELS])\n",
    "\n",
    "    # show the model\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 1280)              6931124   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1280)              0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1280)             5120      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 15)                19215     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 15)               60        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                160       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,955,774\n",
      "Trainable params: 6,882,092\n",
      "Non-trainable params: 73,682\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "processing path b'd:\\\\data\\\\bc\\\\wiltur\\\\XC315999.ogg' variant 7\n",
      "New result calculated and stored in cache key: a76a1aa298eeccfca5911b638430ee1655eaddab0a5706d74f11080c81e303d7\n",
      "processing path b'd:\\\\data\\\\bc\\\\spodov\\\\XC347681.ogg' variant 16\n",
      "New result calculated and stored in cache key: ad0b9c177498ea99c30626cb0c196925e9ffec646c178404b76e4f2e5a912a7a\n",
      "processing path b'd:\\\\data\\\\bc\\\\wiltur\\\\XC578133.ogg' variant 8\n",
      "New result calculated and stored in cache key: da7f5e9764dc963f2b46f2b523cf9290922193ac96c6948ab2699c02ba403eaf\n",
      "processing path b'd:\\\\data\\\\bc\\\\brant\\\\XC588758.ogg' variant 2\n",
      "New result calculated and stored in cache key: 4fd3502136e68cc9a781b16125456f2a5fa9a10592ca4741d646240451f8f575\n",
      "processing path b'd:\\\\data\\\\bc\\\\spodov\\\\XC304101.ogg' variant 15\n",
      "New result calculated and stored in cache key: 4bb5f66be0baafeb476ed49adbc9be2cd1b1cce343d58b5d446a810838c436d6\n",
      "processing path b'd:\\\\data\\\\bc\\\\wiltur\\\\XC614092.ogg' variant 4\n",
      "New result calculated and stored in cache key: 2e000399354f492776639231682a136ef69ef30ba03d1569721bcd5719941c35\n",
      "processing path b'd:\\\\data\\\\bc\\\\brant\\\\XC149312.ogg' variant 2\n",
      "New result calculated and stored in cache key: b81aad459595943f75975a2e6b7b994081cfd5e937ac88331ca720c597b5a5b6\n",
      "processing path b'd:\\\\data\\\\bc\\\\brant\\\\XC600218.ogg' variant 2\n",
      "New result calculated and stored in cache key: 581cd5791c72feb1221c0411513f48c07f1f8f5dfaf00b863c117774417303c5\n",
      "processing path b'd:\\\\data\\\\bc\\\\wiltur\\\\XC586576.ogg' variant 18\n",
      "New result calculated and stored in cache key: 9021e272b71fc59e82a646978c4adbf6ee52dc569ca9bd23d834e56fd25f3afa\n",
      "processing path b'd:\\\\data\\\\bc\\\\wiltur\\\\XC17140.ogg' variant 14\n",
      "New result calculated and stored in cache key: aab734079fb497e123a25ce17e8e6bf5ad7d60929ccb07d8209af4de241b8178\n",
      "processing path b'd:\\\\data\\\\bc\\\\spodov\\\\XC157874.ogg' variant 14\n",
      "New result calculated and stored in cache key: 0f98b005c3837b9630a22027ee81ae9ceacdfb152bb216af9e7f7b923797690a\n",
      "processing path b'd:\\\\data\\\\bc\\\\sheowl\\\\XC661805.ogg' variant 13\n",
      "New result calculated and stored in cache key: 035cd7787a36a90bcd4f327725b744ed0e509da169b5fb08cd2f8f3e49bca731\n",
      "processing path b'd:\\\\data\\\\bc\\\\sheowl\\\\XC607792.ogg' variant 7\n",
      "New result calculated and stored in cache key: 8507216836483517ecf28b3debfe5e660cb4d19b836e6ce157f76020c5a6949c\n",
      "processing path b'd:\\\\data\\\\bc\\\\spodov\\\\XC267346.ogg' variant 11\n",
      "New result calculated and stored in cache key: 2289dbd5c8c6173aaeac1c2ba2471654ce027784383f73053bb187fed15a967f\n",
      "processing path b'd:\\\\data\\\\bc\\\\sheowl\\\\XC608383.ogg' variant 19\n",
      "New result calculated and stored in cache key: 9cd2407a5ce8cdae5bb4fe69b6a3080400b6bc65190f1c6910ae0acb57cb7630\n",
      "processing path b'd:\\\\data\\\\bc\\\\wiltur\\\\XC30895.ogg' variant 9\n",
      "New result calculated and stored in cache key: 29cb23fc1c85d4352029afa87bd96992b61f3c3f45d6efa0dbc0643787644bcd\n",
      "processing path b'd:\\\\data\\\\bc\\\\sheowl\\\\XC614003.ogg' variant 17\n",
      "New result calculated and stored in cache key: f5a9c82a3c3392f8aa5fba35735b1d54fe7e8b8332f1bce1096ac803c6a3f301\n",
      "processing path b'd:\\\\data\\\\bc\\\\jabwar\\\\XC41397.ogg' variant 2\n",
      "New result calculated and stored in cache key: 96f8a6f21990b62c3282e968e62098ac12af374ef40e92b77d253193e365bc28\n",
      "processing path b'd:\\\\data\\\\bc\\\\brant\\\\XC613307.ogg' variant 1\n",
      "New result calculated and stored in cache key: 604cbfc2825406b46d2cfe274fb1de13c63c22f31a8b63e5ddbd6fc82375ba14\n",
      "processing path b'd:\\\\data\\\\bc\\\\jabwar\\\\XC332819.ogg' variant 5\n",
      "New result calculated and stored in cache key: 9a1ec6b88f9cbb470a7aff5c3f2e1e76a95d697acdf6a2d83d9a9d412e12fd2a\n",
      "processing path b'd:\\\\data\\\\bc\\\\sheowl\\\\XC661817.ogg' variant 13\n",
      "New result calculated and stored in cache key: 30c3bd1df8264e768cb3918c7da8dcba1ddb9c49f9cbd486ff2ee2a66ec3e074\n",
      "processing path b'd:\\\\data\\\\bc\\\\sheowl\\\\XC142829.ogg' variant 11\n",
      "New result calculated and stored in cache key: 4d555ef11cbc21989a32598cc3e8f012c4c8364d09ec8e1ef5a5334e89ea7886\n",
      "processing path b'd:\\\\data\\\\bc\\\\brant\\\\XC382144.ogg' variant 11\n",
      "New result calculated and stored in cache key: e101651f74b4470914dc317db30acc4f76c71638e83a8f4e866e89571f963d78\n",
      "processing path b'd:\\\\data\\\\bc\\\\wiltur\\\\XC334314.ogg' variant 3\n",
      "New result calculated and stored in cache key: bbfed961859af732a11754578a27c6d144e143bf968c6fefba63da4b3fbcb26e\n",
      "processing path b'd:\\\\data\\\\bc\\\\spodov\\\\XC616498.ogg' variant 19\n",
      "New result calculated and stored in cache key: 4dfe5164e676bcdcb99856cae58f09b11b7b764ae341550b55a72f9c1dd5a5e6\n",
      "processing path b'd:\\\\data\\\\bc\\\\jabwar\\\\XC282183.ogg' variant 13\n",
      "New result calculated and stored in cache key: cb0b324c41b10cc4b85b881e8088224937039943cfaa84f009e2a64222227317\n",
      "processing path b'd:\\\\data\\\\bc\\\\sheowl\\\\XC318984.ogg' variant 19\n",
      "New result calculated and stored in cache key: b4eaec80bd9dd2a11dfa9d723b6988fcedd694f836d306ae89da09ae69db362c\n",
      "processing path b'd:\\\\data\\\\bc\\\\brant\\\\XC441013.ogg' variant 19\n",
      "New result calculated and stored in cache key: 9ca1c759eae3965adb7f2b3de9065eef34e0eefec2d42f1ef161093f72070e88\n",
      "processing path b'd:\\\\data\\\\bc\\\\wiltur\\\\XC138067.ogg' variant 18\n",
      "New result calculated and stored in cache key: 25bfee6ecbf1502521b6d58d0764d76bac76aba70d41bcbc1f9b7a455f576773\n",
      "processing path b'd:\\\\data\\\\bc\\\\sheowl\\\\XC217336.ogg' variant 11\n",
      "New result calculated and stored in cache key: eca5c4e9622bf049d3273e947c10fd2ed22b6279ba297dbaaab38125a68e8f74\n",
      "processing path b'd:\\\\data\\\\bc\\\\brant\\\\XC604124.ogg' variant 16\n",
      "New result calculated and stored in cache key: 3548607fb0a742e788b16dcaef332af45b51d2cff9e47367903750485095182a\n",
      "processing path b'd:\\\\data\\\\bc\\\\sheowl\\\\XC142830.ogg' variant 0\n",
      "New result calculated and stored in cache key: 5bc4d5448cd1be01a74257107ea51f4f48de4db67cb8ac8936c1ecef0b7350c9\n",
      "processing path b'd:\\\\data\\\\bc\\\\sheowl\\\\XC664628.ogg' variant 8\n",
      "New result calculated and stored in cache key: 5113d5e099beab7ff4f66134ef06e1476bbedb504c556c20fb31fea7bb8b48c2\n",
      "processing path b'd:\\\\data\\\\bc\\\\wiltur\\\\XC465131.ogg' variant 16\n",
      "New result calculated and stored in cache key: 046ad9f6c36b2734b221c9112df838d28f25e69a756aa66f8a8ad8e8dcad1b5d\n",
      "processing path b'd:\\\\data\\\\bc\\\\jabwar\\\\XC191038.ogg' variant 2\n",
      " 1/14 [=>............................] - ETA: 7:58 - loss: 9.5291 - accuracy: 0.0625New result calculated and stored in cache key: 2503889b64fdb336dff369b97612dc763cca3966505baa385e081cd36b6df1be\n",
      "processing path b'd:\\\\data\\\\bc\\\\sheowl\\\\XC474679.ogg' variant 12\n",
      "New result calculated and stored in cache key: 5f2c92a572b3239d4ff390ed6008aa8366135f3c1f8cd5615d6643c26394ea20\n",
      "processing path b'd:\\\\data\\\\bc\\\\sheowl\\\\XC295378.ogg' variant 4\n",
      "New result calculated and stored in cache key: fc764624a8d5c66bf3c86f940b3d01811fb5c31402a84171e9f7f0fe8fafe504\n",
      "processing path b'd:\\\\data\\\\bc\\\\jabwar\\\\XC191037.ogg' variant 12\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('models/'):\n",
    "    os.mkdir('models/')\n",
    "    \n",
    "# allow all the weights to be trained\n",
    "model = build_model(True)\n",
    "\n",
    "# the form_logits means the loss function has the 'softmax' buillt in.  This approach is numerically more stable\n",
    "# than including the softmax activation on the last layer of the classifier\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3), \n",
    "              metrics=[\"accuracy\"],\n",
    "              )\n",
    "\n",
    "# tensorboard for visualisation of results\n",
    "log_dir = \"tensorboard_logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, \n",
    "                                                      histogram_freq=1)\n",
    "\n",
    "# reduce learning rate to avoid overshooting local minima\n",
    "lr_reduce_plateau = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                                      factor=0.5,\n",
    "                                                      patience=4, \n",
    "                                                      verbose=1,\n",
    "                                                      mode='min',\n",
    "                                                      cooldown=0, \n",
    "                                                      min_lr=1e-8)\n",
    "\n",
    "# end the training if no improvement for 16 epochs in a row, then restore best model weights\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=8,\n",
    "    verbose=0,\n",
    "    mode=\"min\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "# save the best model as it trains..\n",
    "mcp_save = tf.keras.callbacks.ModelCheckpoint('models/checkpoint_cnn_model.hdf5', \n",
    "                                           save_best_only=True, \n",
    "                                           monitor='val_loss', \n",
    "                                           mode='min')\n",
    "\n",
    "# fit the model to the training set\n",
    "model.fit(train_dataset, \n",
    "          validation_data=validation_dataset,\n",
    "          callbacks=[lr_reduce_plateau, early_stopping, tensorboard_callback, mcp_save],\n",
    "          epochs=1000)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model weights\n",
    "model.save_weights('models/baseline_cnn_model.hdf5', save_format='h5')\n",
    "\n",
    "# test load the model for inference\n",
    "test_model = build_model(False)\n",
    "test_model.build([None, \n",
    "                MODEL_INPUT_IMAGE_HEIGHT,\n",
    "                MODEL_INPUT_IMAGE_WIDTH, \n",
    "                MODEL_INPUT_IMAGE_CHANNELS])\n",
    "test_model.load_weights('models/baseline_cnn_model.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
