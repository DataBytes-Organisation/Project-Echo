{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Documentation\n",
    "\n",
    "#### Overview:\n",
    "This script provides functionality for sound event detection, specifically aimed at identifying segments within an audio file that potentially contain animal-related sounds. The script uses a pre-trained `YAMNet` model to perform this detection and further refines the results with another pre-trained model (2-3chunk).\n",
    "### Author: Rohit Dhanda \n",
    "---\n",
    "\n",
    "#### Imports:\n",
    "- **pickle**: For loading serialized class names and label encoder objects.\n",
    "- **numpy, pandas**: For numerical and data manipulation.\n",
    "- **soundfile**: To handle audio file I/O.\n",
    "- **yamnet**: To access the YAMNet model and its parameters.\n",
    "- **librosa**: For audio processing tasks.\n",
    "- **tensorflow.keras**: To load the deep learning model.\n",
    "- **tempfile**: To create temporary files.\n",
    "- **tensorflow_hub**: To access TensorFlow Hub models.\n",
    "\n",
    "---\n",
    "\n",
    "#### Global Variables and Model Initialization:\n",
    "1. **class_names.pkl**: A serialized list of class names.\n",
    "2. **label_encoder.pkl**: A serialized label encoder which can convert class names to integers and vice versa.\n",
    "3. **yamnet.h5**: Weights for the YAMNet model.\n",
    "4. **model_3_78_48000.h5**: Pre-trained Keras model for sound classification.\n",
    "\n",
    "---\n",
    "\n",
    "#### Functions:\n",
    "\n",
    "1. **load_audio_file(file_path)**:\n",
    "    - **Input**: Path to the audio file.\n",
    "    - **Output**: An array of audio data samples.\n",
    "    - **Purpose**: Loads the audio file using librosa with a sampling rate of 48000 Hz.\n",
    "\n",
    "2. **extract_features(model, X)**:\n",
    "    - **Input**: A model and an array X containing audio data samples.\n",
    "    - **Output**: Extracted feature array.\n",
    "    - **Purpose**: For each audio sample in X, embeddings are extracted using the given model. The mean of the embeddings is then computed to get a feature vector.\n",
    "\n",
    "3. **predict_on_audio(binary_audio)**:\n",
    "    - **Input**: A binary audio data.\n",
    "    - **Output**: Top two class predictions and their associated probabilities.\n",
    "    - **Purpose**: To make predictions on the given audio data using the pre-trained model.\n",
    "\n",
    "4. **sound_event_detection(filepath)**:\n",
    "    - **Input**: Path to an audio file.\n",
    "    - **Output**: A pandas DataFrame containing segments of the audio where animal-related sounds were detected. Each row of the DataFrame represents a segment and contains the start time, end time, predicted class labels, and their associated confidences.\n",
    "    - **Purpose**: The main function to detect animal-related sounds in an audio file. The function first divides the audio into 1-second chunks, detects potential animal sounds in each chunk using the YAMNet model, and then refines the results using another model. Detected segments are then combined and returned as a DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "#### Usage:\n",
    "At the end of the script, an example usage is provided using the file 'test9.m4a'. The `sound_event_detection` function is called with this file, and the results are printed to the console.\n",
    "\n",
    "---\n",
    "\n",
    "**Note**: It's essential to ensure all the necessary files and weights are available in the respective directories as mentioned in the script before running it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "   start_time  end_time      echonet_label_1  echonet_confidence_1  \\\n",
      "0           0         3          Felis catus              0.999516   \n",
      "1           4         5          Felis catus              1.000000   \n",
      "2           6         8          Felis catus              0.999991   \n",
      "3          11        12  Uperoleia laevigata              0.721224   \n",
      "4          15        17         Capra hircus              0.998273   \n",
      "\n",
      "          echonet_label_2  echonet_confidence_2  \n",
      "0       Canis lupus dingo          4.835153e-04  \n",
      "1       Canis lupus dingo          1.608894e-09  \n",
      "2  Menura novaehollandiae          6.932215e-06  \n",
      "3           Anas gracilis          2.277969e-01  \n",
      "4           Anas gracilis          1.726876e-03  \n",
      "2.13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:184: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "\n",
    "import librosa\n",
    "\n",
    "import tempfile\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"yamnet_dir/\")\n",
    "# yamnet related imports\n",
    "from yamnet_dir import params as params\n",
    "from yamnet_dir import yamnet as yamnet_model\n",
    "\n",
    "\n",
    "# Load the necessary data and models\n",
    "with open('yamnet_dir/class_names.pkl', 'rb') as f:\n",
    "    class_names = pickle.load(f)\n",
    "\n",
    "with open('yamnet_dir/label_encoder.pkl', 'rb') as f:\n",
    "    le = pickle.load(f)\n",
    "\n",
    "yamnet = yamnet_model.yamnet_frames_model(params)\n",
    "yamnet.load_weights('yamnet_dir/yamnet.h5')\n",
    "yamnet_classes = yamnet_model.class_names('yamnet_dir/yamnet_class_map.csv')\n",
    "model = load_model('yamnet_dir/model_3_82_16000.h5')\n",
    "\n",
    "# Load the YAMNet model\n",
    "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
    "yamnet_model = hub.load(yamnet_model_handle)\n",
    "\n",
    "def load_audio_file(file_path):\n",
    "    wav, sr = librosa.load(file_path, sr=16000)\n",
    "    return np.array([wav])\n",
    "\n",
    "def extract_features(model, X):\n",
    "    features = []\n",
    "    for wav in X:\n",
    "        scores, embeddings, spectrogram = model(wav)\n",
    "        features.append(embeddings.numpy().mean(axis=0))\n",
    "    return np.array(features)\n",
    "\n",
    "def predict_on_audio(binary_audio):\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_audio_file:\n",
    "        with open(temp_audio_file.name, 'wb') as f:\n",
    "            f.write(binary_audio)\n",
    "        X_new = load_audio_file(temp_audio_file.name)\n",
    "        X_new_features = extract_features(yamnet_model, X_new)\n",
    "\n",
    "        predictions = model.predict(X_new_features)\n",
    "        top_two_prob_indices = np.argsort(predictions[0])[-2:]\n",
    "        top_two_prob_values = predictions[0][top_two_prob_indices]\n",
    "\n",
    "        top_two_class_names = le.inverse_transform(top_two_prob_indices)\n",
    "        \n",
    "        return [(class_names[top_two_prob_indices[1-i]], top_two_prob_values[1-i]) for i in range(2)]\n",
    "\n",
    "def sound_event_detection(filepath):\n",
    "    data, sr = librosa.load(filepath, sr=16000)\n",
    "    frame_len = int(sr * 1)\n",
    "    num_chunks = len(data) // frame_len\n",
    "    chunks = [data[i*frame_len:(i+1)*frame_len] for i in range(num_chunks)]\n",
    "\n",
    "    # Adding the last chunk which can be less than 1 second\n",
    "    last_chunk = data[num_chunks*frame_len:]\n",
    "    if len(last_chunk) > 0:\n",
    "        chunks.append(last_chunk)\n",
    "\n",
    "    animal_related_classes = [\n",
    "        'Dog', 'Cat', 'Bird', 'Animal', 'Birdsong', 'Canidae', 'Feline', 'Livestock',\n",
    "        'Rodents, Mice', 'Wild animals', 'Pets', 'Frogs', 'Insect', 'Snake', \n",
    "        'Domestic animals, pets', 'crow'\n",
    "    ]\n",
    "\n",
    "    df_rows = []\n",
    "    buffer = []\n",
    "    start_time = None\n",
    "    for cnt, frame_data in enumerate(chunks):\n",
    "        frame_data = np.reshape(frame_data, (-1,)) # Flatten the array to 1D\n",
    "        frame_data = np.array([frame_data]) # Wrapping it back into a 2D array\n",
    "        outputs = yamnet(frame_data)\n",
    "        yamnet_prediction = np.mean(outputs[0], axis=0)\n",
    "        top2_i = np.argsort(yamnet_prediction)[::-1][:2]\n",
    "        threshold=0.2\n",
    "        if any(yamnet_prediction[np.where(yamnet_classes == cls)[0][0]] >= threshold for cls in animal_related_classes if cls in yamnet_classes):\n",
    "            if start_time is None:\n",
    "                start_time = cnt\n",
    "            buffer.append(frame_data)\n",
    "        else:\n",
    "            if start_time is not None:\n",
    "                segment_data = np.concatenate(buffer, axis=1)[0]\n",
    "                with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_audio_file:\n",
    "                    sf.write(temp_audio_file.name, segment_data, sr)\n",
    "                    with open(temp_audio_file.name, 'rb') as binary_file:\n",
    "                        top2_predictions = predict_on_audio(binary_file.read())\n",
    "\n",
    "                df_row = {'start_time': start_time, 'end_time': cnt}\n",
    "                \n",
    "                for i, pred in enumerate(top2_predictions[:2]):\n",
    "                    df_row[f'echonet_label_{i+1}'] = pred[0] if pred[0] is not None else None\n",
    "                    df_row[f'echonet_confidence_{i+1}'] = pred[1] if pred[1] is not None else None\n",
    "\n",
    "                df_rows.append(df_row)\n",
    "                buffer = []\n",
    "                start_time = None\n",
    "\n",
    "    # Handling the case where the last chunk contains an animal-related sound\n",
    "    if start_time is not None:\n",
    "        segment_data = np.concatenate(buffer, axis=1)[0]\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_audio_file:\n",
    "            sf.write(temp_audio_file.name, segment_data, sr)\n",
    "            with open(temp_audio_file.name, 'rb') as binary_file:\n",
    "                top2_predictions = predict_on_audio(binary_file.read())\n",
    "\n",
    "        df_row = {'start_time': start_time, 'end_time': len(chunks)}\n",
    "        \n",
    "        for i, pred in enumerate(top2_predictions[:2]):\n",
    "            df_row[f'echonet_label_{i+1}'] = pred[0] if pred[0] is not None else None\n",
    "            df_row[f'echonet_confidence_{i+1}'] = pred[1] if pred[1] is not None else None\n",
    "\n",
    "        df_rows.append(df_row)\n",
    "\n",
    "    df = pd.DataFrame(df_rows)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Use the function\n",
    "filename = 'yamnet_dir/cat-ul-goat.wav'\n",
    "df = sound_event_detection(filename)\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle: version not found\n",
      "numpy: 1.24.3\n",
      "pandas: 2.1.0\n",
      "soundfile: 0.12.1\n",
      "librosa: 0.10.1\n",
      "tensorflow: 2.13.0\n",
      "tensorflow_hub: 0.14.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Q\\Documents\\uni\\Echo\\Project-Echo\\src\\Components\\Engine\\2_chunk_model_testing.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Q/Documents/uni/Echo/Project-Echo/src/Components/Engine/2_chunk_model_testing.ipynb#W2sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m pd\u001b[39m.\u001b[39mset_option(\u001b[39m'\u001b[39m\u001b[39mdisplay.max_rows\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Q/Documents/uni/Echo/Project-Echo/src/Components/Engine/2_chunk_model_testing.ipynb#W2sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# Now print the DataFrame\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Q/Documents/uni/Echo/Project-Echo/src/Components/Engine/2_chunk_model_testing.ipynb#W2sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mprint\u001b[39m(df)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Q/Documents/uni/Echo/Project-Echo/src/Components/Engine/2_chunk_model_testing.ipynb#W2sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# 1. Read the pickle file\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Q/Documents/uni/Echo/Project-Echo/src/Components/Engine/2_chunk_model_testing.ipynb#W2sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39myamnet_dir/class_names.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# For yamnet, you might have to import it differently if the submodules are not directly exposed.\n",
    "# I'm providing a generic approach here.\n",
    "\n",
    "modules = {\n",
    "    'pickle': pickle,\n",
    "    'numpy': np,\n",
    "    'pandas': pd,\n",
    "    'soundfile': sf,\n",
    "    'librosa': librosa,\n",
    "    'tensorflow': tf,\n",
    "    'tensorflow_hub': hub\n",
    "    # 'yamnet.params': params,\n",
    "    # 'yamnet.yamnet': yamnet_model\n",
    "}\n",
    "\n",
    "for name, module in modules.items():\n",
    "    try:\n",
    "        print(f\"{name}: {module.__version__}\")\n",
    "    except AttributeError:\n",
    "        print(f\"{name}: version not found\")\n",
    "\n",
    "# Set the display options to show all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Now print the DataFrame\n",
    "print(df)\n",
    "\n",
    "\n",
    "# 1. Read the pickle file\n",
    "with open('yamnet_dir/class_names.pkl', 'rb') as f:\n",
    "   data = pickle.load(f)\n",
    "\n",
    "# Ensure that the data is serializable.\n",
    "# If your data contains any non-serializable parts, you'll need to handle those separately.\n",
    "\n",
    "# 2. Convert and save data as JSON\n",
    "with open('yamnet_dir/class_names.json', 'w') as f:\n",
    "   json.dump(data, f)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
