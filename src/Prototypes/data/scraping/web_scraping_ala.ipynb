{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1b067a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "039e316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_PATH = 'C:/Users/Tony/Documents/Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0bb081",
   "metadata": {},
   "source": [
    "## Dataset Origin\n",
    "The following dataset is generated from the occurence records obtained from the Atlas of Living Australia with filters \"machine obcervation\" and \"sound\". https://biocache.ala.org.au/occurrence/search?q=data_resource_uid%3Adr341&disableAllQualityFilters=true&qualityProfile=ALA&fq=multimedia%3A%22Sound%22&fq=basis_of_record%3A%22MACHINE_OBSERVATION%22\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38caf902",
   "metadata": {},
   "source": [
    "Upon manual inspection of the dataset, we can find the relevant columns: recordID for the URL link to pull the audio, species for classification tag, and latitude and longitude for future reference. There's also a sound ID \"sounds\" to link it with the existing database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb32cae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty dataframe to store metadata\n",
    "df = pd.DataFrame(columns=['sounds','species','latitude','longitude'])\n",
    "\n",
    "# Empty list to store metadata\n",
    "rows_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4c1a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default url after searching with machine sounds as filters\n",
    "url = 'https://biocache.ala.org.au/occurrence/search?q=data_resource_uid%3Adr341&disableAllQualityFilters=true&qualityProfile=ALA&fq=multimedia%3A%22Sound%22&fq=basis_of_record%3A%22MACHINE_OBSERVATION%22'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "# Get the link of the next results page\n",
    "link = soup.find('a', {'class': 'nextLink'})\n",
    "\n",
    "while link is not None:\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    # Go thorugh all the records of the current page\n",
    "    for link in soup.findAll('div', {'class': 'recordRow'}):\n",
    "        # Go into each entry of the results\n",
    "        url_id = (link['id']) \n",
    "        nexturl = 'https://biocache.ala.org.au/occurrence/' + url_id\n",
    "        nextpage = requests.get(nexturl)\n",
    "        nextsoup = BeautifulSoup(nextpage.content, 'html.parser')\n",
    "        # Scrape relevant metadata\n",
    "        species = nextsoup.find('tr', {'id': 'species'}).find('i').text\n",
    "        lat = nextsoup.find('tr', {'id': 'latitude'}).find('td', {'class': 'value'}).text.split()[-1]\n",
    "        long = nextsoup.find('tr', {'id': 'longitude'}).find('td', {'class': 'value'}).text.split()[-1]\n",
    "        cat_no = nextsoup.find('tr', {'id': 'catalogNumber'}).find('td', {'class': 'value'}).text.split()[-1]\n",
    "        # Scrape the audio\n",
    "        audio_url = nextsoup.audio['src']\n",
    "        audio = requests.get(audio_url)\n",
    "        \n",
    "        # update a dict to store metadata to a dataframe afterwards.\n",
    "        dict1 = {}\n",
    "        dict1.update({'sounds': cat_no, 'species': species, 'latitude': lat, \n",
    "                     'longitude': long})\n",
    "        rows_list.append(dict1)\n",
    "\n",
    "\n",
    "        # make directory if not already present\n",
    "        parent_dir = DIR_PATH\n",
    "        path = os.path.join(parent_dir, species)\n",
    "        if not os.path.isdir(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "        file_path = file_path = f'{DIR_PATH}{species}/{cat_no}.mp3'\n",
    "        # Write the audio file into directory\n",
    "        with open(file_path,'wb') as audio_file:\n",
    "            audio_file.write(audio.content)\n",
    "        # uncomment to print progress\n",
    "        #print(f\"Saved file: {file_path}\") uncomment to \n",
    "\n",
    "    # Find the link to the next results page\n",
    "    link = soup.find('a', {'class': 'nextLink'})\n",
    "    url = 'https://biocache.ala.org.au' + link['href']\n",
    "    print(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15eee73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sounds</th>\n",
       "      <th>species</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X02937</td>\n",
       "      <td>Ninox boobook</td>\n",
       "      <td>\"-33.1449\"</td>\n",
       "      <td>\"149.9814\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X02937</td>\n",
       "      <td>Ninox boobook</td>\n",
       "      <td>\"-33.1449\"</td>\n",
       "      <td>\"149.9814\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X01769</td>\n",
       "      <td>Menura novaehollandiae</td>\n",
       "      <td>\"-33.1738\"</td>\n",
       "      <td>\"149.9977\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X00489</td>\n",
       "      <td>Chalcites basalis</td>\n",
       "      <td>\"-33.1449\"</td>\n",
       "      <td>\"149.9814\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X00213</td>\n",
       "      <td>Froggattina australis</td>\n",
       "      <td>\"-33.1449\"</td>\n",
       "      <td>\"149.9814\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sounds                 species    latitude   longitude\n",
       "0  X02937           Ninox boobook  \"-33.1449\"  \"149.9814\"\n",
       "1  X02937           Ninox boobook  \"-33.1449\"  \"149.9814\"\n",
       "2  X01769  Menura novaehollandiae  \"-33.1738\"  \"149.9977\"\n",
       "3  X00489       Chalcites basalis  \"-33.1449\"  \"149.9814\"\n",
       "4  X00213   Froggattina australis  \"-33.1449\"  \"149.9814\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the dataframe using the list of stored metadata\n",
    "df3 = pd.DataFrame(rows_list)         \n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cf20d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of directories: 333\n",
      "total number of files: 3980\n"
     ]
    }
   ],
   "source": [
    "totalDir = 0\n",
    "totalFile = 0\n",
    "parent_dir = DIR_PATH\n",
    "for base, dirs, files in os.walk(parent_dir):\n",
    "    for directories in dirs:\n",
    "        totalDir += 1\n",
    "    for file in files:\n",
    "        totalFile += 1\n",
    "print(f'total number of directories: {totalDir}')\n",
    "print(f'total number of files: {totalFile}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "8a6d3034",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da21a330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "dcacd4bc9425bc1dc7eb3eb642b772828e4b7222951303bfcb39fa32157da8bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
