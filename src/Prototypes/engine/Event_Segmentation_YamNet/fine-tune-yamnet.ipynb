{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from scipy.signal import resample_poly\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "# Load YAMNet model\n",
    "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
    "yamnet_model = hub.load(yamnet_model_handle)\n",
    "\n",
    "# Constants\n",
    "main_directory = '/Users/ankush/Downloads/deakin-units/data/b3'\n",
    "class_names = sorted(os.listdir(main_directory))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to get file paths and labels\n",
    "def get_file_paths_and_labels(main_directory, class_names):\n",
    "    filenames = []\n",
    "    labels = []\n",
    "    for label, class_name in enumerate(class_names):\n",
    "        class_directory = os.path.join(main_directory, class_name)\n",
    "        if os.path.isdir(class_directory): # Ensure it's a directory\n",
    "            for file_name in os.listdir(class_directory):\n",
    "                if file_name.endswith('.wav'):\n",
    "                    filenames.append(os.path.join(class_directory, file_name))\n",
    "                    labels.append(label)\n",
    "    return filenames, labels\n",
    "from scipy.signal import resample\n",
    "\n",
    "def resample_audio(wav, num_samples):\n",
    "    return resample(wav, num_samples)\n",
    "\n",
    "def load_wav_16k_mono(filename, target_length=16000):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio, and pad to target length. \"\"\"\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(\n",
    "          file_contents,\n",
    "          desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.float32)\n",
    "    target_sample_rate = 16000.0\n",
    "\n",
    "    # Compute the number of samples for the target sample rate\n",
    "    num_samples = tf.cast(tf.shape(wav)[0], dtype=tf.float32) * target_sample_rate / sample_rate\n",
    "    num_samples = tf.cast(num_samples, tf.int32)\n",
    "\n",
    "    # Resample the wav using scipy resample\n",
    "    resampled_wav = tf.numpy_function(resample_audio, [wav, num_samples], tf.float32)\n",
    "\n",
    "    # Pad or truncate to target length\n",
    "    resampled_wav = tf.cond(tf.shape(resampled_wav)[0] < target_length,\n",
    "                            lambda: tf.pad(resampled_wav, [[0, target_length - tf.shape(resampled_wav)[0]]]),\n",
    "                            lambda: resampled_wav[:target_length])\n",
    "\n",
    "    return resampled_wav\n",
    "\n",
    "\n",
    "\n",
    "# Import necessary libraries\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "# Define the augmentation function\n",
    "def audio_augmentation(wav_data):\n",
    "    # Time shifting\n",
    "    shift = tf.random.uniform([], -1600, 1600, dtype=tf.int32)\n",
    "    wav_data = tf.roll(wav_data, shift, axis=0)\n",
    "    # Adding noise (optional)\n",
    "    noise = tf.random.normal(shape=tf.shape(wav_data), mean=0., stddev=0.1)\n",
    "    wav_data = wav_data + noise\n",
    "    return wav_data\n",
    "\n",
    "# Modify the load_and_preprocess_data function\n",
    "def load_and_preprocess_data(filename, label):\n",
    "    wav_data = load_wav_16k_mono(filename)\n",
    "    # Apply the augmentation\n",
    "    wav_data = audio_augmentation(wav_data)\n",
    "    scores, embeddings, _ = yamnet_model(wav_data)\n",
    "    embeddings = tf.reduce_mean(embeddings, axis=0)  # Average across frames\n",
    "    return embeddings, label\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get file paths and labels\n",
    "filenames, labels = get_file_paths_and_labels(main_directory, class_names)\n",
    "\n",
    "filenames_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "labels_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "\n",
    "# Zipping the datasets to create pairs of (filename, label)\n",
    "main_ds = tf.data.Dataset.zip((filenames_ds, labels_ds))\n",
    "\n",
    "# Apply loading and preprocessing\n",
    "main_ds = main_ds.map(load_and_preprocess_data)\n",
    "\n",
    "# Splitting the dataset\n",
    "train_ds = main_ds.take(int(len(filenames) * 0.7))\n",
    "test_ds = main_ds.skip(int(len(filenames) * 0.7))\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 16)                4112      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 660240 (2.52 MB)\n",
      "Trainable params: 660240 (2.52 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "\n",
    "# Model definition\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "my_model = Sequential([\n",
    "    Input(shape=(1024,), dtype=tf.float32, name='input_embedding'),\n",
    "    Dense(512, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.5), # Adding dropout\n",
    "    Dense(256, activation='relu'), # Additional hidden layer\n",
    "    Dense(len(class_names))\n",
    "], name='my_model')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "my_model.summary()\n",
    "\n",
    "my_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "35/35 [==============================] - 19s 50ms/step - loss: 5.6955 - accuracy: 0.2071\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 1s 16ms/step - loss: 2.7005 - accuracy: 0.2613\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 1s 17ms/step - loss: 2.2840 - accuracy: 0.2667\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 1s 15ms/step - loss: 2.1874 - accuracy: 0.2812\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 1s 15ms/step - loss: 2.1428 - accuracy: 0.2803\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 0s 14ms/step - loss: 2.1085 - accuracy: 0.2821\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 2.0582 - accuracy: 0.2948\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 1s 15ms/step - loss: 2.0433 - accuracy: 0.3056\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 1s 15ms/step - loss: 2.0325 - accuracy: 0.3074\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 1s 15ms/step - loss: 2.0314 - accuracy: 0.3020\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 0s 14ms/step - loss: 2.0165 - accuracy: 0.3038\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 1s 14ms/step - loss: 1.9957 - accuracy: 0.3201\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 1s 15ms/step - loss: 1.9821 - accuracy: 0.3291\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 0s 14ms/step - loss: 1.9845 - accuracy: 0.3083\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 1s 16ms/step - loss: 1.9682 - accuracy: 0.3273\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 0s 14ms/step - loss: 1.9801 - accuracy: 0.2939\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 1.9478 - accuracy: 0.3228\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 0s 14ms/step - loss: 1.9616 - accuracy: 0.3300\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 1s 15ms/step - loss: 1.9432 - accuracy: 0.3273\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 1s 15ms/step - loss: 1.9320 - accuracy: 0.3354\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 0s 14ms/step - loss: 1.9582 - accuracy: 0.3345\n",
      "Epoch 22/50\n",
      "35/35 [==============================] - 1s 17ms/step - loss: 1.9305 - accuracy: 0.3327\n",
      "Epoch 23/50\n",
      "35/35 [==============================] - 1s 15ms/step - loss: 1.9176 - accuracy: 0.3400\n",
      "Epoch 24/50\n",
      "35/35 [==============================] - 1s 16ms/step - loss: 1.9246 - accuracy: 0.3436\n",
      "Epoch 25/50\n",
      "35/35 [==============================] - 0s 14ms/step - loss: 1.9207 - accuracy: 0.3363\n",
      "Epoch 26/50\n",
      "35/35 [==============================] - 1s 15ms/step - loss: 1.8930 - accuracy: 0.3526\n",
      "Epoch 27/50\n",
      "35/35 [==============================] - 0s 14ms/step - loss: 1.8994 - accuracy: 0.3526\n",
      "Epoch 28/50\n",
      "35/35 [==============================] - 1s 16ms/step - loss: 1.8934 - accuracy: 0.3472\n",
      "Epoch 29/50\n",
      "35/35 [==============================] - 0s 14ms/step - loss: 1.8941 - accuracy: 0.3599\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = my_model.fit(train_ds, epochs=50, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 26s 498ms/step - loss: 8.6473 - accuracy: 0.0021\n",
      "Loss:  8.64730167388916\n",
      "Accuracy:  0.002109704539179802\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = my_model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
