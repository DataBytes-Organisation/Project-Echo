{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event Detection\n",
    "\n",
    "To achieve real-time event detection in Python, we have utilised the pyaudio library to capture live audio from the microphone and analyse the audio data to identify events or patterns. The detect_events function monitors the audio data and triggers an alert when the audio exceeds a predefined threshold. This enables the user to be promptly notified of detected events while the audio stream is being monitored.\n",
    "\n",
    "This code has been tested and is ready to deploy to a live testing environment. \n",
    "\n",
    "Author: cpavia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "# library imports\n",
    "########################################################################################\n",
    "\n",
    "# disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# environment settings\n",
    "import os\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "\n",
    "# processing related libraries\n",
    "import librosa\n",
    "\n",
    "# real-time audio event detection\n",
    "import pyaudio\n",
    "import wave\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for events...\n",
      "Event detected!\n",
      "Event recording saved to: C:\\path\\to\\the\\directory\\event_recording.wav\n"
     ]
    }
   ],
   "source": [
    "def detect_event(audio_samples, threshold):\n",
    "    # Perform event detection logic here\n",
    "    # Function to detect an event using spectral centroid\n",
    "    spectral_centroids = librosa.feature.spectral_centroid(y=audio_samples, sr=44100)[0]\n",
    "    avg_spectral_centroid = np.mean(spectral_centroids)\n",
    "    return avg_spectral_centroid < threshold\n",
    "\n",
    "def record_and_save_audio(output_folder, recording_duration=10, threshold=0.5):\n",
    "    # Parameters for audio recording\n",
    "    CHUNK = 1024\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "    RATE = 44100\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    frames = []\n",
    "    event_detected = False\n",
    "    \n",
    "    print(\"Listening for events...\")\n",
    "    for i in range(0, int(RATE / CHUNK * recording_duration)):\n",
    "        audio_data = stream.read(CHUNK)\n",
    "        frames.append(audio_data)\n",
    "        \n",
    "        # Convert the audio data to integers\n",
    "        audio_samples = np.frombuffer(audio_data, dtype=np.int16)\n",
    "\n",
    "        # Convert the integer samples to float format (-1.0 to 1.0 range)\n",
    "        audio_samples = audio_samples / np.iinfo(np.int16).max\n",
    "        \n",
    "        # Detect event\n",
    "        if not event_detected and detect_event(audio_samples, threshold):\n",
    "            event_detected = True\n",
    "            print(\"Event detected!\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    \n",
    "    # Save the recorded audio if an event was detected\n",
    "    if event_detected:\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        output_file = os.path.join(output_folder, \"event_recording.wav\")\n",
    "        wf = wave.open(output_file, \"wb\")\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b\"\".join(frames))\n",
    "        wf.close()\n",
    "        print(\"Event recording saved to:\", output_file)\n",
    "    else:\n",
    "        print(\"No event found\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Set the output folder where the event recording will be saved\n",
    "    output_folder = r'C:\\path\\to\\the\\directory'\n",
    "\n",
    "    # Set the duration (in seconds) for recording\n",
    "    recording_duration = 5\n",
    "\n",
    "    # Set the threshold for event detection (adjust based on your audio input)\n",
    "    threshold = 3500\n",
    "\n",
    "    record_and_save_audio(output_folder, recording_duration, threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
