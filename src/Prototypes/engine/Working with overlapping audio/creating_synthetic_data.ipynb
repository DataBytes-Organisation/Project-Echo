{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a45d294c-968a-4d73-83c5-a5b4a8c86fdb",
   "metadata": {},
   "source": [
    "# Creating Synthetic Overlapping Audio\n",
    "\n",
    "## Jessica Stinson\n",
    "## s224576666"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92c2f90-40e5-4351-98ca-25100b56d201",
   "metadata": {},
   "source": [
    "The following notebook provides a basic script for creating a synthetic audio dataset. When run, the script will copy all original audiofiles to the output directory then create a mix of new files containing either two or three overlapping vocalisations. The 'SYNTHETIC_SIZE' variable can be altered to change the number of synthetic audio files added to the dataset. The ratio of original to synthetic audio files used in this example was approximately 1:2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f318373b-07e8-4a54-b089-7e94b7679f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set TensorFlow environment\n",
    "import os\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "\n",
    "import soundfile as sf \n",
    "from pathlib import Path\n",
    "import librosa\n",
    "import numpy as np\n",
    "import random \n",
    "import tensorflow as tf\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "SC = {\n",
    "    'AUDIO_DATA_DIRECTORY': r\"C:\\Project-Echo\\src\\Prototypes\\engine\\Working with overlapping audio\\Synthetic Dataset tests\\originals\",\n",
    "    'AUDIO_SAMPLE_RATE': 48000,\n",
    "    'AUDIO_CLIP_DURATION': 5, # seconds\n",
    "    'SYNTHETIC_SIZE': 400,\n",
    "    'OUTPUT_DIR': r\"C:\\Project-Echo\\src\\Prototypes\\engine\\Working with overlapping audio\\Synthetic Dataset\"\n",
    "}\n",
    "\n",
    "audio_dir = Path(SC['AUDIO_DATA_DIRECTORY'])\n",
    "output_dir = Path(SC['OUTPUT_DIR'])\n",
    "synthetic_size = SC['SYNTHETIC_SIZE']\n",
    "SR = SC['AUDIO_SAMPLE_RATE']\n",
    "duration = SC['AUDIO_CLIP_DURATION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98bd54a8-ab32-4a33-b5ba-df19e4abbb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_directory(directory, file_types=('.ogg', '.mp3', '.wav', '.flac')):\n",
    "    \"\"\" \n",
    "    Indexes audio files in a directory structured by class subdirectories.\n",
    "\n",
    "    Args:\n",
    "        directory (str or Path): The root directory containing subdirectories for each class.\n",
    "        file_types (tuple, optional): Allowed audio file extensions.\n",
    "            Defaults to ('.ogg', '.mp3', '.wav', '.flac').\n",
    "\n",
    "    Returns: \n",
    "        tuple:\n",
    "            - audio_files (list of str): Full paths to audio files found.\n",
    "            - labels (list of int): Integer labels corresponding to class directories.\n",
    "            - class_names (list of str): Sorted list of class names.\n",
    "\n",
    "    Notes:\n",
    "        The function assumes each subdirectory in 'directory' represents a unique class. \n",
    "        The function assigns integer labels to each class based on alphabetical order of class names. \n",
    "    \"\"\"\n",
    "    audio_files = []\n",
    "    labels = []\n",
    "    class_names = sorted([dir.name for dir in Path(directory).glob('*') if dir.is_dir()])\n",
    "\n",
    "    # Create a mapping from file path to a list of labels\n",
    "    file_label_map = {}\n",
    "    for label_idx, class_name in enumerate(class_names):\n",
    "        class_dir = Path(directory) / class_name\n",
    "        for file_path in class_dir.glob(f'**/*'):\n",
    "            if file_path.suffix in file_types:\n",
    "                str_path = str(file_path)\n",
    "                if str_path not in file_label_map:\n",
    "                    file_label_map[str_path] = []\n",
    "                file_label_map[str_path].append(label_idx)\n",
    "\n",
    "    # Convert the map to parallel lists for dataset creation\n",
    "    file_paths = list(file_label_map.keys())\n",
    "    labels_list = list(file_label_map.values())\n",
    "    \n",
    "    # Use MultiLabelBinarizer to create multi-hot encoded labels\n",
    "    mlb = MultiLabelBinarizer(classes=range(len(class_names)))\n",
    "    labels = mlb.fit_transform(labels_list)\n",
    "    \n",
    "    # Check if a file has no labels and remove it.\n",
    "    valid_indices = [i for i, label in enumerate(labels) if any(label)]\n",
    "    file_paths = [file_paths[i] for i in valid_indices]\n",
    "    labels = labels[valid_indices]\n",
    "\n",
    "    return file_paths, labels, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c8bc24b-8f97-4b64-af26-fd33068a7a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original audio dataset \n",
    "file_paths, labels, class_names = index_directory(audio_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b674d00e-7238-416e-b0c7-bf7671406b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied and normalized 268 original files into: C:\\Project-Echo\\src\\Prototypes\\engine\\Working with overlapping audio\\Synthetic Dataset\n"
     ]
    }
   ],
   "source": [
    "# Copy original audio to output directory\n",
    "combined_file_paths = []\n",
    "synthetic_labels = []\n",
    "\n",
    "for i, (src_path, label) in enumerate(zip(file_paths, labels)):\n",
    "    species_name = Path(src_path).parent.name.replace(\" \", \"_\").lower()\n",
    "    dst_path = output_dir / f\"{species_name}_{i + 1}.wav\"\n",
    "    audio, _ = librosa.load(src_path, sr=SR)\n",
    "    audio = librosa.util.fix_length(audio, size=int(duration * SR))\n",
    "    sf.write(dst_path, audio, SR)\n",
    "\n",
    "    combined_file_paths.append(str(dst_path))\n",
    "    synthetic_labels.append(label)\n",
    "\n",
    "print(f\"Copied and normalized {len(file_paths)} original files into: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26403574-777e-45ad-a86e-777c066c7640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1/400 synthetic samples\n",
      "Generated 100/400 synthetic samples\n",
      "Generated 200/400 synthetic samples\n",
      "Generated 300/400 synthetic samples\n",
      "Generated 400/400 synthetic samples\n",
      "Synthetic dataset generation complete.\n",
      "\n",
      "Combined dataset created in C:\\Project-Echo\\src\\Prototypes\\engine\\Working with overlapping audio\\Synthetic Dataset\n",
      "Total files: 668\n"
     ]
    }
   ],
   "source": [
    "for i in range(synthetic_size):\n",
    "    num_to_mix = random.randint(2, 3)    \n",
    "    indices = random.sample(range(len(file_paths)), num_to_mix)\n",
    "\n",
    "    synthetic_audio = np.zeros(int(duration * SR), dtype = np.float32)\n",
    "    label_vector = np.zeros(len(class_names), dtype = np.float32)\n",
    "\n",
    "    for idx in indices:\n",
    "        path = file_paths[idx]\n",
    "        label = labels[idx]\n",
    "\n",
    "        audio, _ = librosa.load(path, sr = SR)\n",
    "        audio = librosa.util.fix_length(audio, size = int(duration * SR))\n",
    "        synthetic_audio += audio\n",
    "        label_vector += label\n",
    "        label_vector = np.clip(label_vector, 0, 1)\n",
    "\n",
    "    # Normalize to prevent clipping\n",
    "    max_val = np.max(np.abs(synthetic_audio))\n",
    "    if max_val > 1.0:\n",
    "        synthetic_audio = synthetic_audio / max_val\n",
    "\n",
    "    file_name = f\"synthetic_{i + 1}.wav\"\n",
    "    dst_path = output_dir / file_name\n",
    "    sf.write(dst_path, synthetic_audio, SR)\n",
    "\n",
    "    combined_file_paths.append(str(dst_path))\n",
    "    synthetic_labels.append(label_vector)\n",
    "    \n",
    "    if i == 0 or (i + 1) % 100 == 0 or i == synthetic_size - 1:\n",
    "        print(f\"Generated {i + 1}/{synthetic_size} synthetic samples\")\n",
    "\n",
    "synthetic_labels = np.array(synthetic_labels)\n",
    "\n",
    "# Save labels\n",
    "np.save(output_dir / \"synthetic_labels.npy\", np.array(synthetic_labels))\n",
    "    \n",
    "# Save class names and file paths\n",
    "with open(output_dir / \"class_names.json\", \"w\") as f:\n",
    "    json.dump(class_names, f)\n",
    "\n",
    "with open(output_dir / \"file_paths.json\", \"w\") as f:\n",
    "    json.dump(combined_file_paths, f)\n",
    "\n",
    "print(\"Synthetic dataset generation complete.\")\n",
    "print(f\"\\nCombined dataset created in {output_dir}\")\n",
    "print(f\"Total files: {len(combined_file_paths)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (projectecho)",
   "language": "python",
   "name": "projectecho"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
