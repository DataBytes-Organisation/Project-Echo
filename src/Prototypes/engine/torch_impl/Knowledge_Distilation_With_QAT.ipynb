{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "UCaQejxybJBs",
        "nS8ldCtdbTpn",
        "9OamEcBjbvH6",
        "ox5u1ZkKgWRS",
        "sjQ9hD0OgZ7C",
        "R4_s1C6UeGIJ",
        "198Dj5zRe6zr",
        "Lik1cXE3fFJ7",
        "ywfn3EvrflcO",
        "4BuT8DsSflcO",
        "4_Kq_GmCflcP"
      ],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "2nTgYYk3bHA1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DCS0fRZ314O",
        "outputId": "e9b09295-6f48-4ba1-ac8e-884ff66eb7d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.ao.quantization as quant\n",
        "from torch.ao.quantization.quantize_fx import prepare_fx, convert_fx, prepare_qat_fx as prepare_qat_fx_\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iGnc5LtlYGT",
        "outputId": "bd28c629-990c-422a-f723-bae792fe8cd7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_PATH=\"/content/drive/MyDrive/DemoQuantDistillation\""
      ],
      "metadata": {
        "id": "lH9RDoQLmf15"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 0\n",
        "\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed(RANDOM_SEED)\n",
        "  torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False # Disable the non-deterministic algorithms"
      ],
      "metadata": {
        "id": "TJBuf7x5VXY3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "UCaQejxybJBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transforms_train = transforms.Compose([\n",
        "  transforms.RandomCrop(32, padding=4),\n",
        "  transforms.RandomHorizontalFlip(),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "transforms_test = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_ds = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms_train)\n",
        "test_ds = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icFoJzZ73-es",
        "outputId": "cb5a345c-5594-4168-e48a-c7ed68f44843"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:15<00:00, 11.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=2)\n",
        "test_dl = DataLoader(test_ds, batch_size=128, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "gl6sJv064G9O"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "nS8ldCtdbTpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepNN(nn.Module):\n",
        "  def __init__(self, num_classes=10):\n",
        "    super().__init__()\n",
        "    self.features = nn.Sequential(\n",
        "      nn.Conv2d(3, 128, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "      nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "    )\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "      nn.Linear(2048, 512),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.1),\n",
        "      nn.Linear(512, num_classes)\n",
        "    )\n",
        "\n",
        "  def get_features_map(self, x):\n",
        "    x = self.features(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "  def get_emb(self, x):\n",
        "    features = self.get_features_map(x)\n",
        "    x = torch.flatten(features, 1)\n",
        "\n",
        "    return features, x\n",
        "\n",
        "  def classify(self, emb):\n",
        "    x = self.classifier(emb)\n",
        "\n",
        "    return x\n",
        "\n",
        "  def forward(self, x):\n",
        "    _, x = self.get_emb(x)\n",
        "    x = self.classify(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "4gc3bhVN4NN2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LightNN(nn.Module):\n",
        "  def __init__(self, num_classes=10):\n",
        "    super().__init__()\n",
        "\n",
        "    self.features = nn.Sequential(\n",
        "      nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "      nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "    )\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "      nn.Linear(1024, 256),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.1),\n",
        "      nn.Linear(256, num_classes)\n",
        "    )\n",
        "\n",
        "  def get_features_map(self, x):\n",
        "    x = self.features(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "  def get_emb(self, x):\n",
        "    features = self.get_features_map(x)\n",
        "    x = torch.flatten(features, 1)\n",
        "\n",
        "    return features, x\n",
        "\n",
        "  def classify(self, emb):\n",
        "    x = self.classifier(emb)\n",
        "\n",
        "    return x\n",
        "\n",
        "  def forward(self, x):\n",
        "    _, x = self.get_emb(x)\n",
        "    x = self.classify(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "_2rvI-Hm4bvT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "9OamEcBjbvH6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantisation Utils"
      ],
      "metadata": {
        "id": "Y7FOUL2MgfGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fuse_model(model):\n",
        "\t\"\"\"\n",
        "\tFuse conv+relu and linear+relu in simple Sequential modules.\n",
        "\tIn-place on the given model.\n",
        "\t\"\"\"\n",
        "\tfused_model = copy.deepcopy(model).cpu().eval()\n",
        "\n",
        "\tmodules_to_fuse = []\n",
        "\n",
        "\t# features is a Sequential\n",
        "\ttry:\n",
        "\t\tfeatures = model.features\n",
        "\t\tfor i in range(len(features) - 1):\n",
        "\t\t\tif isinstance(features[i], nn.Conv2d) and isinstance(features[i+1], nn.ReLU):\n",
        "\t\t\t\tmodules_to_fuse.append([f\"features.{i}\", f\"features.{i+1}\"])\n",
        "\texcept Exception:\n",
        "\t\tpass\n",
        "\n",
        "\t# classifier sequential (linear + relu)\n",
        "\ttry:\n",
        "\t\tclassifier = model.classifier\n",
        "\t\tfor i in range(len(classifier) - 1):\n",
        "\t\t\tif isinstance(classifier[i], nn.Linear) and isinstance(classifier[i+1], nn.ReLU):\n",
        "\t\t\t\tmodules_to_fuse.append([f\"classifier.{i}\", f\"classifier.{i+1}\"])\n",
        "\texcept Exception:\n",
        "\t\tpass\n",
        "\n",
        "\tif modules_to_fuse:\n",
        "\t\tquant.fuse_modules(fused_model, modules_to_fuse, inplace=True)\n",
        "\n",
        "\treturn fused_model"
      ],
      "metadata": {
        "id": "Ts0xAVnSeWWU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_example_input_from_loader(dl, device):\n",
        "\tbatch = next(iter(dl))[0]\n",
        "\texample_input = batch[:1].cpu()\n",
        "\n",
        "\treturn (example_input,)"
      ],
      "metadata": {
        "id": "iEjJmOQbSAYh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_post_static_quantize_fx(float_model, calib_dl, input_size=(1, 3, 32, 32)):\n",
        "\tquant_model = copy.deepcopy(float_model).cpu().eval()\n",
        "\tfuse_model(quant_model)\n",
        "\n",
        "\tqconfig = quant.get_default_qconfig(\"fbgemm\")\n",
        "\tqconfig_dict = {\"\": qconfig}\n",
        "\n",
        "\texample_inputs = torch.rand(size=input_size).cpu()\n",
        "\tprepared = prepare_fx(quant_model, qconfig_dict, example_inputs=example_inputs)\n",
        "\n",
        "\t# calibration: run a batch through prepared model\n",
        "\twith torch.no_grad():\n",
        "\t\tfor inputs, _ in calib_dl:\n",
        "\t\t\tprepared(inputs.cpu())\n",
        "\t\t\tbreak\n",
        "\n",
        "\treturn prepared"
      ],
      "metadata": {
        "id": "Mife5F-GgiF5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_qat_fx(model, input_size=(1, 3, 32, 32)):\n",
        "\tqconfig = quant.get_default_qat_qconfig('fbgemm')\n",
        "\tqconfig_dict = {\"\": qconfig}\n",
        "\n",
        "\texample_inputs = torch.rand(size=input_size).cpu()\n",
        "\tprepared_qat = prepare_qat_fx_(model, qconfig_dict, example_inputs=example_inputs)\n",
        "\n",
        "\treturn prepared_qat"
      ],
      "metadata": {
        "id": "rpHOz7k2c-8F"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base Training and Test Utils"
      ],
      "metadata": {
        "id": "ox5u1ZkKgWRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, epochs, learning_rate, device, use_qat=False):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  if use_qat:\n",
        "    model = prepare_model_for_qat(model)\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")"
      ],
      "metadata": {
        "id": "yK4nuC3c5Qda"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_loader, device):\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  accuracy = 100 * correct / total\n",
        "  print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "7Fb_Urqu5iMz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Knowledge Distilation Training"
      ],
      "metadata": {
        "id": "sjQ9hD0OgZ7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_knowledge_distillation(teacher, student, train_dl, epochs, lr, T, soft_target_loss_weight, ce_loss_weight, device):\n",
        "  ce_loss = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.AdamW(student.parameters(), lr=lr)\n",
        "\n",
        "  teacher.to(device)\n",
        "  student.to(device)\n",
        "\n",
        "  teacher.eval()\n",
        "  student.train()\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_dl:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        teacher_logits = teacher(inputs)\n",
        "\n",
        "      student_logits = student(inputs)\n",
        "\n",
        "      soft_targets = nn.functional.softmax(teacher_logits / T, dim=-1)\n",
        "      soft_prob = nn.functional.log_softmax(student_logits / T, dim=-1)\n",
        "\n",
        "      soft_targets_loss = torch.sum(soft_targets * (soft_targets.log() - soft_prob)) / soft_prob.size()[0] * (T**2)\n",
        "\n",
        "      label_loss = ce_loss(student_logits, labels)\n",
        "\n",
        "      loss = soft_target_loss_weight * soft_targets_loss + ce_loss_weight * label_loss\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_dl)}\")"
      ],
      "metadata": {
        "id": "21xWtQoA6MbB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_cosine_loss(teacher, student, train_dl, epochs, lr, hidden_rep_loss_weight, ce_loss_weight, device):\n",
        "  ce_loss = nn.CrossEntropyLoss()\n",
        "  cosine_loss = nn.CosineEmbeddingLoss()\n",
        "  optimizer = optim.AdamW(student.parameters(), lr=lr)\n",
        "\n",
        "  teacher.to(device)\n",
        "  student.to(device)\n",
        "\n",
        "  teacher.eval()\n",
        "  student.train()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    _, teacher_dummy_emb = teacher.get_emb(torch.randn(1, 3, 32, 32).to(device))\n",
        "    _, student_dummy_emb = student.get_emb(torch.randn(1, 3, 32, 32).to(device))\n",
        "\n",
        "  teacher_emb_size = teacher_dummy_emb.size(1)\n",
        "  student_emb_size = student_dummy_emb.size(1)\n",
        "\n",
        "  if teacher_emb_size % student_emb_size != 0:\n",
        "    raise ValueError(\"Teacher embedding size must be a multiple of the student embedding size for dynamic pooling.\")\n",
        "\n",
        "  pooling_kernel_size = teacher_emb_size // student_emb_size\n",
        "\n",
        "  print(f\"Teacher embedding size: {teacher_emb_size}\")\n",
        "  print(f\"Student embedding size: {student_emb_size}\")\n",
        "  print(f\"Pooling kernel size: {pooling_kernel_size}\")\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_dl:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        _, teacher_emb = teacher.get_emb(inputs)\n",
        "\n",
        "      _, student_emb = student.get_emb(inputs)\n",
        "      student_logits = student.classify(student_emb)\n",
        "\n",
        "      teacher_emb_pooled = F.avg_pool1d(\n",
        "        teacher_emb.unsqueeze(1),\n",
        "        kernel_size=pooling_kernel_size\n",
        "      ).squeeze(1)\n",
        "\n",
        "      hidden_rep_loss = cosine_loss(student_emb, teacher_emb_pooled, target=torch.ones(inputs.size(0)).to(device))\n",
        "      label_loss = ce_loss(student_logits, labels)\n",
        "\n",
        "      loss = hidden_rep_loss_weight * hidden_rep_loss + ce_loss_weight * label_loss\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_dl)}\")"
      ],
      "metadata": {
        "id": "FwxaXf3ab2O3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_cosine_loss_proj(teacher, student, train_dl, epochs, lr, hidden_rep_loss_weight, ce_loss_weight, device):\n",
        "  ce_loss = nn.CrossEntropyLoss()\n",
        "  cosine_loss = nn.CosineEmbeddingLoss()\n",
        "  optimizer = optim.AdamW(student.parameters(), lr=lr)\n",
        "\n",
        "  teacher.to(device)\n",
        "  student.to(device)\n",
        "\n",
        "  teacher.eval()\n",
        "  student.train()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    _, teacher_dummy_emb = teacher.get_emb(torch.randn(1, 3, 32, 32).to(device))\n",
        "    _, student_dummy_emb = student.get_emb(torch.randn(1, 3, 32, 32).to(device))\n",
        "\n",
        "  teacher_emb_size = teacher_dummy_emb.size(1)\n",
        "  student_emb_size = student_dummy_emb.size(1)\n",
        "\n",
        "  if teacher_emb_size != student_emb_size:\n",
        "    proj_layer = nn.Linear(teacher_emb_size, student_emb_size).to(device)\n",
        "  else:\n",
        "    proj_layer = nn.Identity().to(device)\n",
        "\n",
        "  proj_layer.train()\n",
        "\n",
        "  print(f\"Teacher embedding size: {teacher_emb_size}\")\n",
        "  print(f\"Student embedding size: {student_emb_size}\")\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_dl:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        _, teacher_emb = teacher.get_emb(inputs)\n",
        "\n",
        "      _, student_emb = student.get_emb(inputs)\n",
        "      student_logits = student.classify(student_emb)\n",
        "\n",
        "      teacher_emb_projed = proj_layer(teacher_emb)\n",
        "\n",
        "      hidden_rep_loss = cosine_loss(student_emb, teacher_emb_projed, target=torch.ones(inputs.size(0)).to(device))\n",
        "      label_loss = ce_loss(student_logits, labels)\n",
        "\n",
        "      loss = hidden_rep_loss_weight * hidden_rep_loss + ce_loss_weight * label_loss\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_dl)}\")"
      ],
      "metadata": {
        "id": "mW_kQ_yhdZ1t"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_mse_loss(teacher, student, train_dl, epochs, lr, hidden_rep_loss_weight, ce_loss_weight, device):\n",
        "  ce_loss = nn.CrossEntropyLoss()\n",
        "  mse_loss = nn.MSELoss()\n",
        "  optimizer = optim.AdamW(student.parameters(), lr=lr)\n",
        "\n",
        "  teacher.to(device)\n",
        "  student.to(device)\n",
        "\n",
        "  teacher.eval()\n",
        "  student.train()\n",
        "\n",
        "  proj_layer = nn.Conv2d(16, 32, kernel_size=3, padding=1).to(device)\n",
        "  proj_layer.train()\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_dl:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        teacher_features_map, _ = teacher.get_emb(inputs)\n",
        "\n",
        "      student_features_map, student_emb = student.get_emb(inputs)\n",
        "      student_logits = student.classify(student_emb)\n",
        "\n",
        "      student_features_map_projed = proj_layer(student_features_map)\n",
        "\n",
        "      hidden_rep_loss = mse_loss(student_features_map_projed, teacher_features_map)\n",
        "      label_loss = ce_loss(student_logits, labels)\n",
        "\n",
        "      loss = hidden_rep_loss_weight * hidden_rep_loss + ce_loss_weight * label_loss\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_dl)}\")"
      ],
      "metadata": {
        "id": "RWgmtI1JelGs"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "vVbLbYtMbzWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teacher Model"
      ],
      "metadata": {
        "id": "jlMIneyLdI9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn_deep = DeepNN(num_classes=10).to(device)\n",
        "train(nn_deep, train_dl, epochs=10, learning_rate=0.001, device=device)\n",
        "test_accuracy_deep = test(nn_deep, test_dl, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7M9fB945lTY",
        "outputId": "2b196fc8-2ce2-4af0-dcd1-a464c28839c6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.576228148492096\n",
            "Epoch 2/10, Loss: 1.164011489247422\n",
            "Epoch 3/10, Loss: 0.9765752381680871\n",
            "Epoch 4/10, Loss: 0.871798596418727\n",
            "Epoch 5/10, Loss: 0.7950609061114319\n",
            "Epoch 6/10, Loss: 0.7505644590348539\n",
            "Epoch 7/10, Loss: 0.7044291852990074\n",
            "Epoch 8/10, Loss: 0.6760034995615635\n",
            "Epoch 9/10, Loss: 0.6492420825202142\n",
            "Epoch 10/10, Loss: 0.624915267195543\n",
            "Test Accuracy: 79.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(nn_deep.state_dict(), f\"{SAVE_PATH}/nn_deep.pth\")"
      ],
      "metadata": {
        "id": "lHhScMwFmmPF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base Student Model"
      ],
      "metadata": {
        "id": "3CgiI7Y6dLkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn_light = LightNN(num_classes=10).to(device)"
      ],
      "metadata": {
        "id": "nVp7puAr5pKn"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_nn_light = LightNN(num_classes=10).to(device)"
      ],
      "metadata": {
        "id": "_uhh9olx5_Ta"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Norm of 1st layer of nn_light:\", torch.norm(nn_light.features[0].weight).item())\n",
        "print(\"Norm of 1st layer of new_nn_light:\", torch.norm(new_nn_light.features[0].weight).item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYki5P0t54Es",
        "outputId": "daea2737-0952-479e-984c-dfbe147c4a3e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm of 1st layer of nn_light: 2.3297154903411865\n",
            "Norm of 1st layer of new_nn_light: 2.323422908782959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(nn_light, train_dl, epochs=10, learning_rate=0.001, device=device)\n",
        "test_accuracy_light_ce = test(nn_light, test_dl, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHzAj1EL6B92",
        "outputId": "f7a8a495-e53e-4aca-b59f-ebce852456c1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.6446998732169267\n",
            "Epoch 2/10, Loss: 1.3801570719160388\n",
            "Epoch 3/10, Loss: 1.2711946558769402\n",
            "Epoch 4/10, Loss: 1.1947882338558011\n",
            "Epoch 5/10, Loss: 1.130501159469185\n",
            "Epoch 6/10, Loss: 1.0893920783496573\n",
            "Epoch 7/10, Loss: 1.0567099930685195\n",
            "Epoch 8/10, Loss: 1.0298952349006671\n",
            "Epoch 9/10, Loss: 0.9990920134822426\n",
            "Epoch 10/10, Loss: 0.9827327857846799\n",
            "Test Accuracy: 69.66%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Teacher accuracy: {test_accuracy_deep:.2f}%\")\n",
        "print(f\"Student accuracy: {test_accuracy_light_ce:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xD-9amY6E-S",
        "outputId": "fb597b7b-2045-435c-9569-784fe80f85ef"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher accuracy: 79.25%\n",
            "Student accuracy: 69.66%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(nn_light.state_dict(), f\"{SAVE_PATH}/nn_light.pth\")"
      ],
      "metadata": {
        "id": "jtDzAr6Kmy2f"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distillated Student Model"
      ],
      "metadata": {
        "id": "YqL9zS88dS3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_knowledge_distillation(nn_deep, new_nn_light, train_dl, epochs=10, lr=0.001, T=2, soft_target_loss_weight=0.25, ce_loss_weight=0.75, device=device)\n",
        "test_accuracy_light_ce_and_kd = test(new_nn_light, test_dl, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwckxkVL6UX7",
        "outputId": "7eff74a2-5164-453d-cd13-e0110a8c2b94"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.9301316713738015\n",
            "Epoch 2/10, Loss: 1.5408039059480438\n",
            "Epoch 3/10, Loss: 1.3700120830170028\n",
            "Epoch 4/10, Loss: 1.2478109688100303\n",
            "Epoch 5/10, Loss: 1.167782247981147\n",
            "Epoch 6/10, Loss: 1.1021317158208783\n",
            "Epoch 7/10, Loss: 1.0567719520205427\n",
            "Epoch 8/10, Loss: 1.011583151719759\n",
            "Epoch 9/10, Loss: 0.9823337624140103\n",
            "Epoch 10/10, Loss: 0.9556450740150784\n",
            "Test Accuracy: 70.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(new_nn_light.state_dict(), f\"{SAVE_PATH}/new_nn_light.pth\")"
      ],
      "metadata": {
        "id": "HY8fvpFam2pY"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Teacher accuracy: {test_accuracy_deep:.2f}%\")\n",
        "print(f\"Student accuracy without teacher: {test_accuracy_light_ce:.2f}%\")\n",
        "print(f\"Student accuracy with CE + KD: {test_accuracy_light_ce_and_kd:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3iB_8MT6Xrc",
        "outputId": "f28add13-534b-4963-9405-6d240a70e9a2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher accuracy: 79.25%\n",
            "Student accuracy without teacher: 69.66%\n",
            "Student accuracy with CE + KD: 70.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## COS Pool Distllated Student Model"
      ],
      "metadata": {
        "id": "R4_s1C6UeGIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cos_pool_nn_light = LightNN(num_classes=10).to(device)"
      ],
      "metadata": {
        "id": "XOZAblDneKOQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_cosine_loss(nn_deep, cos_pool_nn_light, train_dl, epochs=10, lr=0.001, hidden_rep_loss_weight=0.25, ce_loss_weight=0.75, device=device)\n",
        "test_accuracy_light_ce_and_kd_cos_pool = test(cos_pool_nn_light, test_dl, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZB97hnZ9ezsb",
        "outputId": "d11feda0-5ae3-469f-9fd3-c1871aa5cac6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher embedding size: 2048\n",
            "Student embedding size: 1024\n",
            "Pooling kernel size: 2\n",
            "Epoch 1/10, Loss: 1.43088225513468\n",
            "Epoch 2/10, Loss: 1.2199425557080437\n",
            "Epoch 3/10, Loss: 1.1315733409293778\n",
            "Epoch 4/10, Loss: 1.0706597118426466\n",
            "Epoch 5/10, Loss: 1.0230807174197243\n",
            "Epoch 6/10, Loss: 0.9930553835676149\n",
            "Epoch 7/10, Loss: 0.9646160815987745\n",
            "Epoch 8/10, Loss: 0.9489797294292304\n",
            "Epoch 9/10, Loss: 0.9283358602572584\n",
            "Epoch 10/10, Loss: 0.9102163734033589\n",
            "Test Accuracy: 68.45%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## COS Proj Distllated Student Model"
      ],
      "metadata": {
        "id": "198Dj5zRe6zr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cos_proj_nn_light = LightNN(num_classes=10).to(device)"
      ],
      "metadata": {
        "id": "J-j3NkFSe6zr"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_cosine_loss_proj(nn_deep, cos_proj_nn_light, train_dl, 10, 0.001, 0.25, ce_loss_weight=0.75, device=device)\n",
        "test_accuracy_light_ce_and_kd_cos_proj = test(cos_proj_nn_light, test_dl, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVo9FswPe6zr",
        "outputId": "b36d1838-c73a-4f04-af6b-a87e99b7db09"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher embedding size: 2048\n",
            "Student embedding size: 1024\n",
            "Epoch 1/10, Loss: 1.4890597607473584\n",
            "Epoch 2/10, Loss: 1.2910036577288146\n",
            "Epoch 3/10, Loss: 1.1974697675546417\n",
            "Epoch 4/10, Loss: 1.1266944438905058\n",
            "Epoch 5/10, Loss: 1.079360692397408\n",
            "Epoch 6/10, Loss: 1.0356844101110687\n",
            "Epoch 7/10, Loss: 1.0136581846820119\n",
            "Epoch 8/10, Loss: 0.9868874568158709\n",
            "Epoch 9/10, Loss: 0.9689526736278973\n",
            "Epoch 10/10, Loss: 0.9526536088160542\n",
            "Test Accuracy: 70.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Teacher accuracy: {test_accuracy_deep:.2f}%\")\n",
        "print(f\"Student accuracy without teacher: {test_accuracy_light_ce:.2f}%\")\n",
        "print(f\"Student accuracy with CE + KD COS Pool: {test_accuracy_light_ce_and_kd_cos_pool:.2f}%\")\n",
        "print(f\"Student accuracy with CE + KD COS Proj: {test_accuracy_light_ce_and_kd_cos_proj:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaZhBzhXfGm9",
        "outputId": "63750965-86da-4fb8-efa6-df78f6f13753"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher accuracy: 79.25%\n",
            "Student accuracy without teacher: 69.66%\n",
            "Student accuracy with CE + KD COS Pool: 68.45%\n",
            "Student accuracy with CE + KD COS Proj: 70.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MSE Distllated Student Model"
      ],
      "metadata": {
        "id": "Lik1cXE3fFJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse_nn_light = LightNN(num_classes=10).to(device)"
      ],
      "metadata": {
        "id": "Hkw_7C-kfFJ7"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse_loss(nn_deep, mse_nn_light, train_dl, 10, 0.001, 0.25, ce_loss_weight=0.75, device=device)\n",
        "test_accuracy_light_ce_and_kd_mse = test(mse_nn_light, test_dl, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7LnpNj_fFJ7",
        "outputId": "aa281853-c084-4c11-c773-ca6577904c34"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.2881577461576827\n",
            "Epoch 2/10, Loss: 1.071609301792691\n",
            "Epoch 3/10, Loss: 0.988097681413831\n",
            "Epoch 4/10, Loss: 0.937765251949925\n",
            "Epoch 5/10, Loss: 0.9004530242032103\n",
            "Epoch 6/10, Loss: 0.869272967281244\n",
            "Epoch 7/10, Loss: 0.8422944977155427\n",
            "Epoch 8/10, Loss: 0.8251956388773516\n",
            "Epoch 9/10, Loss: 0.8051633097021781\n",
            "Epoch 10/10, Loss: 0.788013038580375\n",
            "Test Accuracy: 69.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Teacher accuracy: {test_accuracy_deep:.2f}%\")\n",
        "print(f\"Student accuracy without teacher: {test_accuracy_light_ce:.2f}%\")\n",
        "print(f\"Student accuracy with CE + KD MSE: {test_accuracy_light_ce_and_kd_mse:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OYl_-4Zfacz",
        "outputId": "f661c357-c411-47db-da3d-36575ec13e21"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher accuracy: 79.25%\n",
            "Student accuracy without teacher: 69.66%\n",
            "Student accuracy with CE + KD MSE: 69.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## QAT Base Student Model"
      ],
      "metadata": {
        "id": "Y4HCZo9SdXj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn_light_qat = LightNN(num_classes=10).to(device)\n",
        "nn_light_qat = prepare_qat_fx(nn_light_qat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y-fuY5w6qtp",
        "outputId": "07f75076-76ce-4954-978e-2e8b9f3d2306"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/quantize_fx.py:146: FutureWarning: Passing a QConfig dictionary to prepare is deprecated and will not be supported in a future version. Please pass in a QConfigMapping instead.\n",
            "  prepared = prepare(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_nn_light_qat = LightNN(num_classes=10).to(device)\n",
        "new_nn_light_qat = prepare_qat_fx(new_nn_light_qat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_rlTkq8-CFG",
        "outputId": "83b1d975-d5a6-4a3c-909d-39f4b3918348"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/quantize_fx.py:146: FutureWarning: Passing a QConfig dictionary to prepare is deprecated and will not be supported in a future version. Please pass in a QConfigMapping instead.\n",
            "  prepared = prepare(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cos_pool_nn_light_qat = LightNN(num_classes=10).to(device)\n",
        "cos_pool_nn_light_qat = prepare_qat_fx(cos_pool_nn_light_qat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkXi6emkf9h4",
        "outputId": "204e550e-9294-4d5e-8289-d85989ad7ca7"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/quantize_fx.py:146: FutureWarning: Passing a QConfig dictionary to prepare is deprecated and will not be supported in a future version. Please pass in a QConfigMapping instead.\n",
            "  prepared = prepare(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cos_proj_nn_light_qat = LightNN(num_classes=10).to(device)\n",
        "cos_proj_nn_light_qat = prepare_qat_fx(cos_proj_nn_light_qat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Sp9AWObgApB",
        "outputId": "f51d6c47-883c-4636-9755-d1aff33cecec"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/quantize_fx.py:146: FutureWarning: Passing a QConfig dictionary to prepare is deprecated and will not be supported in a future version. Please pass in a QConfigMapping instead.\n",
            "  prepared = prepare(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_nn_light_qat = LightNN(num_classes=10).to(device)\n",
        "mse_nn_light_qat = prepare_qat_fx(mse_nn_light_qat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee9aVxLJgC9D",
        "outputId": "1ebefa9f-6796-4b10-b818-b930be225c3c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/quantize_fx.py:146: FutureWarning: Passing a QConfig dictionary to prepare is deprecated and will not be supported in a future version. Please pass in a QConfigMapping instead.\n",
            "  prepared = prepare(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(nn_light_qat, train_dl, epochs=10, learning_rate=0.001, device=device)\n",
        "test_accuracy_light_qat_ce = test(nn_light_qat, test_dl, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tEeU_gl-GFU",
        "outputId": "f6ca3373-3747-4913-c62e-823711d88c18"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.705483193592647\n",
            "Epoch 2/10, Loss: 1.3798409557098623\n",
            "Epoch 3/10, Loss: 1.245113938665756\n",
            "Epoch 4/10, Loss: 1.157856786647416\n",
            "Epoch 5/10, Loss: 1.0918839682093666\n",
            "Epoch 6/10, Loss: 1.044563437514293\n",
            "Epoch 7/10, Loss: 1.0187929763513452\n",
            "Epoch 8/10, Loss: 0.9892782256426409\n",
            "Epoch 9/10, Loss: 0.9624277299932201\n",
            "Epoch 10/10, Loss: 0.9512704305941492\n",
            "Test Accuracy: 69.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(nn_light_qat.state_dict(), f\"{SAVE_PATH}/nn_light_qat.pth\")"
      ],
      "metadata": {
        "id": "7hVITXPdnBj8"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## QAT Distillated Student Model"
      ],
      "metadata": {
        "id": "Glfr1BQmdj4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_knowledge_distillation(nn_deep, new_nn_light_qat, train_dl, epochs=10, lr=0.001, T=2, soft_target_loss_weight=0.25, ce_loss_weight=0.75, device=device)\n",
        "test_accuracy_light_qat_ce_and_kd = test(new_nn_light_qat, test_dl, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1OEWafK-IwS",
        "outputId": "0538b44e-a54e-4a39-c795-cb067c8fb9e2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 2.016908584958147\n",
            "Epoch 2/10, Loss: 1.5323560283616986\n",
            "Epoch 3/10, Loss: 1.3478092696050854\n",
            "Epoch 4/10, Loss: 1.2342640627985415\n",
            "Epoch 5/10, Loss: 1.1556020444616333\n",
            "Epoch 6/10, Loss: 1.1010504811621078\n",
            "Epoch 7/10, Loss: 1.05998781331055\n",
            "Epoch 8/10, Loss: 1.022975729097186\n",
            "Epoch 9/10, Loss: 0.9903042057286138\n",
            "Epoch 10/10, Loss: 0.9632899747480212\n",
            "Test Accuracy: 69.16%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(new_nn_light_qat.state_dict(), f\"{SAVE_PATH}/new_nn_light_qat.pth\")"
      ],
      "metadata": {
        "id": "25LmI1-3nJGA"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## QAT COS Pool Distllated Student Model"
      ],
      "metadata": {
        "id": "ywfn3EvrflcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_cosine_loss(nn_deep, cos_pool_nn_light_qat, train_dl, 10, 0.001, 0.25, ce_loss_weight=0.75, device=device)\n",
        "test_accuracy_light_qat_ce_and_kd_cos_pool = test(cos_pool_nn_light_qat, test_dl, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "RmHOL_TvflcO",
        "outputId": "0e8ff522-a7c1-45e0-f4ff-851871213e3d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'GraphModule' object has no attribute 'get_emb'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4192876437.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_cosine_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_deep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcos_pool_nn_light_qat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mce_loss_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_accuracy_light_qat_ce_and_kd_cos_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcos_pool_nn_light_qat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1825657925.py\u001b[0m in \u001b[0;36mtrain_cosine_loss\u001b[0;34m(teacher, student, train_dl, epochs, lr, hidden_rep_loss_weight, ce_loss_weight, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_dummy_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent_dummy_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mteacher_emb_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteacher_dummy_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1929\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'GraphModule' object has no attribute 'get_emb'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## QAT COS Proj Distllated Student Model"
      ],
      "metadata": {
        "id": "4BuT8DsSflcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_cosine_loss_proj(nn_deep, cos_proj_nn_light_qat, train_dl, 10, 0.001, 0.25, ce_loss_weight=0.75, device=device)\n",
        "test_accuracy_light_qat_ce_and_kd_cos_proj = test(cos_proj_nn_light_qat, test_dl, device)"
      ],
      "metadata": {
        "id": "xqpW8HQqflcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Teacher accuracy: {test_accuracy_deep:.2f}%\")\n",
        "print(f\"Student accuracy without teacher: {test_accuracy_light_qat_ce:.2f}%\")\n",
        "print(f\"Student accuracy with CE + KD COS Pool: {test_accuracy_light_qat_ce_and_kd_cos_pool:.2f}%\")\n",
        "print(f\"Student accuracy with CE + KD COS Proj: {test_accuracy_light_qat_ce_and_kd_cos_proj:.2f}%\")"
      ],
      "metadata": {
        "id": "azWdWMmBflcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## QAT MSE Distllated Student Model"
      ],
      "metadata": {
        "id": "4_Kq_GmCflcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse_loss(nn_deep, mse_nn_light_qat, train_dl, 10, 0.001, 0.25, ce_loss_weight=0.75, device=device)\n",
        "test_accuracy_light_qat_ce_and_kd_mse = test(mse_nn_light_qat, test_dl, device)"
      ],
      "metadata": {
        "id": "OYnVfESrflcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Teacher accuracy: {test_accuracy_deep:.2f}%\")\n",
        "print(f\"Student accuracy without teacher: {test_accuracy_light_qat_ce:.2f}%\")\n",
        "print(f\"Student accuracy with CE + KD MSE: {test_accuracy_light_qat_ce_and_kd_mse:.2f}%\")"
      ],
      "metadata": {
        "id": "GvnKwuAsflcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "eKncwB5AdoO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn_light_quantised = prepare_post_static_quantize_fx(nn_light, test_dl)\n",
        "nn_light_quantised = convert_fx(nn_light_quantised)\n",
        "\n",
        "new_nn_light_quantised = prepare_post_static_quantize_fx(new_nn_light, test_dl)\n",
        "new_nn_light_quantised = convert_fx(new_nn_light_quantised)\n",
        "\n",
        "test_accuracy_light_quantised_ce = test(nn_light_quantised, test_dl, device)\n",
        "test_accuracy_light_quantised_ce_and_kd = test(new_nn_light_quantised, test_dl, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zl7clRvd-W5q",
        "outputId": "5cdcf1f8-b309-4773-87ff-d2281a52f6e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/quantize_fx.py:146: FutureWarning: Passing a QConfig dictionary to prepare is deprecated and will not be supported in a future version. Please pass in a QConfigMapping instead.\n",
            "  prepared = prepare(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/quantize_fx.py:146: FutureWarning: Passing a QConfig dictionary to prepare is deprecated and will not be supported in a future version. Please pass in a QConfigMapping instead.\n",
            "  prepared = prepare(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn_light_qat_quantised = convert_fx(nn_light_qat)\n",
        "new_nn_light_qat_quantised = convert_fx(new_nn_light_qat)\n",
        "\n",
        "test_accuracy_light_qat_quantised_ce = test(nn_light_qat_quantised, test_dl, device)\n",
        "test_accuracy_light_qat_quantised_ce_and_kd = test(new_nn_light_qat_quantised, test_dl, device)"
      ],
      "metadata": {
        "id": "IRttnul8-jkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Teacher accuracy: {test_accuracy_deep:.2f}%\")\n",
        "print(f\"Student accuracy without teacher: {test_accuracy_light_ce:.2f}%\")\n",
        "print(f\"Student accuracy with CE + KD: {test_accuracy_light_ce_and_kd:.2f}%\")\n",
        "print(f\"Student QAT accuracy without teacher: {test_accuracy_light_qat_ce:.2f}%\")\n",
        "print(f\"Student QAT accuracy with CE + KD: {test_accuracy_light_qat_ce_and_kd:.2f}%\")"
      ],
      "metadata": {
        "id": "bJzGbV_x-Rj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Student Quantised accuracy without teacher: {test_accuracy_light_quantised_ce:.2f}%\")\n",
        "print(f\"Student Quantised accuracy with CE + KD: {test_accuracy_light_quantised_ce_and_kd:.2f}%\")\n",
        "print(f\"Student Quantised QAT accuracy without teacher: {test_accuracy_light_qat_quantised_ce:.2f}%\")\n",
        "print(f\"Student Quantised QAT accuracy with CE + KD: {test_accuracy_light_qat_quantised_ce_and_kd:.2f}%\")"
      ],
      "metadata": {
        "id": "9HjGKcbr-vCh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}