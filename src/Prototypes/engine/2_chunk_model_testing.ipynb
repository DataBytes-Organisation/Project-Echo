{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Analysis and Sound Event Detection using 2-chunk model\n",
    "### Author: Rohit Dhanda\n",
    "\n",
    "## Overview\n",
    "\n",
    "This script is designed to perform audio analysis and sound event detection, notably to facilitate the testing on a two-chunk model. Utilizing the pre-trained deep learning model, YAMNet, it performs sound event detection on audio files. It classifies detected events into various classes and filters out specific events of interest such as animal-related sounds.\n",
    "\n",
    "## Libraries and Models\n",
    "\n",
    "### Libraries:\n",
    "- **pickle:** For deserializing data from the file storage.\n",
    "- **numpy and pandas:** Essential libraries for data handling and manipulation.\n",
    "- **soundfile and librosa:** Libraries used to process and handle audio files.\n",
    "- **tensorflow and tensorflow_hub:** To work with the pre-trained YAMNet model from TensorFlow Hub.\n",
    "\n",
    "### Models:\n",
    "- **YAMNet:** A deep learning model pre-trained to classify a wide array of audio events. It's loaded both from a local setup and from TensorFlow Hub.\n",
    "- **model_2_79.h5:** A custom trained model for specific classifications, used in tandem with YAMNet for precise event detection.\n",
    "\n",
    "## Functions\n",
    "\n",
    "### 1. load_audio_file\n",
    "- **Input:** File path of the audio file.\n",
    "- **Output:** A NumPy array of the audio data.\n",
    "- **Description:** It uses librosa to load an audio file with a standard sampling rate of 16000 Hz.\n",
    "\n",
    "### 2. extract_features\n",
    "- **Input:** The YAMNet model and an array of audio data.\n",
    "- **Output:** An array with the extracted features.\n",
    "- **Description:** This function utilizes the YAMNet model to extract embeddings from each frame in the audio data array, returning the mean of the embeddings.\n",
    "\n",
    "### 3. predict_on_audio\n",
    "- **Input:** Binary representation of audio data.\n",
    "- **Output:** The top two class predictions along with their corresponding probabilities.\n",
    "- **Description:** It writes the binary audio data to a temporary file from which features are extracted and then used by the custom model to make predictions.\n",
    "\n",
    "### 4. sound_event_detection\n",
    "- **Input:** File path of the audio file.\n",
    "- **Output:** A pandas dataframe recording the start and end times of detected sound events along with the top two class predictions and their probabilities.\n",
    "- **Description:** \n",
    "  - **Step 1:** It divides the audio file into 1-second chunks.\n",
    "  - **Step 2:** Using YAMNet, it iterates over each chunk to make sound event predictions.\n",
    "  - **Step 3:** If a chunk is recognized as containing animal-related sounds based on a predetermined threshold, it is stored in a buffer.\n",
    "  - **Step 4:** When a non-animal-related sound is detected, the buffered chunks are processed to make a final prediction using the custom model.\n",
    "  - **Step 5:** It then records the details such as the start and end time of the sound event and the top two class predictions into a dataframe.\n",
    "  - **Step 6:** Handles the end case where the last chunk contains an animal-related sound, ensuring it is processed correctly.\n",
    "\n",
    "### Animal-Related Classes\n",
    "A predefined set of labels used to identify and isolate animal-related sounds from the predictions generated by YAMNet.\n",
    "\n",
    "## Usage\n",
    "\n",
    "To utilize this script for sound event detection and testing on a two-chunk model:\n",
    "1. Set the file path of the audio file you wish to analyze in the `filename` variable.\n",
    "2. Call the `sound_event_detection` function with the `filename` as the parameter.\n",
    "3. The function will return a pandas dataframe with details of each detected sound event.\n",
    "4. Print the dataframe to visualize the results, noting each sound event's start and end times, and the top two predictions with their probabilities.\n",
    "\n",
    "## Note\n",
    "- Ensure the necessary files and models are correctly loaded at the beginning of the script.\n",
    "- Adjust the threshold value in the `sound_event_detection` function as necessary to correctly classify chunks as containing animal-related sounds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import yamnet.params as params\n",
    "import yamnet.yamnet as yamnet_model\n",
    "import librosa\n",
    "from tensorflow.keras.models import load_model\n",
    "import tempfile\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary data and models\n",
    "with open('yamnet/class_names.pkl', 'rb') as f:\n",
    "    class_names = pickle.load(f)\n",
    "\n",
    "with open('yamnet/label_encoder.pkl', 'rb') as f:\n",
    "    le = pickle.load(f)\n",
    "\n",
    "yamnet = yamnet_model.yamnet_frames_model(params)\n",
    "yamnet.load_weights('yamnet/yamnet.h5')\n",
    "yamnet_classes = yamnet_model.class_names('yamnet/yamnet_class_map.csv')\n",
    "model = load_model('models/model_2_79.h5')\n",
    "\n",
    "# Load the YAMNet model\n",
    "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
    "yamnet_model = hub.load(yamnet_model_handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_audio_file(file_path):\n",
    "    wav, sr = librosa.load(file_path, sr=16000)\n",
    "    return np.array([wav])\n",
    "\n",
    "def extract_features(model, X):\n",
    "    features = []\n",
    "    for wav in X:\n",
    "        scores, embeddings, spectrogram = model(wav)\n",
    "        features.append(embeddings.numpy().mean(axis=0))\n",
    "    return np.array(features)\n",
    "\n",
    "def predict_on_audio(binary_audio):\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_audio_file:\n",
    "        with open(temp_audio_file.name, 'wb') as f:\n",
    "            f.write(binary_audio)\n",
    "        X_new = load_audio_file(temp_audio_file.name)\n",
    "        X_new_features = extract_features(yamnet_model, X_new)\n",
    "\n",
    "        predictions = model.predict(X_new_features)\n",
    "        top_two_prob_indices = np.argsort(predictions[0])[-2:]\n",
    "        top_two_prob_values = predictions[0][top_two_prob_indices]\n",
    "\n",
    "        top_two_class_names = le.inverse_transform(top_two_prob_indices)\n",
    "        \n",
    "        return [(class_names[top_two_prob_indices[1-i]], top_two_prob_values[1-i]) for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/jx74xxwd0qgct2nvjkzx_m1h0000gn/T/ipykernel_77522/3583565354.py:55: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  data, sr = librosa.load(filepath, sr=16000)\n",
      "/Users/ankush/anaconda3/envs/new_env/lib/python3.9/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "2023-09-15 21:51:35.478562: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 21:51:35.919682: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "   start_time  end_time     echonet_label_1  echonet_confidence_1  \\\n",
      "0           4         9  Strepera Graculina              0.999611   \n",
      "1          20        22         Felis Catus              0.966280   \n",
      "2          32        34   Rattus Norvegicus              0.618285   \n",
      "3          51        56          Sus_Scrofa              0.673910   \n",
      "4          63        66          Sus_Scrofa              0.668935   \n",
      "5          67        69         Felis Catus              0.919543   \n",
      "\n",
      "           echonet_label_2  echonet_confidence_2  \n",
      "0  Colluricincla Harmonica              0.000279  \n",
      "1        Corvus Coronoides              0.024591  \n",
      "2  Colluricincla Harmonica              0.146041  \n",
      "3              Felis Catus              0.134276  \n",
      "4              Felis Catus              0.330683  \n",
      "5        Rattus Norvegicus              0.035131  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ankush/anaconda3/envs/new_env/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/ankush/anaconda3/envs/new_env/lib/python3.9/site-packages/numpy/core/_methods.py:184: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def sound_event_detection(filepath):\n",
    "    data, sr = librosa.load(filepath, sr=48000)\n",
    "    frame_len = int(sr * 1)\n",
    "    num_chunks = len(data) // frame_len\n",
    "    chunks = [data[i*frame_len:(i+1)*frame_len] for i in range(num_chunks)]\n",
    "\n",
    "    # Adding the last chunk which can be less than 1 second\n",
    "    last_chunk = data[num_chunks*frame_len:]\n",
    "    if len(last_chunk) > 0:\n",
    "        chunks.append(last_chunk)\n",
    "\n",
    "    animal_related_classes = [\n",
    "        'Dog', 'Cat', 'Bird', 'Animal', 'Birdsong', 'Canidae', 'Feline', 'Livestock',\n",
    "        'Rodents, Mice', 'Wild animals', 'Pets', 'Frogs', 'Insect', 'Snake', \n",
    "        'Domestic animals, pets', 'crow'\n",
    "    ]\n",
    "\n",
    "    df_rows = []\n",
    "    buffer = []\n",
    "    start_time = None\n",
    "    for cnt, frame_data in enumerate(chunks):\n",
    "        frame_data = np.reshape(frame_data, (-1,)) # Flatten the array to 1D\n",
    "        frame_data = np.array([frame_data]) # Wrapping it back into a 2D array\n",
    "        outputs = yamnet(frame_data)\n",
    "        yamnet_prediction = np.mean(outputs[0], axis=0)\n",
    "        top2_i = np.argsort(yamnet_prediction)[::-1][:2]\n",
    "        threshold=0.10\n",
    "        if any(yamnet_prediction[np.where(yamnet_classes == cls)[0][0]] >= threshold for cls in animal_related_classes if cls in yamnet_classes):\n",
    "            if start_time is None:\n",
    "                start_time = cnt\n",
    "            buffer.append(frame_data)\n",
    "        else:\n",
    "            if start_time is not None:\n",
    "                segment_data = np.concatenate(buffer, axis=1)[0]\n",
    "                with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_audio_file:\n",
    "                    sf.write(temp_audio_file.name, segment_data, sr)\n",
    "                    with open(temp_audio_file.name, 'rb') as binary_file:\n",
    "                        top2_predictions = predict_on_audio(binary_file.read())\n",
    "\n",
    "                df_row = {'start_time': start_time, 'end_time': cnt}\n",
    "                \n",
    "                for i, pred in enumerate(top2_predictions[:2]):\n",
    "                    df_row[f'echonet_label_{i+1}'] = pred[0] if pred[0] is not None else None\n",
    "                    df_row[f'echonet_confidence_{i+1}'] = pred[1] if pred[1] is not None else None\n",
    "\n",
    "                df_rows.append(df_row)\n",
    "                buffer = []\n",
    "                start_time = None\n",
    "\n",
    "    # Handling the case where the last chunk contains an animal-related sound\n",
    "    if start_time is not None:\n",
    "        segment_data = np.concatenate(buffer, axis=1)[0]\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_audio_file:\n",
    "            sf.write(temp_audio_file.name, segment_data, sr)\n",
    "            with open(temp_audio_file.name, 'rb') as binary_file:\n",
    "                top2_predictions = predict_on_audio(binary_file.read())\n",
    "\n",
    "        df_row = {'start_time': start_time, 'end_time': len(chunks)}\n",
    "        \n",
    "        for i, pred in enumerate(top2_predictions[:2]):\n",
    "            df_row[f'echonet_label_{i+1}'] = pred[0] if pred[0] is not None else None\n",
    "            df_row[f'echonet_confidence_{i+1}'] = pred[1] if pred[1] is not None else None\n",
    "\n",
    "        df_rows.append(df_row)\n",
    "\n",
    "    df = pd.DataFrame(df_rows)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Use the function\n",
    "filename = 'test5.m4a'\n",
    "df = sound_event_detection(filename)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>echonet_label_1</th>\n",
       "      <th>echonet_confidence_1</th>\n",
       "      <th>echonet_label_2</th>\n",
       "      <th>echonet_confidence_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>Strepera Graculina</td>\n",
       "      <td>0.999611</td>\n",
       "      <td>Colluricincla Harmonica</td>\n",
       "      <td>0.000279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>Felis Catus</td>\n",
       "      <td>0.966280</td>\n",
       "      <td>Corvus Coronoides</td>\n",
       "      <td>0.024591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>Rattus Norvegicus</td>\n",
       "      <td>0.618285</td>\n",
       "      <td>Colluricincla Harmonica</td>\n",
       "      <td>0.146041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>56</td>\n",
       "      <td>Sus_Scrofa</td>\n",
       "      <td>0.673910</td>\n",
       "      <td>Felis Catus</td>\n",
       "      <td>0.134276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>66</td>\n",
       "      <td>Sus_Scrofa</td>\n",
       "      <td>0.668935</td>\n",
       "      <td>Felis Catus</td>\n",
       "      <td>0.330683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>67</td>\n",
       "      <td>69</td>\n",
       "      <td>Felis Catus</td>\n",
       "      <td>0.919543</td>\n",
       "      <td>Rattus Norvegicus</td>\n",
       "      <td>0.035131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_time  end_time     echonet_label_1  echonet_confidence_1  \\\n",
       "0           4         9  Strepera Graculina              0.999611   \n",
       "1          20        22         Felis Catus              0.966280   \n",
       "2          32        34   Rattus Norvegicus              0.618285   \n",
       "3          51        56          Sus_Scrofa              0.673910   \n",
       "4          63        66          Sus_Scrofa              0.668935   \n",
       "5          67        69         Felis Catus              0.919543   \n",
       "\n",
       "           echonet_label_2  echonet_confidence_2  \n",
       "0  Colluricincla Harmonica              0.000279  \n",
       "1        Corvus Coronoides              0.024591  \n",
       "2  Colluricincla Harmonica              0.146041  \n",
       "3              Felis Catus              0.134276  \n",
       "4              Felis Catus              0.330683  \n",
       "5        Rattus Norvegicus              0.035131  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
