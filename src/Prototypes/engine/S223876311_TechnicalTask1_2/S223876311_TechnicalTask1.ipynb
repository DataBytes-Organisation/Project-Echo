{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff52978",
   "metadata": {},
   "source": [
    "\n",
    "# Project Echo — Task 1: Alternate Model **vs Baseline** (Suite‑Style Notebook)\n",
    "\n",
    "This notebook mirrors Dean’s benchmarking suite structure (configs + utils + orchestration) but stays **self‑contained** for Task 1.  \n",
    "It runs **one alternate model** (default: *MobileNetV2*) and optionally a **baseline** (default: *ResNet50*) so you can compare.\n",
    "\n",
    "**Mapping to the suite:**\n",
    "- `configs/*.py` → Config dataclasses below (`SystemConfig`, `MelSpecConfig`, `TrainConfig`, `ExperimentConfig`).\n",
    "- `utils/*.py` → Helper functions (dataset discovery, mel pipeline, DataSets, train/eval).\n",
    "- `Benchmarking_Framework.ipynb` → Orchestration cells at the end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a7cbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional installs (uncomment if needed)\n",
    "# !pip install librosa==0.10.1 soundfile==0.12.1 tensorflow==2.12.0 scikit-learn==1.4.2 matplotlib==3.8.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76977036",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, random, json\n",
    "from dataclasses import dataclass, asdict\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import librosa, soundfile as sf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Set seed early so everything else can use it\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aeac93",
   "metadata": {},
   "source": [
    "## Configs (suite-style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "233983b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output dir: ./outputs_task1\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class SystemConfig:\n",
    "    data_root: str = \"/Users/mankirat/Desktop/Deakin/DEAKIN25/Sem2/ProjectEcho/dataset/Bucket_1\"\n",
    "    output_dir: str = \"./outputs_task1\"\n",
    "    seed: int = SEED\n",
    "    device: str = \"GPU\"  # or \"CPU\"\n",
    "\n",
    "system_cfg = SystemConfig()\n",
    "\n",
    "@dataclass\n",
    "class MelSpecConfig:\n",
    "    sample_rate: int = 48000\n",
    "    clip_duration_s: int = 5\n",
    "    n_fft: int = 2048\n",
    "    hop_length: int = 200\n",
    "    n_mels: int = 260\n",
    "    fmin: int = 20\n",
    "    fmax: int = 13000\n",
    "    top_db: int = 80\n",
    "    image_size: tuple = (260, 260)  # (H, W)\n",
    "    channels: int = 3\n",
    "\n",
    "melspec_cfg = MelSpecConfig()\n",
    "\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    batch_size: int = 16\n",
    "    max_epochs: int = 50\n",
    "    learning_rate: float = 1e-4\n",
    "    early_stop_patience: int = 10\n",
    "    lr_plateau_patience: int = 6\n",
    "\n",
    "train_cfg = TrainConfig()\n",
    "\n",
    "@dataclass\n",
    "class ExperimentConfig:\n",
    "    # Run keys: choose any from model factory below\n",
    "    alt_model_key: str = \"mobilenet_v2_alt\"\n",
    "    baseline_model_key: str = \"resnet50_baseline\"\n",
    "    run_baseline: bool = True\n",
    "    val_size: float = 0.2\n",
    "    test_size: float = 0.1\n",
    "    stratify: bool = True\n",
    "\n",
    "exp_cfg = ExperimentConfig()\n",
    "\n",
    "Path(system_cfg.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "print(\"Output dir:\", system_cfg.output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740ca922",
   "metadata": {},
   "source": [
    "## Utils — Dataset discovery & splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65d7834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def discover_dataset(root: str, exts=('.wav','.mp3','.flac','.ogg')):\n",
    "    root = Path(root)\n",
    "    classes = sorted([d.name for d in root.iterdir() if d.is_dir()])\n",
    "    files, labels = [], []\n",
    "    for idx, cls in enumerate(classes):\n",
    "        for p in (root/cls).rglob(\"*\"):\n",
    "            if p.suffix.lower() in exts:\n",
    "                files.append(str(p)); labels.append(idx)\n",
    "    return classes, np.array(files), np.array(labels)\n",
    "\n",
    "def make_splits(files, labels, val_size=0.2, test_size=0.1, stratify=True, seed=SEED):\n",
    "    strat = labels if stratify else None\n",
    "    f_trainval, f_test, y_trainval, y_test = train_test_split(files, labels, test_size=test_size,\n",
    "                                                             random_state=seed, stratify=strat)\n",
    "    strat2 = y_trainval if stratify else None\n",
    "    relative_val = val_size / (1.0 - test_size)\n",
    "    f_train, f_val, y_train, y_val = train_test_split(f_trainval, y_trainval, test_size=relative_val,\n",
    "                                                      random_state=seed, stratify=strat2)\n",
    "    return (f_train, y_train), (f_val, y_val), (f_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3d04fb7-9824-4ebf-ba5d-dbf81a0b15b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def filter_min_count(files, labels, min_per_class=3):\n",
    "    files = np.array(files); labels = np.array(labels)\n",
    "    keep = []\n",
    "    for cls in np.unique(labels):\n",
    "        idx = np.where(labels == cls)[0]\n",
    "        if len(idx) >= min_per_class:\n",
    "            keep.extend(idx.tolist())\n",
    "    keep = np.array(sorted(keep))\n",
    "    return files[keep], labels[keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d649707",
   "metadata": {},
   "source": [
    "## Utils — Audio→Mel→Image (pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "428dfb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) (Optional but recommended) set MobileNet-friendly size\n",
    "melspec_cfg.image_size = (224, 224)  # (H, W)\n",
    "\n",
    "# 2) Replace your load_audio_to_mel with this PURE NumPy/Python version\n",
    "from PIL import Image\n",
    "\n",
    "def load_audio_to_mel(path, cfg: MelSpecConfig):\n",
    "    # --- read path from tf.numpy_function (bytes) ---\n",
    "    if isinstance(path, (bytes, bytearray)):\n",
    "        path = path.decode()\n",
    "\n",
    "    # --- load audio, pad/trim to fixed duration ---\n",
    "    y, sr = librosa.load(path, sr=cfg.sample_rate, mono=True)\n",
    "    target_len = int(cfg.clip_duration_s * cfg.sample_rate)\n",
    "    if len(y) < target_len:\n",
    "        y = np.pad(y, (0, target_len - len(y)))\n",
    "    elif len(y) > target_len:\n",
    "        y = y[:target_len]\n",
    "\n",
    "    # --- mel spectrogram in dB, normalized to [0,1] ---\n",
    "    S = librosa.feature.melspectrogram(\n",
    "        y=y, sr=cfg.sample_rate, n_fft=cfg.n_fft, hop_length=cfg.hop_length,\n",
    "        n_mels=cfg.n_mels, fmin=cfg.fmin, fmax=cfg.fmax\n",
    "    )\n",
    "    S_db = librosa.power_to_db(S, top_db=cfg.top_db, ref=np.max)  # shape: (n_mels, time)\n",
    "    img = S_db.T  # (time, mels)\n",
    "\n",
    "    # min-max normalize (avoid div by zero)\n",
    "    mn, mx = img.min(), img.max()\n",
    "    if mx > mn:\n",
    "        img = (img - mn) / (mx - mn)\n",
    "    else:\n",
    "        img = np.zeros_like(img, dtype=np.float32)\n",
    "\n",
    "    # --- resize to (H,W) using PIL (no TF ops here) ---\n",
    "    # PIL expects (W,H), so reverse when passing size\n",
    "    pil_img = Image.fromarray((img * 255).astype(np.uint8))\n",
    "    pil_img = pil_img.resize((cfg.image_size[1], cfg.image_size[0]), resample=Image.BICUBIC)\n",
    "\n",
    "    arr = np.asarray(pil_img).astype(np.float32) / 255.0  # (H, W)\n",
    "    if arr.ndim == 2:\n",
    "        arr = np.repeat(arr[..., None], cfg.channels, axis=-1)  # (H, W, C)\n",
    "\n",
    "    return arr.astype(np.float32)  # pure numpy array, no tf ops\n",
    "\n",
    "\n",
    "# Keep your existing load_audio_to_mel(path, melspec_cfg) as-is\n",
    "# 1) Discover dataset\n",
    "CLASS_NAMES, FILES, LABELS = discover_dataset(system_cfg.data_root)\n",
    "CLASS_NAMES = np.array(CLASS_NAMES)\n",
    "NUM_CLASSES = int(len(CLASS_NAMES))  # set once after you set CLASS_NAMES\n",
    "\n",
    "def _load_with_cfg(path):\n",
    "    # path comes in as a numpy bytes/str; we use the global melspec_cfg\n",
    "    return load_audio_to_mel(path, melspec_cfg)\n",
    "\n",
    "def tf_load_mel_map(path, label):\n",
    "    # Only pass Tensors to numpy_function; capture config via closure\n",
    "    img = tf.numpy_function(_load_with_cfg, [path], tf.float32)\n",
    "    img.set_shape((melspec_cfg.image_size[0], melspec_cfg.image_size[1], melspec_cfg.channels))\n",
    "    one_hot = tf.one_hot(label, depth=NUM_CLASSES)   # use a Python int, not tf.shape(...)\n",
    "    one_hot.set_shape((NUM_CLASSES,))\n",
    "    return img, one_hot\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def build_dataset(file_paths, labels, batch_size, shuffle=False):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
    "    if shuffle: ds = ds.shuffle(len(file_paths), seed=SEED)\n",
    "    ds = ds.map(tf_load_mel_map, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(batch_size).prefetch(AUTOTUNE)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9763d8c4",
   "metadata": {},
   "source": [
    "## Model factory (alternate + baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78b33ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(model_key: str, num_classes: int, input_shape=(260,260,3), lr=1e-4):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    if model_key == \"mobilenet_v2_alt\":\n",
    "        base = tf.keras.applications.MobileNetV2(include_top=False, weights=\"imagenet\",\n",
    "                                                 input_shape=input_shape, pooling=\"avg\")\n",
    "    elif model_key == \"resnet50_baseline\":\n",
    "        base = tf.keras.applications.ResNet50(include_top=False, weights=\"imagenet\",\n",
    "                                              input_shape=input_shape, pooling=\"avg\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model_key: {model_key}\")\n",
    "\n",
    "    x = base(inputs, training=True)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(num_classes * 8, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(num_classes * 4, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    logits = tf.keras.layers.Dense(num_classes, activation=None)(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, logits)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aa4652",
   "metadata": {},
   "source": [
    "## Train / Evaluate helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e331589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, train_ds, val_ds, out_dir: str):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    ckpt_path = os.path.join(out_dir, \"best.h5\")\n",
    "    cbs = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(ckpt_path, monitor=\"val_loss\", mode=\"min\",\n",
    "                                           save_best_only=True, save_weights_only=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.75, patience=6),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "    ]\n",
    "    hist = model.fit(train_ds, validation_data=val_ds, epochs=train_cfg.max_epochs, callbacks=cbs, verbose=1)\n",
    "    return hist, ckpt_path\n",
    "\n",
    "def evaluate_model(model, test_ds, class_names):\n",
    "    y_true, y_pred = [], []\n",
    "    for xb, yb in test_ds:\n",
    "        logits = model.predict(xb, verbose=0)\n",
    "        y_pred.extend(np.argmax(logits, axis=1).tolist())\n",
    "        y_true.extend(np.argmax(yb.numpy(), axis=1).tolist())\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names, digits=3))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return macro_f1, cm\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, title=\"Confusion Matrix\"):\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    im = ax.imshow(cm, interpolation='nearest')\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=class_names, yticklabels=class_names,\n",
    "           ylabel='True label', xlabel='Predicted label', title=title)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    fig.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26218304",
   "metadata": {},
   "source": [
    "## Orchestration — Build data once (shared splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c9694b-c730-4196-a5fa-9f9faf4dcb70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64fc729b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes total: 118 | Min per-class count (after filtering): 2\n",
      "⚠️ Stratified split failed with current sizes: The test_size = 36 should be greater or equal to the number of classes = 118\n",
      "➡️ Retrying with bumped sizes: test_size=0.334, val_size=0.331\n",
      "⚠️ Bumped stratified split still failed: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.\n",
      "➡️ Falling back to NON-stratified split so training can proceed.\n",
      "Train: 246, Val: 71, Test: 36 | Classes: 118\n",
      "Metal device set to: Apple M2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-08 20:28:31.239184: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-09-08 20:28:31.239516: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-09-08 20:28:31.408948: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch shapes: (16, 224, 224, 3) (16, 118)\n"
     ]
    }
   ],
   "source": [
    "# === ALL-IN-ONE: discover -> filter -> remap -> safe split -> build datasets ===\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "assert Path(system_cfg.data_root).exists(), \"Update system_cfg.data_root to your dataset path.\"\n",
    "\n",
    "# 1) Discover dataset (requires discover_dataset() to be defined already)\n",
    "CLASS_NAMES, FILES, LABELS = discover_dataset(system_cfg.data_root)\n",
    "CLASS_NAMES = np.array(CLASS_NAMES)\n",
    "\n",
    "# 2) Filter classes with < 2 samples (prevents stratified split errors)\n",
    "counts = Counter(LABELS.tolist())\n",
    "valid_old_labels = sorted([c for c, n in counts.items() if n >= 2])\n",
    "\n",
    "# Keep only those samples\n",
    "keep_idx = [i for i, l in enumerate(LABELS) if l in valid_old_labels]\n",
    "FILES2  = np.array(FILES)[keep_idx]\n",
    "LABELS2 = np.array(LABELS)[keep_idx]\n",
    "\n",
    "# 3) Remap labels to 0..K-1 based on kept classes\n",
    "kept_classes = [CLASS_NAMES[i] for i in valid_old_labels]  # names of kept classes in old order\n",
    "old_to_new = {old:i for i, old in enumerate(valid_old_labels)}\n",
    "LABELS2 = np.array([old_to_new[l] for l in LABELS2], dtype=int)\n",
    "CLASS_NAMES = np.array(kept_classes)\n",
    "\n",
    "print(f\"Classes total: {len(CLASS_NAMES)} | Min per-class count (after filtering): \"\n",
    "      f\"{min(Counter(LABELS2.tolist()).values() or [0])}\")\n",
    "\n",
    "# 4) Safe stratified split with bump + fallback\n",
    "def safe_stratified_splits(files, labels, val_size, test_size, seed):\n",
    "    files = np.array(files); labels = np.array(labels)\n",
    "    n = len(labels)\n",
    "    n_classes = len(np.unique(labels))\n",
    "\n",
    "    def _do_split(vs, ts, stratify=True):\n",
    "        strat = labels if stratify else None\n",
    "        f_trainval, f_test, y_trainval, y_test = train_test_split(\n",
    "            files, labels, test_size=ts, random_state=seed, stratify=strat\n",
    "        )\n",
    "        rel_val = vs / (1.0 - ts)\n",
    "        strat2 = y_trainval if stratify else None\n",
    "        f_train, f_val, y_train, y_val = train_test_split(\n",
    "            f_trainval, y_trainval, test_size=rel_val, random_state=seed, stratify=strat2\n",
    "        )\n",
    "        return (f_train, y_train), (f_val, y_val), (f_test, y_test)\n",
    "\n",
    "    # try as-is\n",
    "    try:\n",
    "        return _do_split(val_size, test_size, stratify=True)\n",
    "    except ValueError as e:\n",
    "        print(\"⚠️ Stratified split failed with current sizes:\", e)\n",
    "\n",
    "    # bump sizes to ensure ≥1 sample/class in each split\n",
    "    min_frac = n_classes / max(n, 1)\n",
    "    bumped_test = max(test_size, min_frac + 1e-6)\n",
    "    bumped_val  = max(val_size,  min_frac + 1e-6)\n",
    "\n",
    "    # ensure train size also ≥ n_classes\n",
    "    max_val_allowed = 1.0 - bumped_test - min_frac - 1e-6\n",
    "    if bumped_val > max_val_allowed:\n",
    "        bumped_val = max_val_allowed\n",
    "\n",
    "    if bumped_test + bumped_val >= 1.0 - 1e-6:\n",
    "        print(\"⚠️ Not enough samples to keep stratification with all classes.\")\n",
    "    else:\n",
    "        try:\n",
    "            print(f\"➡️ Retrying with bumped sizes: test_size={bumped_test:.3f}, val_size={bumped_val:.3f}\")\n",
    "            return _do_split(bumped_val, bumped_test, stratify=True)\n",
    "        except ValueError as e2:\n",
    "            print(\"⚠️ Bumped stratified split still failed:\", e2)\n",
    "\n",
    "    print(\"➡️ Falling back to NON-stratified split so training can proceed.\")\n",
    "    return _do_split(val_size, test_size, stratify=False)\n",
    "\n",
    "# 5) Make splits (uses exp_cfg/train_cfg/system_cfg already defined)\n",
    "(train_f, train_y), (val_f, val_y), (test_f, test_y) = safe_stratified_splits(\n",
    "    FILES2, LABELS2, val_size=exp_cfg.val_size, test_size=exp_cfg.test_size, seed=system_cfg.seed\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_f)}, Val: {len(val_f)}, Test: {len(test_f)} | Classes: {len(CLASS_NAMES)}\")\n",
    "\n",
    "# 6) Build tf.data datasets (requires build_dataset() to be defined already)\n",
    "train_ds = build_dataset(train_f, train_y, batch_size=train_cfg.batch_size, shuffle=True)\n",
    "val_ds   = build_dataset(val_f,   val_y,   batch_size=train_cfg.batch_size, shuffle=False)\n",
    "test_ds  = build_dataset(test_f,  test_y,  batch_size=train_cfg.batch_size, shuffle=False)\n",
    "\n",
    "# quick sanity check\n",
    "for xb, yb in train_ds.take(1):\n",
    "    print(\"Sample batch shapes:\", xb.shape, yb.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7a9cf3",
   "metadata": {},
   "source": [
    "## Run Alternate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcd432e9-2320-4888-9a92-d3a29b6c6a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch X: (16, 224, 224, 3) | Batch y: (16, 118)\n"
     ]
    }
   ],
   "source": [
    "# Build tf.data datasets from the split file lists\n",
    "train_ds = build_dataset(train_f, train_y, batch_size=train_cfg.batch_size, shuffle=True)\n",
    "val_ds   = build_dataset(val_f,   val_y,   batch_size=train_cfg.batch_size, shuffle=False)\n",
    "test_ds  = build_dataset(test_f,  test_y,  batch_size=train_cfg.batch_size, shuffle=False)\n",
    "\n",
    "# Quick sanity check\n",
    "for xb, yb in train_ds.take(1):\n",
    "    print(\"Batch X:\", xb.shape, \"| Batch y:\", yb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "874185ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " mobilenetv2_1.00_224 (Funct  (None, 1280)             2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1280)             5120      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 944)               1209264   \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 944)              3776      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 472)               446040    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 472)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 118)               55814     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,977,998\n",
      "Trainable params: 3,939,438\n",
      "Non-trainable params: 38,560\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-08 20:28:39.173338: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - ETA: 0s - loss: 5.8452 - accuracy: 0.0163"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-08 20:29:10.504941: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 43s 2s/step - loss: 5.8452 - accuracy: 0.0163 - val_loss: 4.9142 - val_accuracy: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 29s 2s/step - loss: 4.9170 - accuracy: 0.0447 - val_loss: 4.9004 - val_accuracy: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 30s 2s/step - loss: 4.2365 - accuracy: 0.0935 - val_loss: 4.8776 - val_accuracy: 0.0141 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 30s 2s/step - loss: 3.5566 - accuracy: 0.1463 - val_loss: 4.8793 - val_accuracy: 0.0282 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 33s 2s/step - loss: 2.8739 - accuracy: 0.3537 - val_loss: 4.8409 - val_accuracy: 0.0282 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 29s 2s/step - loss: 2.3012 - accuracy: 0.5203 - val_loss: 4.8364 - val_accuracy: 0.0282 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 28s 2s/step - loss: 2.0943 - accuracy: 0.5772 - val_loss: 4.8378 - val_accuracy: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 29s 2s/step - loss: 1.6243 - accuracy: 0.6992 - val_loss: 4.8027 - val_accuracy: 0.0704 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 29s 2s/step - loss: 1.2532 - accuracy: 0.8293 - val_loss: 4.7721 - val_accuracy: 0.0845 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 31s 2s/step - loss: 1.0328 - accuracy: 0.8618 - val_loss: 4.7724 - val_accuracy: 0.0704 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 29s 2s/step - loss: 0.8963 - accuracy: 0.9024 - val_loss: 4.8048 - val_accuracy: 0.0704 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 31s 2s/step - loss: 0.7035 - accuracy: 0.9146 - val_loss: 4.7906 - val_accuracy: 0.0563 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 31s 2s/step - loss: 0.6444 - accuracy: 0.9309 - val_loss: 4.7823 - val_accuracy: 0.0704 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 29s 2s/step - loss: 0.5298 - accuracy: 0.9593 - val_loss: 4.8008 - val_accuracy: 0.1127 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 33s 2s/step - loss: 0.4655 - accuracy: 0.9675 - val_loss: 4.8021 - val_accuracy: 0.0704 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 28s 2s/step - loss: 0.4107 - accuracy: 0.9715 - val_loss: 4.7864 - val_accuracy: 0.0845 - lr: 7.5000e-05\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 28s 2s/step - loss: 0.3401 - accuracy: 0.9797 - val_loss: 4.7825 - val_accuracy: 0.0704 - lr: 7.5000e-05\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 29s 2s/step - loss: 0.3673 - accuracy: 0.9797 - val_loss: 4.7686 - val_accuracy: 0.0845 - lr: 7.5000e-05\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 28s 2s/step - loss: 0.3147 - accuracy: 0.9675 - val_loss: 4.7673 - val_accuracy: 0.0845 - lr: 7.5000e-05\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 29s 2s/step - loss: 0.2651 - accuracy: 0.9878 - val_loss: 4.8043 - val_accuracy: 0.0986 - lr: 7.5000e-05\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 28s 2s/step - loss: 0.2165 - accuracy: 0.9919 - val_loss: 4.8398 - val_accuracy: 0.0986 - lr: 7.5000e-05\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 29s 2s/step - loss: 0.2381 - accuracy: 0.9878 - val_loss: 4.8591 - val_accuracy: 0.0845 - lr: 7.5000e-05\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 29s 2s/step - loss: 0.2119 - accuracy: 0.9919 - val_loss: 4.8361 - val_accuracy: 0.0986 - lr: 7.5000e-05\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 29s 2s/step - loss: 0.1806 - accuracy: 0.9959 - val_loss: 4.8493 - val_accuracy: 0.0704 - lr: 7.5000e-05\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 27s 2s/step - loss: 0.1519 - accuracy: 0.9959 - val_loss: 4.8619 - val_accuracy: 0.0986 - lr: 7.5000e-05\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 29s 2s/step - loss: 0.1641 - accuracy: 0.9959 - val_loss: 4.8259 - val_accuracy: 0.1127 - lr: 5.6250e-05\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 28s 2s/step - loss: 0.1799 - accuracy: 0.9878 - val_loss: 4.8209 - val_accuracy: 0.0986 - lr: 5.6250e-05\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 29s 2s/step - loss: 0.1668 - accuracy: 0.9959 - val_loss: 4.8135 - val_accuracy: 0.1127 - lr: 5.6250e-05\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 28s 2s/step - loss: 0.1286 - accuracy: 0.9878 - val_loss: 4.8251 - val_accuracy: 0.1127 - lr: 5.6250e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-08 20:43:02.028289: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 53, does not match size of target_names, 118. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m alt_model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m      8\u001b[0m alt_hist, alt_ckpt \u001b[38;5;241m=\u001b[39m train_model(alt_model, train_ds, val_ds, alt_out)\n\u001b[0;32m----> 9\u001b[0m alt_f1, alt_cm \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43malt_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCLASS_NAMES\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m plot_confusion_matrix(alt_cm, CLASS_NAMES\u001b[38;5;241m.\u001b[39mtolist(), title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_cfg\u001b[38;5;241m.\u001b[39malt_model_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m — Confusion Matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(Path(alt_out)\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "Cell \u001b[0;32mIn[8], line 22\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, test_ds, class_names)\u001b[0m\n\u001b[1;32m     20\u001b[0m macro_f1 \u001b[38;5;241m=\u001b[39m f1_score(y_true, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mClassification report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdigits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     23\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_true, y_pred)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m macro_f1, cm\n",
      "File \u001b[0;32m/opt/anaconda3/envs/projectecho/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/projectecho/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2693\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2687\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2688\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2689\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[1;32m   2690\u001b[0m             )\n\u001b[1;32m   2691\u001b[0m         )\n\u001b[1;32m   2692\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2693\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2694\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2695\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2696\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[1;32m   2697\u001b[0m         )\n\u001b[1;32m   2698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2699\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes, 53, does not match size of target_names, 118. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "\n",
    "alt_name = f\"{exp_cfg.alt_model_key}_seed{system_cfg.seed}\"\n",
    "alt_out = str(Path(system_cfg.output_dir)/alt_name)\n",
    "\n",
    "alt_model = build_model(exp_cfg.alt_model_key, num_classes=len(CLASS_NAMES),\n",
    "                        input_shape=(melspec_cfg.image_size[0], melspec_cfg.image_size[1], melspec_cfg.channels),\n",
    "                        lr=train_cfg.learning_rate)\n",
    "alt_model.summary()\n",
    "alt_hist, alt_ckpt = train_model(alt_model, train_ds, val_ds, alt_out)\n",
    "alt_f1, alt_cm = evaluate_model(alt_model, test_ds, CLASS_NAMES.tolist())\n",
    "plot_confusion_matrix(alt_cm, CLASS_NAMES.tolist(), title=f\"{exp_cfg.alt_model_key} — Confusion Matrix\")\n",
    "\n",
    "with open(Path(alt_out)/\"results.json\",\"w\") as f:\n",
    "    json.dump({\"model_key\": exp_cfg.alt_model_key, \"macro_f1\": float(alt_f1),\n",
    "               \"classes\": CLASS_NAMES.tolist(),\n",
    "               \"config\": {\"system\": asdict(system_cfg), \"mel\": asdict(melspec_cfg),\n",
    "                          \"train\": asdict(train_cfg), \"exp\": asdict(exp_cfg)}}, f, indent=2)\n",
    "print(\"Saved:\", Path(alt_out)/\"results.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fb2203",
   "metadata": {},
   "source": [
    "## Run Baseline (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6d3899",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baseline_f1 = None\n",
    "if exp_cfg.run_baseline:\n",
    "    base_name = f\"{exp_cfg.baseline_model_key}_seed{system_cfg.seed}\"\n",
    "    base_out = str(Path(system_cfg.output_dir)/base_name)\n",
    "\n",
    "    base_model = build_model(exp_cfg.baseline_model_key, num_classes=len(CLASS_NAMES),\n",
    "                             input_shape=(melspec_cfg.image_size[0], melspec_cfg.image_size[1], melspec_cfg.channels),\n",
    "                             lr=train_cfg.learning_rate)\n",
    "    base_model.summary()\n",
    "    base_hist, base_ckpt = train_model(base_model, train_ds, val_ds, base_out)\n",
    "    baseline_f1, base_cm = evaluate_model(base_model, test_ds, CLASS_NAMES.tolist())\n",
    "    plot_confusion_matrix(base_cm, CLASS_NAMES.tolist(), title=f\"{exp_cfg.baseline_model_key} — Confusion Matrix\")\n",
    "\n",
    "    with open(Path(base_out)/\"results.json\",\"w\") as f:\n",
    "        json.dump({\"model_key\": exp_cfg.baseline_model_key, \"macro_f1\": float(baseline_f1),\n",
    "                   \"classes\": CLASS_NAMES.tolist(),\n",
    "                   \"config\": {\"system\": asdict(system_cfg), \"mel\": asdict(melspec_cfg),\n",
    "                              \"train\": asdict(train_cfg), \"exp\": asdict(exp_cfg)}}, f, indent=2)\n",
    "    print(\"Saved:\", Path(base_out)/\"results.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ce6e3a",
   "metadata": {},
   "source": [
    "## Save a quick summary CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcc9071",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "summary_path = Path(system_cfg.output_dir)/\"summary.csv\"\n",
    "rows = [[\"model_key\",\"macro_f1\"],\n",
    "        [exp_cfg.alt_model_key, alt_f1]]\n",
    "if baseline_f1 is not None:\n",
    "    rows.append([exp_cfg.baseline_model_key, baseline_f1])\n",
    "\n",
    "with open(summary_path, \"w\", newline=\"\") as f:\n",
    "    csv.writer(f).writerows(rows)\n",
    "\n",
    "print(\"Summary saved:\", summary_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cecfe2b",
   "metadata": {},
   "source": [
    "\n",
    "### Porting Tips for Task 2\n",
    "- Move dataclasses into `configs/system_config.py`, `configs/model_configs.py`, etc.\n",
    "- Move dataset/mel functions into `utils/create_dataset.py` and `utils/data_pipeline.py`.\n",
    "- Keep the `model_key` names identical; register them in `configs/model_configs.py`.\n",
    "- In `experiment_configs.py`, create entries for (baseline, alt) with shared splits and epochs.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (projectecho)",
   "language": "python",
   "name": "projectecho"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
