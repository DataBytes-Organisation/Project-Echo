{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6c816e-65b8-4f06-88e6-7ce07151fbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, UpSampling1D, BatchNormalization, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Turn off all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_and_extract_features(directory_path, sr=22050):\n",
    "    \"\"\"\n",
    "    Load audio files from a directory, extract features, and return them as a numpy array.\n",
    "    \n",
    "    Parameters:\n",
    "    - directory_path: str, path to the directory containing audio files.\n",
    "    - sr: int, sample rate for audio files. Default is 22050.\n",
    "    \n",
    "    Returns:\n",
    "    - features_data: numpy array, extracted features from all audio files.\n",
    "    \"\"\"\n",
    "    feature_names = ['mfcc', 'chroma', 'mel', 'contrast', 'tonnetz']\n",
    "    data = np.zeros((0, 174))  # Initialize empty array with correct shape\n",
    "    \n",
    "    # Iterate over audio files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.wav'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            \n",
    "            # Load audio file\n",
    "            y, sr = librosa.load(file_path, sr=sr)\n",
    "            \n",
    "            # Extract features\n",
    "            mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "            chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "            mel = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "            contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "            tonnetz = librosa.feature.tonnetz(y=y, sr=sr)\n",
    "            \n",
    "            # Concatenate features and append to data\n",
    "            features = np.concatenate([mfcc, chroma, mel, contrast, tonnetz], axis=0).T\n",
    "            file_name=np.array([filename]*features.shape[0])\n",
    "            features = np.hstack((features, file_name.reshape(-1, 1)))\n",
    "            data = np.vstack((data, features))\n",
    "\n",
    "    data = np.delete(data, 0, axis=0)\n",
    "    return data\n",
    "\n",
    "def build_conv_autoencoder(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv1D(32, 3, activation=\"relu\", padding=\"same\")(input_layer)\n",
    "    x = MaxPooling1D(2, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv1D(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = MaxPooling1D(2, padding=\"same\")(x)\n",
    "    encoded = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv1D(16, 3, activation=\"relu\", padding=\"same\")(encoded)\n",
    "    x = UpSampling1D(2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = UpSampling1D(2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(np.prod(input_shape), activation='relu')(x)\n",
    "    decoded = Reshape(input_shape)(x)\n",
    "\n",
    "    autoencoder = Model(input_layer, decoded)\n",
    "    encoder = Model(input_layer, encoded)\n",
    "\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "    return autoencoder, encoder\n",
    "\n",
    "\n",
    "audio_file_path = \"scikit-maad/data\"\n",
    "\n",
    "label_features = load_and_extract_features(audio_file_path)\n",
    "label_names=label_features[:,-1]\n",
    "label_names=np.array(pd.DataFrame(label_names).iloc[:,0].str.replace('.wav', ''))\n",
    "label_features=label_features[:,:-1]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(label_features)\n",
    "\n",
    "features_scaled_reshaped = features_scaled.reshape(-1, features_scaled.shape[1], 1)\n",
    "\n",
    "input_shape = (features_scaled.shape[1], 1)\n",
    "autoencoder, encoder = build_conv_autoencoder(input_shape)\n",
    "\n",
    "autoencoder.fit(features_scaled_reshaped,\n",
    "                features_scaled_reshaped,\n",
    "                epochs=50, batch_size=128)\n",
    "\n",
    "compressed_features = encoder.predict(features_scaled.reshape(features_scaled.shape[0], features_scaled.shape[1], 1))\n",
    "label_compressed_features_flattened = compressed_features.reshape(compressed_features.shape[0], -1)\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=42).fit(label_compressed_features_flattened)\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(label_compressed_features_flattened)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=kmeans.labels_, cmap='viridis')\n",
    "plt.title(\"t-SNE Visualization of Clustered Features\")\n",
    "plt.xlabel(\"t-SNE Feature 1\")\n",
    "plt.ylabel(\"t-SNE Feature 2\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "cluster_labels=kmeans.labels_\n",
    "# Add the cluster labels as an additional feature\n",
    "X_label = np.hstack((label_compressed_features_flattened, cluster_labels.reshape(-1, 1)))\n",
    "X_label = np.hstack((X_label, label_names.reshape(-1, 1)))\n",
    "\n",
    "\n",
    "label_data=pd.DataFrame(X_label)\n",
    "label_data=label_data.iloc[:,704:]\n",
    "label_data.columns=['Category','Label_Names']\n",
    "label_data_groupby=label_data.groupby('Label_Names')['Category'].unique().reset_index()\n",
    "\n",
    "\n",
    "label_data_groupby['Label_Names'][0]='cold_forest_daylight/tropical_forest_morning'\n",
    "label_data_groupby=label_data_groupby.iloc[:-1,:]\n",
    "\n",
    "# sphinx_gallery_thumbnail_path = './_images/sphx_glr_plot_unsupervised_sound_classification_004.png'\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from maad import sound, features, rois\n",
    "from maad.util import power2dB, plot2d, format_features, overlay_rois\n",
    "\n",
    "# List of audio files\n",
    "audio_files = [\n",
    "    'scikit-maad/data/cold_forest_daylight.wav',\n",
    "    'scikit-maad/data/cold_forest_night.wav',\n",
    "    'scikit-maad/data/rock_savanna.wav', \n",
    "    'scikit-maad/data/spinetail.wav', \n",
    "    'scikit-maad/data/tropical_forest_morning.wav'  \n",
    "]\n",
    "adio_name=['cold_forest_daylight','cold_forest_night','rock_savanna','spinetail','tropical_forest_morning']\n",
    "\n",
    "# Parameters for processing\n",
    "fcut = 100\n",
    "forder = 3\n",
    "ftype = 'highpass'\n",
    "db_max = 70\n",
    "\n",
    "# Loop over each file and plot the spectrogram\n",
    "for idx, file in enumerate(audio_files):\n",
    "    # Load the audio file\n",
    "    s, fs = sound.load(file)\n",
    "    \n",
    "    # Apply a high-pass filter to the audio signal\n",
    "    s_filt = sound.select_bandwidth(s, fs, fcut=fcut, forder=forder, ftype=ftype)\n",
    "    \n",
    "    # Compute the spectrogram\n",
    "    Sxx, tn, fn, ext = sound.spectrogram(s_filt, fs, nperseg=1024, noverlap=512)\n",
    "    \n",
    "    # Convert the power spectrogram to decibel scale and normalize\n",
    "    Sxx_db = power2dB(Sxx, db_range=db_max) + db_max\n",
    "    \n",
    "    # Plot the spectrogram\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(Sxx_db, extent=ext, aspect='auto', origin='lower', cmap='inferno')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(adio_name[idx])\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "audio_file_path = \"scikit-maad/data/indices\"\n",
    "\n",
    "features = load_and_extract_features(audio_file_path)\n",
    "filenames=features[:,-1]\n",
    "features=features[:,:-1]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "features_scaled_reshaped = features_scaled.reshape(-1, features_scaled.shape[1], 1)\n",
    "\n",
    "input_shape = (features_scaled.shape[1], 1)\n",
    "autoencoder, encoder = build_conv_autoencoder(input_shape)\n",
    "\n",
    "autoencoder.fit(features_scaled_reshaped,\n",
    "                features_scaled_reshaped,\n",
    "                epochs=50, batch_size=128)\n",
    "\n",
    "compressed_features = encoder.predict(features_scaled.reshape(features_scaled.shape[0], features_scaled.shape[1], 1))\n",
    "compressed_features_flattened = compressed_features.reshape(compressed_features.shape[0], -1)\n",
    "\n",
    "predicted_clusters = kmeans.predict(compressed_features_flattened)\n",
    "\n",
    "# cluster_labels=kmeans.labels_\n",
    "X=compressed_features_flattened\n",
    "# Add the cluster labels as an additional feature\n",
    "X_extended = np.hstack((X, predicted_clusters.reshape(-1, 1)))\n",
    "X_extended = np.hstack((X_extended, filenames.reshape(-1, 1)))\n",
    "\n",
    "data=pd.DataFrame(X_extended)\n",
    "\n",
    "data=data.iloc[:,704:]\n",
    "data.columns=['Category','File_Names']\n",
    "\n",
    "data_groupby=data.groupby('File_Names')['Category'].unique().reset_index()\n",
    "data_groupby['Features']=data_groupby['Category']\n",
    "sound_dict={'0.0':'Cicada/Frog','1.0':'Birds','2.0':'Cicada/Frog','3.0':'BackGround','4.0':'Spinetail'}\n",
    "for idx,col in enumerate(data_groupby['Category']):\n",
    "    string=''\n",
    "    for i in col:\n",
    "        string=string+sound_dict[i]+' / '\n",
    "    data_groupby['Features'][idx]=string[:-2]\n",
    "\n",
    "label_data_groupby['Category'] = label_data_groupby['Category'].apply(lambda x: ','.join(map(str, sorted(x))))\n",
    "data_groupby['Category'] = data_groupby['Category'].apply(lambda x: ','.join(map(str, sorted(x))))\n",
    "merged_df = pd.merge(data_groupby, label_data_groupby, on='Category', how='left')\n",
    "\n",
    "merged_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
