{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will be working from here to systematically work through the trello card relating to \"Project Echo Engine template notebook report for transfer learning\" \n",
    "- summary markdown document as a professional report to stakeholders \n",
    "- list of transfer learning models \n",
    "- why they are chosen\n",
    "- the performance of each \n",
    "- display examples (original spectogram and then the augmented versions, originla audio and then the augmented audio, etc...)\n",
    "- explain what type of model was used and why it is suitable for our task \n",
    "- anything extra needed to clearly explain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note I will be using this notebook to brainstorm and craft the final response so think of it as a draft "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The team lead mentioned this in the trello card which will help me get started:\n",
    "\n",
    "> Tanmay Pachpande 13 Mar at 10:48\n",
    "> For previous trimester, I used the [optimized_engine_pipeline.ipynb](https://github.com/DataBytes-Organisation/Project-Echo/src/Prototypes/engine/Transfer Learning Tasks) to implement the transfer learning for InceptionResNetV2. The optimized_engine_pipeline could be used for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIST OF MODELS\n",
    "- list the models currently being used in the project \n",
    "- explain why each model was chosen based on its suitability for bioacoustic signal analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL PERFORMANCES \n",
    "- detailing the performance of each model (Graphs/tables/training curves/validation accuracy, etc...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUDIO AND SPECTOGRAM EXAMPLES \n",
    "- provide examples of original audio files and their Mel spectrogram images \n",
    "- show how they are augmented and explain the augmentation techniques "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLAIN MODEL SUITABILITY \n",
    "- why the model was chosen \n",
    "- why it's suitable for the task \n",
    "- discuss model architecture, efficiency and accuracy \n",
    "- basically explain all the technical details "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTS AND DISCUSSION \n",
    "- summarise the findings \n",
    "- explain the impact of the chosen models on the project's goals "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSION \n",
    "- wrap up the report for the stakeholders so there is a tldr; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REFERENCES "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
