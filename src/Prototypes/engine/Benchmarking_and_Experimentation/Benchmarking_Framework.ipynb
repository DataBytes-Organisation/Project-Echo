{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Echo - Experiment Benchmarking Framework\n",
    "\n",
    "This notebook provides an interactive interface to the benchmarking framework. It allows you to run various experiments with different model architectures and augmentation strategies, and compare their performance.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The benchmarking framework is designed to systematically evaluate different combinations of:\n",
    "- Model architectures (EfficientNet, MobileNet, ResNet, etc.)\n",
    "- Audio augmentation strategies\n",
    "- Image/spectrogram augmentation strategies\n",
    "\n",
    "Results are collected and visualized to help identify the best performing configurations for bat sound classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import re\n",
    "import importlib\n",
    "import config.system_config # To reload the module\n",
    "\n",
    "# Add the current directory to path for imports\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Import framework components\n",
    "from config.experiment_configs import EXPERIMENTS\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Set up the directories and options for benchmarking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU support found, running on CPU\n"
     ]
    }
   ],
   "source": [
    "# Default directories - you can change these as needed\n",
    "DATA_DIR = r\"C:\\Users\\deanf\\OneDrive\\CTMC\\MAppAI\\SIT764 Team Project A\\Project Echo\"  # Directory containing audio data\n",
    "CACHE_DIR = r\"C:\\Users\\deanf\\OneDrive\\CTMC\\MAppAI\\SIT764 Team Project A\\pipeline_cache\"  # Directory for caching pipeline results\n",
    "OUTPUT_DIR = r\"./results\"  # Directory to save experiment results\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "# Configure GPU memory if available\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(f\"GPU support enabled: {len(gpus)} GPU(s) found\")\n",
    "else:\n",
    "    print(\"No GPU support found, running on CPU\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Available Experiments\n",
    "\n",
    "Here you can view and select experiments to run. Each experiment represents a combination of model architecture and augmentation strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model</th>\n",
       "      <th>audio_augmentation</th>\n",
       "      <th>image_augmentation</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>EfficientNetV2B0</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>basic_audio_aug</td>\n",
       "      <td>EfficientNetV2B0</td>\n",
       "      <td>basic</td>\n",
       "      <td>none</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>basic_image_aug</td>\n",
       "      <td>EfficientNetV2B0</td>\n",
       "      <td>none</td>\n",
       "      <td>basic_rotation</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>full_augmentation</td>\n",
       "      <td>EfficientNetV2B0</td>\n",
       "      <td>advanced</td>\n",
       "      <td>combined</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mobilenet_baseline</td>\n",
       "      <td>MobileNetV2</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mobilenet_full_aug</td>\n",
       "      <td>MobileNetV2</td>\n",
       "      <td>advanced</td>\n",
       "      <td>combined</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name             model audio_augmentation image_augmentation  \\\n",
       "0            baseline  EfficientNetV2B0               none               none   \n",
       "1     basic_audio_aug  EfficientNetV2B0              basic               none   \n",
       "2     basic_image_aug  EfficientNetV2B0               none     basic_rotation   \n",
       "3   full_augmentation  EfficientNetV2B0           advanced           combined   \n",
       "4  mobilenet_baseline       MobileNetV2               none               none   \n",
       "5  mobilenet_full_aug       MobileNetV2           advanced           combined   \n",
       "\n",
       "   epochs  batch_size  \n",
       "0      10          16  \n",
       "1      10          16  \n",
       "2      10          16  \n",
       "3      10          16  \n",
       "4      10          16  \n",
       "5      10          16  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display available experiments\n",
    "experiment_data = []\n",
    "for exp in EXPERIMENTS:\n",
    "    experiment_data.append({\n",
    "        \"name\": exp[\"name\"],\n",
    "        \"model\": exp[\"model\"],\n",
    "        \"audio_augmentation\": exp[\"audio_augmentation\"],\n",
    "        \"image_augmentation\": exp[\"image_augmentation\"],\n",
    "        \"epochs\": exp[\"epochs\"],\n",
    "        \"batch_size\": exp[\"batch_size\"]\n",
    "    })\n",
    "\n",
    "experiments_df = pd.DataFrame(experiment_data)\n",
    "display(experiments_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interactive Experiment Selection\n",
    "\n",
    "Use the widgets below to select experiments and set directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30de6e81ea9d46cc8a3b448e58ba5d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='C:\\\\Users\\\\deanf\\\\OneDrive\\\\CTMC\\\\MAppAI\\\\SIT764 Team Project A\\\\Project Echo', description='Data …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd04b90e3b64a81885261a2b7679903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='C:\\\\Users\\\\deanf\\\\OneDrive\\\\CTMC\\\\MAppAI\\\\SIT764 Team Project A\\\\pipeline_cache', description='Cac…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f925e39bc6a7449ca60130a9157c7784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='./results', description='Output Directory:', layout=Layout(width='80%'), style=TextStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d71ed758114cf49928a13b9904b513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Select Experiments:', layout=Layout(height='200px', width='50%'), options=(('basel…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07fd2d2ac91408ca18d8cac74f1ae13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='primary', description='Run Selected Experiments', style=ButtonStyle(), too…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b828b4d452446a86b8a0a54b34d645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create widgets for directory selection\n",
    "data_dir_widget = widgets.Text(\n",
    "    value=DATA_DIR,\n",
    "    description='Data Directory:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "cache_dir_widget = widgets.Text(\n",
    "    value=CACHE_DIR,\n",
    "    description='Cache Directory:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "output_dir_widget = widgets.Text(\n",
    "    value=OUTPUT_DIR,\n",
    "    description='Output Directory:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "# Create widget for experiment selection\n",
    "experiment_options = [(exp[\"name\"], exp[\"name\"]) for exp in EXPERIMENTS]\n",
    "experiment_widget = widgets.SelectMultiple(\n",
    "    options=experiment_options,\n",
    "    description='Select Experiments:',\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='50%', height='200px')\n",
    ")\n",
    "\n",
    "# Buttons for actions\n",
    "run_selected_button = widgets.Button(\n",
    "    description='Run Selected Experiments',\n",
    "    button_style='primary',\n",
    "    tooltip='Run the selected experiments'\n",
    ")\n",
    "\n",
    "run_all_button = widgets.Button(\n",
    "    description='Run All Experiments',\n",
    "    tooltip='Run all experiments'\n",
    ")\n",
    "\n",
    "generate_report_button = widgets.Button(\n",
    "    description='Generate Report Only',\n",
    "    button_style='info',\n",
    "    tooltip='Generate a report from existing results'\n",
    ")\n",
    "\n",
    "# Output area for logs\n",
    "output_area = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "# Display widgets\n",
    "display(data_dir_widget)\n",
    "display(cache_dir_widget)\n",
    "display(output_dir_widget)\n",
    "display(experiment_widget)\n",
    "display(widgets.HBox([run_selected_button, run_all_button, generate_report_button]))\n",
    "display(output_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Experiment Runner Functions\n",
    "\n",
    "These functions handle the execution of experiments and report generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.optimised_engine_pipeline import train_model\n",
    "\n",
    "\n",
    "def run_selected_experiments(b):\n",
    "    from IPython.display import clear_output # Moved import here for clarity\n",
    "    clear_output(wait=True) # Clear previous output first\n",
    "    with output_area:\n",
    "        print(\"Starting experiment run...\")\n",
    "        # Get new directory paths from widgets\n",
    "        new_data_dir = data_dir_widget.value\n",
    "        new_cache_dir = cache_dir_widget.value\n",
    "        \n",
    "        # Define path to system_config.py (relative to notebook directory)\n",
    "        # Assumes 'config' is a subdirectory of the notebook's directory\n",
    "        config_file_path = os.path.join('config', 'system_config.py')\n",
    "        \n",
    "        try:\n",
    "            print(f\"Attempting to update {config_file_path}...\")\n",
    "            with open(config_file_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            new_lines = []\n",
    "            config_updated = False\n",
    "            for line in lines:\n",
    "                if \"'AUDIO_DATA_DIRECTORY':\" in line:\n",
    "                    # Use r-string for replacement to handle backslashes in path correctly\n",
    "                    new_line = re.sub(r\"('AUDIO_DATA_DIRECTORY':\\s*r\\\")[^\\\"]*(\\\")\", rf'\\1{new_data_dir}\\2', line)\n",
    "                    if new_line != line:\n",
    "                        config_updated = True\n",
    "                    new_lines.append(new_line)\n",
    "                elif \"'CACHE_DIRETORY':\" in line: # Note the typo 'DIRETORY'\n",
    "                    new_line = re.sub(r\"('CACHE_DIRETORY':\\s*r\\\")[^\\\"]*(\\\")\", rf'\\1{new_cache_dir}\\2', line)\n",
    "                    if new_line != line:\n",
    "                        config_updated = True\n",
    "                    new_lines.append(new_line)\n",
    "                else:\n",
    "                    new_lines.append(line)\n",
    "            \n",
    "            if config_updated:\n",
    "                with open(config_file_path, 'w') as f:\n",
    "                    f.writelines(new_lines)\n",
    "                print(f\"Successfully updated {config_file_path} with new directory paths.\")\n",
    "            else:\n",
    "                print(f\"{config_file_path} already up-to-date or keys not found.\")\n",
    "            \n",
    "            # Reload the system_config module to apply changes\n",
    "            importlib.reload(config.system_config)\n",
    "            # Re-import SC if it's used directly in this notebook, or ensure train_model gets the fresh one.\n",
    "            # from config.system_config import SC \n",
    "            print(\"System configuration reloaded.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error updating or reloading system_config.py: {e}\")\n",
    "            print(\"Proceeding with potentially outdated configuration.\")\n",
    "            # Decide if you want to return or proceed if config update fails\n",
    "            # return \n",
    "\n",
    "        selected_experiments = list(experiment_widget.value)\n",
    "        if not selected_experiments:\n",
    "            print(\"No experiment selected. Please select at least one experiment.\")\n",
    "            return\n",
    "        \n",
    "        for exp_name in selected_experiments:\n",
    "            exp_config = next((exp for exp in EXPERIMENTS if exp[\"name\"] == exp_name), None)\n",
    "            if exp_config is None:\n",
    "                print(f\"Experiment {exp_name} not found in EXPERIMENTS.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Running experiment: {exp_config['name']}\")\n",
    "            # Pass configuration values to the train_model function.\n",
    "            # train_model will use the reloaded system_config.SC for DATA_DIR and CACHE_DIR\n",
    "            model, history = train_model(\n",
    "                model_name=exp_config['model'],\n",
    "                epochs=exp_config.get('epochs'),\n",
    "                batch_size=exp_config.get('batch_size')\n",
    "            )\n",
    "            print(f\"Training completed for experiment: {exp_config['name']}\")\n",
    "            if model:\n",
    "                 model.summary(print_fn=lambda x: print(x)) # Ensure summary prints to output_area\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "run_selected_button.on_click(run_selected_experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. View Previous Results\n",
    "\n",
    "If you've already run experiments, you can view and analyze the results here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No comparison results found. Run experiments or generate a report first.\n"
     ]
    }
   ],
   "source": [
    "# Under development\n",
    "def load_results(output_dir=OUTPUT_DIR):\n",
    "    # Check if results directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        print(f\"Results directory does not exist: {output_dir}\")\n",
    "        return None\n",
    "    \n",
    "    # Look for comparison report CSV\n",
    "    csv_files = [f for f in os.listdir(output_dir) if f.startswith(\"comparison_results_\") and f.endswith(\".csv\")]\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(\"No comparison results found. Run experiments or generate a report first.\")\n",
    "        return None\n",
    "    \n",
    "    # Load the latest CSV file\n",
    "    latest_csv = max(csv_files)\n",
    "    csv_path = os.path.join(output_dir, latest_csv)\n",
    "    results_df = pd.read_csv(csv_path)\n",
    "    \n",
    "    print(f\"Loaded results from: {csv_path}\")\n",
    "    return results_df\n",
    "\n",
    "# Load and display results if available\n",
    "results_df = load_results()\n",
    "if results_df is not None:\n",
    "    display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Results\n",
    "\n",
    "Create various visualizations to compare experiment results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from previously developed notebooks in Machine Learing course\n",
    "\n",
    "def visualize_results(results_df):\n",
    "    if results_df is None or len(results_df) == 0:\n",
    "        print(\"No results available to visualize.\")\n",
    "        return\n",
    "    \n",
    "    # Set the figure size for better visibility\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Create accuracy comparison bar chart\n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.barplot(x='Experiment', y='Test Accuracy', data=results_df)\n",
    "    plt.title('Test Accuracy by Experiment')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Create F1 score comparison bar chart\n",
    "    plt.subplot(2, 2, 2)\n",
    "    sns.barplot(x='Experiment', y='F1 Score', data=results_df)\n",
    "    plt.title('F1 Score by Experiment')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Training time comparison\n",
    "    plt.subplot(2, 2, 3)\n",
    "    sns.barplot(x='Experiment', y='Training Time (min)', data=results_df)\n",
    "    plt.title('Training Time by Experiment (minutes)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Model comparison\n",
    "    plt.subplot(2, 2, 4)\n",
    "    model_comparison = results_df.groupby('Model')['Test Accuracy'].mean().reset_index()\n",
    "    sns.barplot(x='Model', y='Test Accuracy', data=model_comparison)\n",
    "    plt.title('Average Accuracy by Model')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.tight_layout(pad=3.0)\n",
    "    plt.show()\n",
    "    \n",
    "    # Create a separate visualization for augmentation impact\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Reshape data for augmentation comparison\n",
    "    # The following code is yet to be tested and may need adjustments based on the actual DataFrame structure\n",
    "    \"\"\"\n",
    "    aug_data = []\n",
    "    for _, row in results_df.iterrows():\n",
    "        aug_data.append({\n",
    "            'Experiment': row['Experiment'],\n",
    "            'Augmentation Type': 'Audio',\n",
    "            'Augmentation': row['Audio Augmentation'],\n",
    "            'Accuracy': row['Test Accuracy']\n",
    "        })\n",
    "        aug_data.append({\n",
    "            'Experiment': row['Experiment'],\n",
    "            'Augmentation Type': 'Image',\n",
    "            'Augmentation': row['Image Augmentation'],\n",
    "            'Accuracy': row['Test Accuracy']\n",
    "        })\"\"\"\n",
    "    \n",
    "    aug_df = pd.DataFrame(aug_data)\n",
    "    sns.barplot(x='Augmentation', y='Accuracy', hue='Augmentation Type', data=aug_df)\n",
    "    plt.title('Accuracy by Augmentation Type')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize results if available\n",
    "if results_df is not None:\n",
    "    visualize_results(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Experiment Analysis and Conclusions\n",
    "(if required)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectecho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
