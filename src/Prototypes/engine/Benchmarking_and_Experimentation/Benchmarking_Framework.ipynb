{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Echo - Experiment Benchmarking Framework\n",
    "\n",
    "This notebook provides an interactive interface to the benchmarking framework. It allows you to run various experiments with different model architectures and augmentation strategies, and compare their performance.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The benchmarking framework is designed to systematically evaluate different combinations of:\n",
    "- Model architectures (EfficientNet, MobileNet, ResNet, etc.)\n",
    "- Audio augmentation strategies\n",
    "- Image/spectrogram augmentation strategies\n",
    "\n",
    "Results are collected and visualized to help identify the best performing configurations for bird sound classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1 Install Required Libraries\n",
    "The following cell is to install required libraries if you are running this notebook remotly, such as on an instance from Vast.ai or google colab.\n",
    "Ensure you have a clean python 3.9.21 kernal to start.\n",
    "Details on how to set this up are contained within the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f6d1ba30664a0a838e9f6592dbd7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider\n",
    "from IPython.display import display\n",
    "slider = IntSlider()\n",
    "display(slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Running in devcontainer environment\n",
      "Using base path: /workspace\n",
      "config directory: ‚úì /workspace/config\n",
      "utils directory: ‚úì /workspace/utils\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIGURATION FOR DEVCONTAINER ---\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# When running in devcontainer, the workspace is mounted to /workspace\n",
    "if os.path.exists('/workspace') and os.path.exists('/workspace/config'):\n",
    "    # Running in devcontainer with proper mount\n",
    "    base_path = \"/workspace\"\n",
    "    print(\"‚úì Running in devcontainer environment\")\n",
    "elif os.path.exists('./config'):\n",
    "    # Running locally\n",
    "    base_path = os.getcwd()\n",
    "    print(\"‚úì Running in local environment\")\n",
    "else:\n",
    "    # Fallback - try to find config directory\n",
    "    current_dir = os.getcwd()\n",
    "    parent_dir = os.path.dirname(current_dir)\n",
    "    \n",
    "    if os.path.exists(os.path.join(current_dir, 'config')):\n",
    "        base_path = current_dir\n",
    "    elif os.path.exists(os.path.join(parent_dir, 'config')):\n",
    "        base_path = parent_dir\n",
    "    else:\n",
    "        print(\"‚ùå ERROR: Cannot find config directory\")\n",
    "        print(f\"Current directory: {current_dir}\")\n",
    "        print(f\"Available files/dirs: {os.listdir(current_dir)}\")\n",
    "        base_path = current_dir\n",
    "\n",
    "print(f\"Using base path: {base_path}\")\n",
    "\n",
    "# Add to Python path\n",
    "if base_path not in sys.path:\n",
    "    sys.path.insert(0, base_path)\n",
    "\n",
    "# Verify required directories exist\n",
    "required_dirs = ['config', 'utils']\n",
    "for dir_name in required_dirs:\n",
    "    dir_path = os.path.join(base_path, dir_name)\n",
    "    exists = os.path.exists(dir_path)\n",
    "    print(f\"{dir_name} directory: {'‚úì' if exists else '‚ùå'} {dir_path}\")\n",
    "\n",
    "# --- END CONFIGURATION ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-06 01:11:51.311566: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-06 01:11:51.573898: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in devcontainer environment\n",
      "Using module path: /workspace\n",
      "Successfully added to sys.path: /workspace\n",
      "Config directory exists: True\n",
      "Utils directory exists: True\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "\n",
    "# --- CONFIGURATION FOR DEVCONTAINER ---\n",
    "# When running in devcontainer, use the mounted workspace path\n",
    "# The devcontainer.json mounts the workspace to /workspace\n",
    "if os.path.exists('/workspace'):\n",
    "    # Running in devcontainer\n",
    "    actual_module_path_inside_container = \"/workspace\"\n",
    "    print(\"Running in devcontainer environment\")\n",
    "else:\n",
    "    # Fallback for local development\n",
    "    actual_module_path_inside_container = os.getcwd()\n",
    "    print(\"Running in local environment\")\n",
    "\n",
    "print(f\"Using module path: {actual_module_path_inside_container}\")\n",
    "\n",
    "if not os.path.isdir(actual_module_path_inside_container):\n",
    "    print(f\"ERROR: The path '{actual_module_path_inside_container}' does NOT exist or is not a directory.\")\n",
    "    print(f\"Current CWD: {os.getcwd()}\")\n",
    "    print(f\"Available directories: {os.listdir('.')}\")\n",
    "else:\n",
    "    if actual_module_path_inside_container not in sys.path:\n",
    "        sys.path.insert(0, actual_module_path_inside_container)\n",
    "    print(f\"Successfully added to sys.path: {actual_module_path_inside_container}\")\n",
    "    \n",
    "    # Verify the required directories exist\n",
    "    config_path = os.path.join(actual_module_path_inside_container, 'config')\n",
    "    utils_path = os.path.join(actual_module_path_inside_container, 'utils')\n",
    "    print(f\"Config directory exists: {os.path.exists(config_path)}\")\n",
    "    print(f\"Utils directory exists: {os.path.exists(utils_path)}\")\n",
    "\n",
    "# --- END CONFIGURATION ---\n",
    "\n",
    "# Import framework components\n",
    "from config.experiment_configs import EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import re\n",
    "import importlib\n",
    "\n",
    "# Add the current directory to path for imports\n",
    "module_path = os.getcwd() # Gets the current working directory of the notebook\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Import framework components\n",
    "from config.experiment_configs import EXPERIMENTS\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Available Experiments\n",
    "\n",
    "Here you can view and select experiments to run. Each experiment represents a combination of model architecture and augmentation strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Set up the directories and options for benchmarking. \n",
    "\n",
    "Ensure to update these in the system_config.py file in the config folder.\n",
    "\n",
    "The default directories are as follows:\n",
    "\n",
    "DATA_DIR = \"D:\\Echo\\Audio_data\"  # Directory containing audio data\n",
    "\n",
    "CACHE_DIR = \"D:\\Echo\\Training_cache\"  # Directory for caching pipeline results\n",
    "\n",
    "OUTPUT_DIR = \"D:\\Echo\\results\"  # Directory to save experiment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using directories from system_config:\n",
      "Data Directory: /workspace/Audio_data\n",
      "Cache Directory: /workspace/Training_cache\n",
      "Output Directory: /workspace/Output\n",
      "Physical GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Built with CUDA: True\n",
      "GPU name: /device:GPU:0\n",
      "GPU support enabled: 1 GPU(s) found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-06 01:11:54.409906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-08-06 01:11:54.419992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-08-06 01:11:54.420308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-08-06 01:11:54.421594: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-06 01:11:54.423372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-08-06 01:11:54.423534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-08-06 01:11:54.423700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-08-06 01:11:55.238739: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-08-06 01:11:55.239543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-08-06 01:11:55.239564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-08-06 01:11:55.239836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-08-06 01:11:55.239879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:0 with 21602 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Import directories from system_config\n",
    "from config.system_config import SC\n",
    "\n",
    "# Get directory paths from system config\n",
    "DATA_DIR = SC['AUDIO_DATA_DIRECTORY']\n",
    "CACHE_DIR = SC['CACHE_DIRECTORY']\n",
    "OUTPUT_DIR = SC['OUTPUT_DIRECTORY']\n",
    "\n",
    "print(f\"Using directories from system_config:\")\n",
    "print(f\"Data Directory: {DATA_DIR}\")\n",
    "print(f\"Cache Directory: {CACHE_DIR}\")\n",
    "print(f\"Output Directory: {OUTPUT_DIR}\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "\n",
    "print(\"Physical GPUs:\", tf.config.list_physical_devices(\"GPU\"))\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU name:\", tf.test.gpu_device_name())\n",
    "\n",
    "\n",
    "# Configure GPU memory if available\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(f\"GPU support enabled: {len(gpus)} GPU(s) found\")\n",
    "else:\n",
    "    print(\"No GPU support found, running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model</th>\n",
       "      <th>audio_augmentation</th>\n",
       "      <th>image_augmentation</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>EfficientNetV2B0</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>noise_and_stretch_audio_aug</td>\n",
       "      <td>EfficientNetV2B0</td>\n",
       "      <td>noise_and_stretch</td>\n",
       "      <td>none</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>basic_image_aug</td>\n",
       "      <td>EfficientNetV2B0</td>\n",
       "      <td>none</td>\n",
       "      <td>basic_rotation</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>full_augmentation</td>\n",
       "      <td>EfficientNetV2B0</td>\n",
       "      <td>advanced</td>\n",
       "      <td>combined</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mobilenet_baseline</td>\n",
       "      <td>MobileNetV2</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>50</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mobilenet_full_aug</td>\n",
       "      <td>MobileNetV2</td>\n",
       "      <td>advanced</td>\n",
       "      <td>combined</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>noise_and_pitch_small</td>\n",
       "      <td>ResNet50V2</td>\n",
       "      <td>noise_and_pitch</td>\n",
       "      <td>none</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spec_only_aggressive</td>\n",
       "      <td>InceptionV3</td>\n",
       "      <td>none</td>\n",
       "      <td>aggressive</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mobilenet_v3_large_baseline</td>\n",
       "      <td>MobileNetV3-Large</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>50</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mobilenet_v3_small_baseline</td>\n",
       "      <td>MobileNetV3-Small</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>50</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name              model audio_augmentation  \\\n",
       "0                     baseline   EfficientNetV2B0               none   \n",
       "1  noise_and_stretch_audio_aug   EfficientNetV2B0  noise_and_stretch   \n",
       "2              basic_image_aug   EfficientNetV2B0               none   \n",
       "3            full_augmentation   EfficientNetV2B0           advanced   \n",
       "4           mobilenet_baseline        MobileNetV2               none   \n",
       "5           mobilenet_full_aug        MobileNetV2           advanced   \n",
       "6        noise_and_pitch_small         ResNet50V2    noise_and_pitch   \n",
       "7         spec_only_aggressive        InceptionV3               none   \n",
       "8  mobilenet_v3_large_baseline  MobileNetV3-Large               none   \n",
       "9  mobilenet_v3_small_baseline  MobileNetV3-Small               none   \n",
       "\n",
       "  image_augmentation  epochs  batch_size  \n",
       "0               none      50           8  \n",
       "1               none      10          16  \n",
       "2     basic_rotation      10          16  \n",
       "3           combined      10          16  \n",
       "4               none      50          16  \n",
       "5           combined      10          16  \n",
       "6               none      10          16  \n",
       "7         aggressive      10          16  \n",
       "8               none      50          16  \n",
       "9               none      50          16  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display available experiments\n",
    "experiment_data = []\n",
    "for exp in EXPERIMENTS:\n",
    "    experiment_data.append({\n",
    "        \"name\": exp[\"name\"],\n",
    "        \"model\": exp[\"model\"],\n",
    "        \"audio_augmentation\": exp[\"audio_augmentation\"],\n",
    "        \"image_augmentation\": exp[\"image_augmentation\"],\n",
    "        \"epochs\": exp[\"epochs\"],\n",
    "        \"batch_size\": exp[\"batch_size\"]\n",
    "    })\n",
    "\n",
    "experiments_df = pd.DataFrame(experiment_data)\n",
    "display(experiments_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interactive Experiment Selection\n",
    "\n",
    "Use the widgets below to select experiments and set directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48fab472397b411085fbc8912e4c193e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Directory Configuration:</h3>'), VBox(children=(Text(value='/workspace/Audio_da‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74cff40a3b4d449ea9bd79d4205847b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid b‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create widgets for directory selection\n",
    "data_dir_widget = widgets.Text(\n",
    "    value=DATA_DIR,\n",
    "    description='Data Directory:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "cache_dir_widget = widgets.Text(\n",
    "    value=CACHE_DIR,\n",
    "    description='Cache Directory:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "output_dir_widget = widgets.Text(\n",
    "    value=OUTPUT_DIR,\n",
    "    description='Output Directory:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "# Group directory widgets\n",
    "dir_widgets_box = widgets.VBox([data_dir_widget, cache_dir_widget, output_dir_widget])\n",
    "\n",
    "# Create widget for experiment selection\n",
    "experiment_options = [(exp[\"name\"], exp[\"name\"]) for exp in EXPERIMENTS]\n",
    "experiment_widget = widgets.SelectMultiple(\n",
    "    options=experiment_options,\n",
    "    description='Select Experiments:',\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='50%', height='200px')\n",
    ")\n",
    "\n",
    "# Buttons for actions\n",
    "run_selected_button = widgets.Button(\n",
    "    description='Run Selected Experiments',\n",
    "    button_style='primary',\n",
    "    tooltip='Run the selected experiments'\n",
    ")\n",
    "\n",
    "run_all_button = widgets.Button(\n",
    "    description='Run All Experiments',\n",
    "    tooltip='Run all experiments'\n",
    ")\n",
    "\n",
    "generate_report_button = widgets.Button(\n",
    "    description='Generate Report Only',\n",
    "    button_style='info',\n",
    "    tooltip='Generate a report from existing results'\n",
    ")\n",
    "\n",
    "# Group buttons\n",
    "buttons_box = widgets.HBox([run_selected_button, run_all_button, generate_report_button])\n",
    "\n",
    "# Output area for logs\n",
    "output_area = widgets.Output(layout={'border': '1px solid black', 'width': '90%', 'height': '300px'}) # Adjusted width and added height\n",
    "\n",
    "# Main container for all control widgets\n",
    "controls_box = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Directory Configuration:</h3>\"), # Optional title\n",
    "    dir_widgets_box,\n",
    "    widgets.HTML(\"<hr><h3>Experiment Selection:</h3>\"), # Optional separator and title\n",
    "    experiment_widget,\n",
    "    widgets.HTML(\"<hr><h3>Actions:</h3>\"), # Optional separator and title\n",
    "    buttons_box\n",
    "])\n",
    "\n",
    "# Display main controls container and then the output area\n",
    "display(controls_box)\n",
    "display(output_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Experiment Runner Functions\n",
    "\n",
    "These functions handle the execution of experiments and report generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment runner function has been updated.\n"
     ]
    }
   ],
   "source": [
    "from utils.optimised_engine_pipeline import train_model\n",
    "import importlib\n",
    "import config.system_config # Ensure the module is imported\n",
    "\n",
    "def run_selected_experiments(b):\n",
    "    \"\"\"\n",
    "    Runs experiments based on widget selections.\n",
    "    Updates configuration in memory instead of writing to file.\n",
    "    \"\"\"\n",
    "    output_area.clear_output(wait=True)\n",
    "    with output_area:\n",
    "        print(\"Starting experiment run...\")\n",
    "\n",
    "        # Get new directory paths from widgets\n",
    "        new_data_dir = data_dir_widget.value\n",
    "        new_cache_dir = cache_dir_widget.value\n",
    "        new_output_dir = output_dir_widget.value\n",
    "\n",
    "        # --- FIX: Update config directly in memory ---\n",
    "        # This is safer and more reliable than reloading modules.\n",
    "        from config.system_config import SC\n",
    "        SC['AUDIO_DATA_DIRECTORY'] = new_data_dir\n",
    "        SC['CACHE_DIRECTORY'] = new_cache_dir\n",
    "        SC['OUTPUT_DIRECTORY'] = new_output_dir\n",
    "        print(\"System configuration updated in memory.\")\n",
    "        print(f\"  - Data Dir: {SC['AUDIO_DATA_DIRECTORY']}\")\n",
    "        print(f\"  - Cache Dir: {SC['CACHE_DIRECTORY']}\")\n",
    "\n",
    "        # Ensure directories exist\n",
    "        for path in [new_data_dir, new_cache_dir, new_output_dir]:\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path, exist_ok=True)\n",
    "                print(f\"Created directory: {path}\")\n",
    "\n",
    "        selected_experiments = list(experiment_widget.value)\n",
    "        if not selected_experiments:\n",
    "            print(\"No experiment selected. Please select at least one experiment.\")\n",
    "            return\n",
    "\n",
    "        for exp_name in selected_experiments:\n",
    "            exp_config = next((exp for exp in EXPERIMENTS if exp[\"name\"] == exp_name), None)\n",
    "            if exp_config is None:\n",
    "                print(f\"Experiment {exp_name} not found in EXPERIMENTS.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\nRunning experiment: {exp_config['name']}\")\n",
    "            try:\n",
    "                model, history = train_model(\n",
    "                    model_name=exp_config['model'],\n",
    "                    epochs=exp_config.get('epochs'),\n",
    "                    batch_size=exp_config.get('batch_size')\n",
    "                )\n",
    "                print(f\"‚úÖ Training completed for experiment: {exp_config['name']}\")\n",
    "                if model:\n",
    "                    model.summary(print_fn=lambda x: print(x))\n",
    "\n",
    "            except Exception as e:\n",
    "                import traceback\n",
    "                print(f\"‚ùå An error occurred during training for experiment {exp_config['name']}:\")\n",
    "                traceback.print_exc() # Print the full traceback for better debugging\n",
    "\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "# Bind the corrected function to the button\n",
    "run_selected_button.on_click(run_selected_experiments)\n",
    "\n",
    "print(\"Experiment runner function has been updated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from utils.data_pipeline import create_datasets, build_datasets\n",
    "from config.system_config import SC\n",
    "from config.model_configs import MODELS\n",
    "\n",
    "with output_area:\n",
    "    print(\"üî¨ Starting corrected augmentation diagnostics...\")\n",
    "    try:\n",
    "        # 1. Get the initial datasets (paths and labels)\n",
    "        train_ds_init, val_ds_init, test_ds_init, class_names = create_datasets(SC['AUDIO_DATA_DIRECTORY'])\n",
    "        num_classes = len(class_names)\n",
    "        print(\"‚úÖ Initial dataset created.\")\n",
    "\n",
    "        # 2. Get the model's expected input shape\n",
    "        model_config = MODELS['EfficientNetV2B0'] # Using baseline as an example\n",
    "        input_shape = model_config['expected_input_shape']\n",
    "        print(f\"‚úÖ Using model input shape: {input_shape}\")\n",
    "\n",
    "        # 3. Build the full data pipeline.\n",
    "        # This will use the default augmentation strategy defined inside the function.\n",
    "        train_dataset, _, _ = build_datasets(\n",
    "            train_ds_init, val_ds_init, test_ds_init, num_classes, input_shape\n",
    "        )\n",
    "        print(\"‚úÖ Full data pipeline built.\")\n",
    "\n",
    "        # 4. Try to pull one batch and see if it fails\n",
    "        print(\"‚è≥ Attempting to get one batch from the augmented dataset...\")\n",
    "        for images, labels in train_dataset.take(1):\n",
    "            print(f\"‚úÖ Successfully retrieved one batch!\")\n",
    "            print(f\"   - Image batch shape: {images.shape}\")\n",
    "            print(f\"   - Image batch dtype: {images.dtype}\")\n",
    "            print(f\"   - Labels batch shape: {labels.shape}\")\n",
    "        print(\"\\nüéâ Diagnostic PASSED. The augmentation pipeline seems to work in isolation.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(\"\\n‚ùå Diagnostic FAILED. The error was reproduced. See traceback below.\")\n",
    "        print(\"   This confirms the issue is within the default image augmentation pipeline.\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.optimised_engine_pipeline import train_model\n",
    "\n",
    "# Update the run_selected_experiments function in your notebook\n",
    "def run_selected_experiments(b):\n",
    "    from IPython.display import clear_output\n",
    "    import importlib\n",
    "    import config.system_config\n",
    "    \n",
    "    output_area.clear_output(wait=True) \n",
    "    with output_area:\n",
    "        print(\"Starting experiment run...\")\n",
    "        \n",
    "        # Get new directory paths from widgets\n",
    "        new_data_dir = data_dir_widget.value\n",
    "        new_cache_dir = cache_dir_widget.value\n",
    "        new_output_dir = output_dir_widget.value\n",
    "        \n",
    "        # Update the paths directly in the SC dictionary\n",
    "        from config.system_config import SC\n",
    "        SC['AUDIO_DATA_DIRECTORY'] = new_data_dir\n",
    "        SC['CACHE_DIRECTORY'] = new_cache_dir\n",
    "        SC['OUTPUT_DIRECTORY'] = new_output_dir\n",
    "        \n",
    "        # Create directories if they don't exist\n",
    "        for directory in [new_data_dir, new_cache_dir, new_output_dir]:\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory, exist_ok=True)\n",
    "                print(f\"Created directory: {directory}\")\n",
    "        \n",
    "        print(f\"Updated directories:\")\n",
    "        print(f\"  Data: {new_data_dir}\")\n",
    "        print(f\"  Cache: {new_cache_dir}\")\n",
    "        print(f\"  Output: {new_output_dir}\")\n",
    "\n",
    "        selected_experiments = list(experiment_widget.value)\n",
    "        if not selected_experiments:\n",
    "            print(\"No experiment selected. Please select at least one experiment.\")\n",
    "            return\n",
    "        \n",
    "        for exp_name in selected_experiments:\n",
    "            exp_config = next((exp for exp in EXPERIMENTS if exp[\"name\"] == exp_name), None)\n",
    "            if exp_config is None:\n",
    "                print(f\"Experiment {exp_name} not found in EXPERIMENTS.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Running experiment: {exp_config['name']}\")\n",
    "            \n",
    "            try:\n",
    "                # Temporarily disable image augmentation to test if that's the issue\n",
    "                model, history = train_model(\n",
    "                    model_name=exp_config['model'],\n",
    "                    epochs=exp_config.get('epochs', 10),\n",
    "                    batch_size=exp_config.get('batch_size', 16)\n",
    "                )\n",
    "                print(f\"Training completed for experiment: {exp_config['name']}\")\n",
    "                if model:\n",
    "                    model.summary(print_fn=lambda x: print(x))\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error running experiment {exp_config['name']}: {str(e)}\")\n",
    "                print(\"This might be due to image augmentation configuration issues.\")\n",
    "                print(\"Trying with reduced batch size...\")\n",
    "                \n",
    "                try:\n",
    "                    # Try again with smaller batch size\n",
    "                    model, history = train_model(\n",
    "                        model_name=exp_config['model'],\n",
    "                        epochs=exp_config.get('epochs', 10),\n",
    "                        batch_size=8  # Smaller batch size\n",
    "                    )\n",
    "                    print(f\"‚úÖ Training completed with reduced batch size for: {exp_config['name']}\")\n",
    "                except Exception as e2:\n",
    "                    print(f\"‚ùå Still failed with reduced batch size: {str(e2)}\")\n",
    "                    \n",
    "            print(\"-\" * 40)\n",
    "\n",
    "# Re-bind the button\n",
    "run_selected_button.on_click(run_selected_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.optimised_engine_pipeline import train_model\n",
    "\n",
    "# Original function to run selected experiments\n",
    "\n",
    "def run_selected_experiments(b):\n",
    "\n",
    "    from IPython.display import clear_output # Moved import here for clarity\n",
    "    # clear_output(wait=True) # Clear previous output first\n",
    "    output_area.clear_output(wait=True) \n",
    "    with output_area:\n",
    "        print(\"Starting experiment run...\")\n",
    "        # Get new directory paths from widgets\n",
    "        new_data_dir = data_dir_widget.value\n",
    "        new_cache_dir = cache_dir_widget.value\n",
    "        \n",
    "        # Define path to system_config.py (relative to notebook directory)\n",
    "        # Assumes 'config' is a subdirectory of the notebook's directory\n",
    "        config_file_path = os.path.join('config', 'system_config.py')\n",
    "        \n",
    "        try:\n",
    "            print(f\"Attempting to update {config_file_path}...\")\n",
    "            with open(config_file_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            new_lines = []\n",
    "            config_updated = False\n",
    "            for line in lines:\n",
    "                if \"'AUDIO_DATA_DIRECTORY':\" in line:\n",
    "                    # Use r-string for replacement to handle backslashes in path correctly\n",
    "                    new_line = re.sub(r\"('AUDIO_DATA_DIRECTORY':\\s*r\\\")[^\\\"]*(\\\")\", rf'\\1{new_data_dir}\\2', line)\n",
    "                    if new_line != line:\n",
    "                        config_updated = True\n",
    "                    new_lines.append(new_line)\n",
    "                elif \"'CACHE_DIRECTORY':\" in line: \n",
    "                    new_line = re.sub(r\"('CACHE_DIRECTORY':\\s*r\\\")[^\\\"]*(\\\")\", rf'\\1{new_cache_dir}\\2', line)\n",
    "                    if new_line != line:\n",
    "                        config_updated = True\n",
    "                    new_lines.append(new_line)\n",
    "                else:\n",
    "                    new_lines.append(line)\n",
    "            \n",
    "            if config_updated:\n",
    "                with open(config_file_path, 'w') as f:\n",
    "                    f.writelines(new_lines)\n",
    "                print(f\"Successfully updated {config_file_path} with new directory paths.\")\n",
    "            else:\n",
    "                print(f\"{config_file_path} already up-to-date or keys not found.\")\n",
    "            \n",
    "            # Reload the system_config module to apply changes\n",
    "            importlib.reload(config.system_config)\n",
    "            # Re-import SC if it's used directly in this notebook, or ensure train_model gets the fresh one.\n",
    "            # from config.system_config import SC \n",
    "            print(\"System configuration reloaded.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error updating or reloading system_config.py: {e}\")\n",
    "            print(\"Proceeding with potentially outdated configuration.\")\n",
    "            # Decide if you want to return or proceed if config update fails\n",
    "            # return \n",
    "\n",
    "        selected_experiments = list(experiment_widget.value)\n",
    "        if not selected_experiments:\n",
    "            print(\"No experiment selected. Please select at least one experiment.\")\n",
    "            return\n",
    "        \n",
    "        for exp_name in selected_experiments:\n",
    "            exp_config = next((exp for exp in EXPERIMENTS if exp[\"name\"] == exp_name), None)\n",
    "            if exp_config is None:\n",
    "                print(f\"Experiment {exp_name} not found in EXPERIMENTS.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Running experiment: {exp_config['name']}\")\n",
    "            # Pass configuration values to the train_model function.\n",
    "            # train_model will use the reloaded system_config.SC for DATA_DIR and CACHE_DIR\n",
    "            model, history = train_model(\n",
    "                model_name=exp_config['model'],\n",
    "                epochs=exp_config.get('epochs'),\n",
    "                batch_size=exp_config.get('batch_size')\n",
    "            )\n",
    "            print(f\"Training completed for experiment: {exp_config['name']}\")\n",
    "            if model:\n",
    "                 model.summary(print_fn=lambda x: print(x)) # Ensure summary prints to output_area\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "run_selected_button.on_click(run_selected_experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. View Previous Results (From here down, notebook is under development)\n",
    "\n",
    "If you've already run experiments, you can view and analyse the results here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under development\n",
    "def load_results(output_dir=OUTPUT_DIR):\n",
    "    # Check if results directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        print(f\"Results directory does not exist: {output_dir}\")\n",
    "        return None\n",
    "    \n",
    "    # Look for comparison report CSV\n",
    "    csv_files = [f for f in os.listdir(output_dir) if f.startswith(\"comparison_results_\") and f.endswith(\".csv\")]\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(\"No comparison results found. Run experiments or generate a report first.\")\n",
    "        return None\n",
    "    \n",
    "    # Load the latest CSV file\n",
    "    latest_csv = max(csv_files)\n",
    "    csv_path = os.path.join(output_dir, latest_csv)\n",
    "    results_df = pd.read_csv(csv_path)\n",
    "    \n",
    "    print(f\"Loaded results from: {csv_path}\")\n",
    "    return results_df\n",
    "\n",
    "# Load and display results if available\n",
    "results_df = load_results()\n",
    "if results_df is not None:\n",
    "    display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualise Results\n",
    "\n",
    "Create various visualisations to compare experiment results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under Development\n",
    "# Taken from previously developed notebooks in Machine Learing course\n",
    "\n",
    "def visualize_results(results_df):\n",
    "    if results_df is None or len(results_df) == 0:\n",
    "        print(\"No results available to visualize.\")\n",
    "        return\n",
    "    \n",
    "    # Set the figure size for better visibility\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Create accuracy comparison bar chart\n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.barplot(x='Experiment', y='Test Accuracy', data=results_df)\n",
    "    plt.title('Test Accuracy by Experiment')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Create F1 score comparison bar chart\n",
    "    plt.subplot(2, 2, 2)\n",
    "    sns.barplot(x='Experiment', y='F1 Score', data=results_df)\n",
    "    plt.title('F1 Score by Experiment')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Training time comparison\n",
    "    plt.subplot(2, 2, 3)\n",
    "    sns.barplot(x='Experiment', y='Training Time (min)', data=results_df)\n",
    "    plt.title('Training Time by Experiment (minutes)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Model comparison\n",
    "    plt.subplot(2, 2, 4)\n",
    "    model_comparison = results_df.groupby('Model')['Test Accuracy'].mean().reset_index()\n",
    "    sns.barplot(x='Model', y='Test Accuracy', data=model_comparison)\n",
    "    plt.title('Average Accuracy by Model')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.tight_layout(pad=3.0)\n",
    "    plt.show()\n",
    "    \n",
    "    # Create a separate visualization for augmentation impact\n",
    "    plt.figure(figsize=(12, 6))\n",
    "       \n",
    "    aug_df = pd.DataFrame(aug_data)\n",
    "    sns.barplot(x='Augmentation', y='Accuracy', hue='Augmentation Type', data=aug_df)\n",
    "    plt.title('Accuracy by Augmentation Type')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize results if available\n",
    "if results_df is not None:\n",
    "    visualize_results(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Experiment Analysis and Conclusions\n",
    "(if required)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
