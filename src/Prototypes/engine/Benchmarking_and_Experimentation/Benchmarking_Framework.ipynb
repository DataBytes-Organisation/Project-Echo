{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Echo - Experiment Benchmarking Framework\n",
    "\n",
    "This notebook provides an interactive interface to the benchmarking framework. It allows you to run various experiments with different model architectures and augmentation strategies, and compare their performance.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The benchmarking framework is designed to systematically evaluate different combinations of:\n",
    "- Model architectures (EfficientNet, MobileNet, ResNet, etc.)\n",
    "- Audio augmentation strategies\n",
    "- Image/spectrogram augmentation strategies\n",
    "\n",
    "Results are collected and visualized to help identify the best performing configurations for bird sound classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Install Required Libraries\n",
    "The following cell is to install required libraries if you are running this notebook remotely, such as on an instance from Vast.ai or Google Colab.\n",
    "Ensure you have a clean Python 3.9+ kernel to start.\n",
    "Details on how to set this up are contained within the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntSlider\n",
    "from IPython.display import display\n",
    "slider = IntSlider()\n",
    "display(slider)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION FOR DEVCONTAINER ---\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# When running in devcontainer, the workspace is mounted to /workspace\n",
    "if os.path.exists('/workspace') and os.path.exists('/workspace/config'):\n",
    "    # Running in devcontainer with proper mount\n",
    "    base_path = \"/workspace\"\n",
    "    print(\"âœ“ Running in devcontainer environment\")\n",
    "elif os.path.exists('./config'):\n",
    "    # Running locally\n",
    "    base_path = os.getcwd()\n",
    "    print(\"âœ“ Running in local environment\")\n",
    "else:\n",
    "    # Fallback - try to find config directory\n",
    "    current_dir = os.getcwd()\n",
    "    parent_dir = os.path.dirname(current_dir)\n",
    "    if os.path.exists(os.path.join(current_dir, 'config')):\n",
    "        base_path = current_dir\n",
    "    elif os.path.exists(os.path.join(parent_dir, 'config')):\n",
    "        base_path = parent_dir\n",
    "    else:\n",
    "        print(\"âŒ ERROR: Cannot find config directory\")\n",
    "        print(f\"Current directory: {current_dir}\")\n",
    "        print(f\"Available files/dirs: {os.listdir(current_dir)}\")\n",
    "        base_path = current_dir\n",
    "\n",
    "print(f\"Using base path: {base_path}\")\n",
    "\n",
    "# Add to Python path\n",
    "if base_path not in sys.path:\n",
    "    sys.path.insert(0, base_path)\n",
    "\n",
    "# Verify required directories exist\n",
    "required_dirs = ['config', 'utils']\n",
    "for dir_name in required_dirs:\n",
    "    dir_path = os.path.join(base_path, dir_name)\n",
    "    exists = os.path.exists(dir_path)\n",
    "    print(f\"{dir_name} directory: {'âœ“' if exists else 'âŒ'} {dir_path}\")\n",
    "\n",
    "# --- END CONFIGURATION ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# When running in devcontainer, use the mounted workspace path\n",
    "if os.path.exists('/workspace'):\n",
    "    actual_module_path_inside_container = \"/workspace\"\n",
    "    print(\"Running in devcontainer environment\")\n",
    "else:\n",
    "    actual_module_path_inside_container = os.getcwd()\n",
    "    print(\"Running in local environment\")\n",
    "\n",
    "print(f\"Using module path: {actual_module_path_inside_container}\")\n",
    "if actual_module_path_inside_container not in sys.path:\n",
    "    sys.path.insert(0, actual_module_path_inside_container)\n",
    "\n",
    "# Verify required directories\n",
    "config_path = os.path.join(actual_module_path_inside_container, 'config')\n",
    "utils_path = os.path.join(actual_module_path_inside_container, 'utils')\n",
    "print(f\"Config directory exists: {os.path.exists(config_path)}\")\n",
    "print(f\"Utils directory exists: {os.path.exists(utils_path)}\")\n",
    "\n",
    "from config.experiment_configs import EXPERIMENTS"
   ]
  },
  {
# === Part 1: Imports & Path Setup (clean) ===
import os, sys, re, importlib, warnings
warnings.filterwarnings("ignore")

# Reduce TF logging noise before importing TF
os.environ.setdefault("TF_CPP_MIN_LOG_LEVEL", "2")
import tensorflow as tf

# Plotting (ä¸å¼ºä¾èµ– seabornï¼Œé¿å…ç¯å¢ƒç¼ºåŒ…å¯¼è‡´ä¸­æ–­)
import matplotlib.pyplot as plt
try:
    import pandas as pd
except Exception:
    pd = None  # è‹¥æœªå®‰è£…ä¹Ÿä¸å½±å“åç»­è®­ç»ƒ

# Jupyter helpers
from IPython.display import display, HTML, clear_output

# === Ensure project modules are importable ===
# ç›®æ ‡ï¼šæŠŠåŒ…å« `config/experiment_configs.py` çš„ç›®å½•åŠ å…¥ sys.path
def _add_project_root_to_path(max_up=5):
    here = os.getcwd()
    for _ in range(max_up + 1):
        candidate_cfg = os.path.join(here, "config", "experiment_configs.py")
        if os.path.isfile(candidate_cfg):
            if here not in sys.path:
                sys.path.append(here)
            return here
        # å†å°è¯•ä¸Šçº§ç›®å½•
        parent = os.path.dirname(here)
        if parent == here:
            break
        here = parent
    # å…œåº•ï¼šæŠŠå½“å‰å·¥ä½œç›®å½•åŠ å…¥ sys.pathï¼ˆå³ä½¿æ²¡æ‰¾åˆ°ä¹Ÿä¸æŠ¥é”™ï¼‰
    if os.getcwd() not in sys.path:
        sys.path.append(os.getcwd())
    return os.getcwd()

PROJECT_ROOT = _add_project_root_to_path()

# === Import framework components ===
from config.experiment_configs import EXPERIMENTS
# å¦‚éœ€åç»­ç›´æ¥ä½¿ç”¨æ¨¡å‹æˆ–ç³»ç»Ÿé…ç½®ï¼Œå¯è§£å¼€ä¸‹é¢ä¸¤è¡Œï¼š
# from config.model_configs import MODELS
# from config.system_config import SC

# å°å·¥å…·ï¼šæ‰“å°ç¯å¢ƒä¿¡æ¯ï¼Œä¾¿äºæ’é”™
def show_env():
    gpu = tf.config.list_physical_devices('GPU')
    print(f"Project root: {PROJECT_ROOT}")
    print(f"TensorFlow: {tf.__version__} | GPU available: {bool(gpu)} | GPUs: {gpu}")
show_env()

   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Set up the directories and options for benchmarking.\n",
    "Ensure to update these in the `system_config.py` file in the `config` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import directories from system_config\n",
    "from config.system_config import SC\n",
    "\n",
    "# Get directory paths from system config\n",
    "DATA_DIR = SC['AUDIO_DATA_DIRECTORY']\n",
    "CACHE_DIR = SC['CACHE_DIRECTORY']\n",
    "OUTPUT_DIR = SC['OUTPUT_DIRECTORY']\n",
    "\n",
    "print(\"Using directories from system_config:\")\n",
    "print(f\"Data Directory: {DATA_DIR}\")\n",
    "print(f\"Cache Directory: {CACHE_DIR}\")\n",
    "print(f\"Output Directory: {OUTPUT_DIR}\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# GPU info\n",
    "print(\"Physical GPUs:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU name:\", tf.test.gpu_device_name())\n",
    "\n",
    "# Configure GPU memory if available\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(f\"GPU support enabled: {len(gpus)} GPU(s) found\")\n",
    "else:\n",
    "    print(\"No GPU support found, running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display available experiments\n",
    "import pandas as pd\n",
    "\n",
    "experiment_data = []\n",
    "for exp in EXPERIMENTS:\n",
    "    experiment_data.append({\n",
    "        \"name\": exp[\"name\"],\n",
    "        \"model\": exp[\"model\"],\n",
    "        \"audio_augmentation\": exp[\"audio_augmentation\"],\n",
    "        \"image_augmentation\": exp[\"image_augmentation\"],\n",
    "        \"epochs\": exp[\"epochs\"],\n",
    "        \"batch_size\": exp[\"batch_size\"]\n",
    "    })\n",
    "\n",
    "experiments_df = pd.DataFrame(experiment_data)\n",
    "display(experiments_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interactive Experiment Selection\n",
    "Use the widgets below to select experiments and set directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create widgets for directory selection\n",
    "data_dir_widget = widgets.Text(\n",
    "    value=DATA_DIR,\n",
    "    description='Data Directory:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "cache_dir_widget = widgets.Text(\n",
    "    value=CACHE_DIR,\n",
    "    description='Cache Directory:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "output_dir_widget = widgets.Text(\n",
    "    value=OUTPUT_DIR,\n",
    "    description='Output Directory:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "# Group directory widgets\n",
    "dir_widgets_box = widgets.VBox([data_dir_widget, cache_dir_widget, output_dir_widget])\n",
    "\n",
    "# Create widget for experiment selection\n",
    "experiment_options = [(exp[\"name\"], exp[\"name\"]) for exp in EXPERIMENTS]\n",
    "experiment_widget = widgets.SelectMultiple(\n",
    "    options=experiment_options,\n",
    "    description='Select Experiments:',\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='50%', height='200px')\n",
    ")\n",
    "\n",
    "# Buttons for actions\n",
    "run_selected_button = widgets.Button(\n",
    "    description='Run Selected Experiments',\n",
    "    button_style='primary',\n",
    "    tooltip='Run the selected experiments'\n",
    ")\n",
    "run_all_button = widgets.Button(\n",
    "    description='Run All Experiments',\n",
    "    tooltip='Run all experiments'\n",
    ")\n",
    "generate_report_button = widgets.Button(\n",
    "    description='Generate Report Only',\n",
    "    button_style='info',\n",
    "    tooltip='Generate a report from existing results'\n",
    ")\n",
    "\n",
    "# Group buttons\n",
    "buttons_box = widgets.HBox([run_selected_button, run_all_button, generate_report_button])\n",
    "\n",
    "# Output area for logs\n",
    "output_area = widgets.Output(layout={'border': '1px solid black', 'width': '90%', 'height': '300px'})\n",
    "\n",
    "# Main container\n",
    "controls_box = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Directory Configuration:</h3>\"),\n",
    "    dir_widgets_box,\n",
    "    widgets.HTML(\"<hr><h3>Experiment Selection:</h3>\"),\n",
    "    experiment_widget,\n",
    "    widgets.HTML(\"<hr><h3>Actions:</h3>\"),\n",
    "    buttons_box\n",
    "])\n",
    "\n",
    "display(controls_box)\n",
    "display(output_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experiment Runner Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.optimised_engine_pipeline import train_model\n",
    "import importlib\n",
    "import config.system_config  # Ensure module import\n",
    "\n",
    "def run_selected_experiments(b):\n",
    "    \"\"\"Run experiments based on widget selections.\n",
    "    Updates configuration in memory and ensures directories exist.\"\"\"\n",
    "    output_area.clear_output(wait=True)\n",
    "    with output_area:\n",
    "        print(\"Starting experiment run...\")\n",
    "\n",
    "        # Get new directory paths from widgets\n",
    "        new_data_dir = data_dir_widget.value\n",
    "        new_cache_dir = cache_dir_widget.value\n",
    "        new_output_dir = output_dir_widget.value\n",
    "\n",
    "        # Update config directly in memory\n",
    "        from config.system_config import SC\n",
    "        SC['AUDIO_DATA_DIRECTORY'] = new_data_dir\n",
    "        SC['CACHE_DIRECTORY'] = new_cache_dir\n",
    "        SC['OUTPUT_DIRECTORY'] = new_output_dir\n",
    "        print(\"System configuration updated in memory.\")\n",
    "        print(f\"  - Data Dir: {SC['AUDIO_DATA_DIRECTORY']}\")\n",
    "        print(f\"  - Cache Dir: {SC['CACHE_DIRECTORY']}\")\n",
    "        print(f\"  - Output Dir: {SC['OUTPUT_DIRECTORY']}\")\n",
    "\n", 
    "        # Ensure directories exist\n",
    "        for path in [new_data_dir, new_cache_dir, new_output_dir]:\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "\n",
    "        selected_experiments = list(experiment_widget.value)\n",
    "        if not selected_experiments:\n",
    "            print(\"No experiment selected. Please select at least one experiment.\")\n",
    "            return\n",
    "\n",
    "        for exp_name in selected_experiments:\n",
    "            exp_config = next((exp for exp in EXPERIMENTS if exp[\"name\"] == exp_name), None)\n",
    "            if exp_config is None:\n",
    "                print(f\"Experiment {exp_name} not found in EXPERIMENTS.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\nRunning experiment: {exp_config['name']}\")\n",
    "            try:\n",
    "                model, history = train_model(\n",
    "                    model_name=exp_config['model'],\n",
    "                    epochs=exp_config.get('epochs'),\n",
    "                    batch_size=exp_config.get('batch_size')\n",
    "                )\n",
    "                print(f\"âœ… Training completed for experiment: {exp_config['name']}\")\n",
    "                if model:\n",
    "                    model.summary(print_fn=lambda x: print(x))\n",
    "            except Exception as e:\n",
    "                import traceback\n",
    "                print(f\"âŒ An error occurred during training for experiment {exp_config['name']}:\")\n",
    "                traceback.print_exc()\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "# Bind button\n",
    "run_selected_button.on_click(run_selected_experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. View Previous Results (under development)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def load_results(output_dir=OUTPUT_DIR):\n",
    "    if not os.path.exists(output_dir):\n",
    "        print(f\"Results directory does not exist: {output_dir}\")\n",
    "        return None\n",
    "    csv_files = [f for f in os.listdir(output_dir) if f.startswith(\"comparison_results_\") and f.endswith(\".csv\")]\n",
    "    if not csv_files:\n",
    "        print(\"No comparison results found. Run experiments or generate a report first.\")\n",
    "        return None\n",
    "    latest_csv = max(csv_files)\n",
    "    csv_path = os.path.join(output_dir, latest_csv)\n",
    "    results_df = pd.read_csv(csv_path)\n",
    "    print(f\"Loaded results from: {csv_path}\")\n",
    "    return results_df\n",
    "\n",
    "results_df = load_results()\n",
    "if results_df is not None:\n",
    "    display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualise Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def visualize_results(results_df):\n",
    "    if results_df is None or len(results_df) == 0:\n",
    "        print(\"No results available to visualize.\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.barplot(x='Experiment', y='Test Accuracy', data=results_df)\n",
    "    plt.title('Test Accuracy by Experiment')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # F1\n",
    "    plt.subplot(2, 2, 2)\n",
    "    sns.barplot(x='Experiment', y='F1 Score', data=results_df)\n",
    "    plt.title('F1 Score by Experiment')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Training time\n",
    "    plt.subplot(2, 2, 3)\n",
    "    sns.barplot(x='Experiment', y='Training Time (min)', data=results_df)\n",
    "    plt.title('Training Time by Experiment (minutes)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Average by Model\n",
    "    plt.subplot(2, 2, 4)\n",
    "    model_comparison = results_df.groupby('Model')['Test Accuracy'].mean().reset_index()\n",
    "    sns.barplot(x='Model', y='Test Accuracy', data=model_comparison)\n",
    "    plt.title('Average Accuracy by Model')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.tight_layout(pad=3.0)\n",
    "    plt.show()\n",
    "\n",
    "if results_df is not None:\n",
    "    visualize_results(results_df)"
   ]

# === Section 8: Experiment Analysis, Env Check, TensorBoard Fix & Training (single cell replacement) ===
import os, sys, datetime, shutil, warnings

# 1) ç¯å¢ƒå®‰é™ & ç‰ˆæœ¬æ£€æŸ¥ï¼ˆå¯é€‰ä¾èµ–ä¸ä¼šä¸­æ–­ï¼‰
warnings.filterwarnings("ignore")
os.environ.setdefault("TF_CPP_MIN_LOG_LEVEL", "2")

def _vers(mod, attr="__version__"):
    try:
        m = __import__(mod)
        v = getattr(m, attr, "?")
        print(f"âœ… {mod}: {v}")
    except Exception as e:
        print(f"âš ï¸ {mod}: not available ({e.__class__.__name__})")

_vers("tensorflow")
_vers("tensorflow_hub")
_vers("numpy")
_vers("pandas")
_vers("matplotlib")
_vers("librosa")
_vers("sklearn")
_vers("soundfile")

import tensorflow as tf

# 2) è‡ªåŠ¨å®šä½é¡¹ç›®æ ¹ç›®å½•ï¼ˆåŒ…å« config/experiment_configs.pyï¼‰
def _add_project_root_to_path(max_up=5):
    here = os.getcwd()
    for _ in range(max_up + 1):
        candidate_cfg = os.path.join(here, "config", "experiment_configs.py")
        if os.path.isfile(candidate_cfg):
            if here not in sys.path:
                sys.path.append(here)
            return here
        parent = os.path.dirname(here)
        if parent == here:
            break
        here = parent
    if os.getcwd() not in sys.path:
        sys.path.append(os.getcwd())
    return os.getcwd()

PROJECT_ROOT = _add_project_root_to_path()

# 3) é¡¹ç›®å†…å¯¼å…¥
from config.experiment_configs import EXPERIMENTS
from config.system_config import SC
from utils.optimised_engine_pipeline import train_model

# 4) å…³é”®ä¿®å¤ï¼šç¡®ä¿ TensorBoard æ—¥å¿—â€œæ˜¯ç›®å½•ä¸”å­˜åœ¨â€
def ensure_tb_dir_ok(base_dir: str = None) -> str:
    """
    ç¡®ä¿ TensorBoard æ—¥å¿—ç›®å½•å­˜åœ¨ä¸”ä¸ºç›®å½•ã€‚
    - è‹¥å­˜åœ¨åŒåæ–‡ä»¶å ä½ï¼šè‡ªåŠ¨æ”¹åå¤‡ä»½ä¸º *.bak_æ—¶é—´æˆ³ï¼Œå¹¶åˆ›å»ºç›®å½•
    - è‹¥ç›®å½•ä¸å­˜åœ¨ï¼šåˆ›å»ºç›®å½•
    - è¿”å›ï¼šæœ¬æ¬¡è¿è¡Œçš„å­ç›®å½•è·¯å¾„ï¼ˆtensorboard_logs/run_æ—¶é—´æˆ³ï¼‰
    """
    if base_dir is None:
        base_dir = SC.get("TENSORBOARD_LOG_DIR", os.path.join(os.getcwd(), "tensorboard_logs"))

    # åŒåâ€œæ–‡ä»¶â€ -> å¤‡ä»½å¹¶æ”¹ä¸ºç›®å½•
    if os.path.exists(base_dir) and not os.path.isdir(base_dir):
        bak = base_dir + ".bak_" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
        shutil.move(base_dir, bak)
        print(f"âš ï¸ å‘ç°ä¸æ—¥å¿—ç›®å½•åŒåçš„æ–‡ä»¶ï¼Œå·²é‡å‘½åä¸º: {bak}")

    os.makedirs(base_dir, exist_ok=True)

    run_dir = os.path.join(base_dir, "run_" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
    os.makedirs(run_dir, exist_ok=True)
    return run_dir

tb_run_dir = ensure_tb_dir_ok()

# åšä¸€æ¬¡ ping æµ‹è¯•ï¼ˆTensorBoard å¯è§ï¼‰
writer = tf.summary.create_file_writer(tb_run_dir)
with writer.as_default():
    tf.summary.scalar("ping", 1.0, step=0)
print("âœ… TensorBoard æ—¥å¿—å†™å…¥æˆåŠŸï¼š", tb_run_dir)

# 5) é€‰æ‹© baseline å®éªŒå¹¶è®­ç»ƒ
# ä¼˜å…ˆç²¾ç¡®ååŒ¹é…ï¼›è‹¥ä¸å­˜åœ¨ï¼Œå›é€€åˆ°åŒ…å«å…³é”®å­—çš„ç¬¬ä¸€ä¸ªå®éªŒ
target_name = "mobilenet_v3_small_baseline"
exp_cfg = None
for e in EXPERIMENTS:
    if e.get("name") == target_name:
        exp_cfg = e
        break
if exp_cfg is None:
    exp_cfg = next((e for e in EXPERIMENTS if "mobilenet_v3_small" in e.get("name", "").lower()), None)
    if exp_cfg is None:
        raise RuntimeError("æœªæ‰¾åˆ° mobilenet_v3_small_baseline å®éªŒé…ç½®ï¼Œè¯·æ£€æŸ¥ EXPERIMENTSã€‚")

print("Project root:", PROJECT_ROOT)
print("Data dir:", SC.get("AUDIO_DATA_DIRECTORY", "<unset>"))
print("Starting training for model:", exp_cfg["model"])

trained_model, history = train_model(
    model_name=exp_cfg["model"],
    epochs=SC["MAX_EPOCHS"],
    batch_size=SC["BATCH_SIZE"]
)

# 6) ç®€è¦ç»“æœè¾“å‡º
final_acc = history.history.get("accuracy", [None])[-1] if hasattr(history, "history") else None
val_final_acc = None
for k in ("val_accuracy", "val_acc"):
    if k in getattr(history, "history", {}):
        val_final_acc = history.history[k][-1]
        break

print("âœ… Training finished.")
print("ğŸ“Š Final train acc:", final_acc)
print("ğŸ“Š Final val acc:", val_final_acc)
print("â„¹ï¸ ä½ å¯ä»¥è¿è¡Œ: `tensorboard --logdir \"{}\"` æŸ¥çœ‹å¯è§†åŒ–".format(os.path.dirname(tb_run_dir)))


  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_echo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": { "name": "ipython", "version": 3 },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
    "version": "3.10.18"

  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
