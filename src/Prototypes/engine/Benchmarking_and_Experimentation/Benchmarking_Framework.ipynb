{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Echo - Experiment Benchmarking Framework\n",
    "\n",
    "This notebook provides an interactive interface to the benchmarking framework. It allows you to run various experiments with different model architectures and augmentation strategies, and compare their performance.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The benchmarking framework is designed to systematically evaluate different combinations of:\n",
    "- Model architectures (EfficientNet, MobileNet, ResNet, etc.)\n",
    "- Audio augmentation strategies\n",
    "- Image/spectrogram augmentation strategies\n",
    "\n",
    "Results are collected and visualized to help identify the best performing configurations for bird sound classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Install Required Libraries\n",
    "The following cell is to install required libraries if you are running this notebook remotely, such as on an instance from Vast.ai or Google Colab.\n",
    "Ensure you have a clean Python 3.9+ kernel to start.\n",
    "Details on how to set this up are contained within the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntSlider\n",
    "from IPython.display import display\n",
    "slider = IntSlider()\n",
    "display(slider)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION FOR DEVCONTAINER ---\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# When running in devcontainer, the workspace is mounted to /workspace\n",
    "if os.path.exists('/workspace') and os.path.exists('/workspace/config'):\n",
    "    # Running in devcontainer with proper mount\n",
    "    base_path = \"/workspace\"\n",
    "    print(\"✓ Running in devcontainer environment\")\n",
    "elif os.path.exists('./config'):\n",
    "    # Running locally\n",
    "    base_path = os.getcwd()\n",
    "    print(\"✓ Running in local environment\")\n",
    "else:\n",
    "    # Fallback - try to find config directory\n",
    "    current_dir = os.getcwd()\n",
    "    parent_dir = os.path.dirname(current_dir)\n",
    "    if os.path.exists(os.path.join(current_dir, 'config')):\n",
    "        base_path = current_dir\n",
    "    elif os.path.exists(os.path.join(parent_dir, 'config')):\n",
    "        base_path = parent_dir\n",
    "    else:\n",
    "        print(\"❌ ERROR: Cannot find config directory\")\n",
    "        print(f\"Current directory: {current_dir}\")\n",
    "        print(f\"Available files/dirs: {os.listdir(current_dir)}\")\n",
    "        base_path = current_dir\n",
    "\n",
    "print(f\"Using base path: {base_path}\")\n",
    "\n",
    "# Add to Python path\n",
    "if base_path not in sys.path:\n",
    "    sys.path.insert(0, base_path)\n",
    "\n",
    "# Verify required directories exist\n",
    "required_dirs = ['config', 'utils']\n",
    "for dir_name in required_dirs:\n",
    "    dir_path = os.path.join(base_path, dir_name)\n",
    "    exists = os.path.exists(dir_path)\n",
    "    print(f\"{dir_name} directory: {'✓' if exists else '❌'} {dir_path}\")\n",
    "\n",
    "# --- END CONFIGURATION ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# When running in devcontainer, use the mounted workspace path\n",
    "if os.path.exists('/workspace'):\n",
    "    actual_module_path_inside_container = \"/workspace\"\n",
    "    print(\"Running in devcontainer environment\")\n",
    "else:\n",
    "    actual_module_path_inside_container = os.getcwd()\n",
    "    print(\"Running in local environment\")\n",
    "\n",
    "print(f\"Using module path: {actual_module_path_inside_container}\")\n",
    "if actual_module_path_inside_container not in sys.path:\n",
    "    sys.path.insert(0, actual_module_path_inside_container)\n",
    "\n",
    "# Verify required directories\n",
    "config_path = os.path.join(actual_module_path_inside_container, 'config')\n",
    "utils_path = os.path.join(actual_module_path_inside_container, 'utils')\n",
    "print(f\"Config directory exists: {os.path.exists(config_path)}\")\n",
    "print(f\"Utils directory exists: {os.path.exists(utils_path)}\")\n",
    "\n",
    "from config.experiment_configs import EXPERIMENTS"
   ]
  },
  {
# === Part 1: Imports & Path Setup (clean) ===
import os, sys, re, importlib, warnings
warnings.filterwarnings("ignore")

# Reduce TF logging noise before importing TF
os.environ.setdefault("TF_CPP_MIN_LOG_LEVEL", "2")
import tensorflow as tf

# Plotting (不强依赖 seaborn，避免环境缺包导致中断)
import matplotlib.pyplot as plt
try:
    import pandas as pd
except Exception:
    pd = None  # 若未安装也不影响后续训练

# Jupyter helpers
from IPython.display import display, HTML, clear_output

# === Ensure project modules are importable ===
# 目标：把包含 `config/experiment_configs.py` 的目录加入 sys.path
def _add_project_root_to_path(max_up=5):
    here = os.getcwd()
    for _ in range(max_up + 1):
        candidate_cfg = os.path.join(here, "config", "experiment_configs.py")
        if os.path.isfile(candidate_cfg):
            if here not in sys.path:
                sys.path.append(here)
            return here
        # 再尝试上级目录
        parent = os.path.dirname(here)
        if parent == here:
            break
        here = parent
    # 兜底：把当前工作目录加入 sys.path（即使没找到也不报错）
    if os.getcwd() not in sys.path:
        sys.path.append(os.getcwd())
    return os.getcwd()

PROJECT_ROOT = _add_project_root_to_path()

# === Import framework components ===
from config.experiment_configs import EXPERIMENTS
# 如需后续直接使用模型或系统配置，可解开下面两行：
# from config.model_configs import MODELS
# from config.system_config import SC

# 小工具：打印环境信息，便于排错
def show_env():
    gpu = tf.config.list_physical_devices('GPU')
    print(f"Project root: {PROJECT_ROOT}")
    print(f"TensorFlow: {tf.__version__} | GPU available: {bool(gpu)} | GPUs: {gpu}")
show_env()

   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Set up the directories and options for benchmarking.\n",
    "Ensure to update these in the `system_config.py` file in the `config` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import directories from system_config\n",
    "from config.system_config import SC\n",
    "\n",
    "# Get directory paths from system config\n",
    "DATA_DIR = SC['AUDIO_DATA_DIRECTORY']\n",
    "CACHE_DIR = SC['CACHE_DIRECTORY']\n",
    "OUTPUT_DIR = SC['OUTPUT_DIRECTORY']\n",
    "\n",
    "print(\"Using directories from system_config:\")\n",
    "print(f\"Data Directory: {DATA_DIR}\")\n",
    "print(f\"Cache Directory: {CACHE_DIR}\")\n",
    "print(f\"Output Directory: {OUTPUT_DIR}\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# GPU info\n",
    "print(\"Physical GPUs:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU name:\", tf.test.gpu_device_name())\n",
    "\n",
    "# Configure GPU memory if available\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(f\"GPU support enabled: {len(gpus)} GPU(s) found\")\n",
    "else:\n",
    "    print(\"No GPU support found, running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display available experiments\n",
    "import pandas as pd\n",
    "\n",
    "experiment_data = []\n",
    "for exp in EXPERIMENTS:\n",
    "    experiment_data.append({\n",
    "        \"name\": exp[\"name\"],\n",
    "        \"model\": exp[\"model\"],\n",
    "        \"audio_augmentation\": exp[\"audio_augmentation\"],\n",
    "        \"image_augmentation\": exp[\"image_augmentation\"],\n",
    "        \"epochs\": exp[\"epochs\"],\n",
    "        \"batch_size\": exp[\"batch_size\"]\n",
    "    })\n",
    "\n",
    "experiments_df = pd.DataFrame(experiment_data)\n",
    "display(experiments_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interactive Experiment Selection\n",
    "Use the widgets below to select experiments and set directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create widgets for directory selection\n",
    "data_dir_widget = widgets.Text(\n",
    "    value=DATA_DIR,\n",
    "    description='Data Directory:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "cache_dir_widget = widgets.Text(\n",
    "    value=CACHE_DIR,\n",
    "    description='Cache Directory:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "output_dir_widget = widgets.Text(\n",
    "    value=OUTPUT_DIR,\n",
    "    description='Output Directory:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "# Group directory widgets\n",
    "dir_widgets_box = widgets.VBox([data_dir_widget, cache_dir_widget, output_dir_widget])\n",
    "\n",
    "# Create widget for experiment selection\n",
    "experiment_options = [(exp[\"name\"], exp[\"name\"]) for exp in EXPERIMENTS]\n",
    "experiment_widget = widgets.SelectMultiple(\n",
    "    options=experiment_options,\n",
    "    description='Select Experiments:',\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='50%', height='200px')\n",
    ")\n",
    "\n",
    "# Buttons for actions\n",
    "run_selected_button = widgets.Button(\n",
    "    description='Run Selected Experiments',\n",
    "    button_style='primary',\n",
    "    tooltip='Run the selected experiments'\n",
    ")\n",
    "run_all_button = widgets.Button(\n",
    "    description='Run All Experiments',\n",
    "    tooltip='Run all experiments'\n",
    ")\n",
    "generate_report_button = widgets.Button(\n",
    "    description='Generate Report Only',\n",
    "    button_style='info',\n",
    "    tooltip='Generate a report from existing results'\n",
    ")\n",
    "\n",
    "# Group buttons\n",
    "buttons_box = widgets.HBox([run_selected_button, run_all_button, generate_report_button])\n",
    "\n",
    "# Output area for logs\n",
    "output_area = widgets.Output(layout={'border': '1px solid black', 'width': '90%', 'height': '300px'})\n",
    "\n",
    "# Main container\n",
    "controls_box = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Directory Configuration:</h3>\"),\n",
    "    dir_widgets_box,\n",
    "    widgets.HTML(\"<hr><h3>Experiment Selection:</h3>\"),\n",
    "    experiment_widget,\n",
    "    widgets.HTML(\"<hr><h3>Actions:</h3>\"),\n",
    "    buttons_box\n",
    "])\n",
    "\n",
    "display(controls_box)\n",
    "display(output_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experiment Runner Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.optimised_engine_pipeline import train_model\n",
    "import importlib\n",
    "import config.system_config  # Ensure module import\n",
    "\n",
    "def run_selected_experiments(b):\n",
    "    \"\"\"Run experiments based on widget selections.\n",
    "    Updates configuration in memory and ensures directories exist.\"\"\"\n",
    "    output_area.clear_output(wait=True)\n",
    "    with output_area:\n",
    "        print(\"Starting experiment run...\")\n",
    "\n",
    "        # Get new directory paths from widgets\n",
    "        new_data_dir = data_dir_widget.value\n",
    "        new_cache_dir = cache_dir_widget.value\n",
    "        new_output_dir = output_dir_widget.value\n",
    "\n",
    "        # Update config directly in memory\n",
    "        from config.system_config import SC\n",
    "        SC['AUDIO_DATA_DIRECTORY'] = new_data_dir\n",
    "        SC['CACHE_DIRECTORY'] = new_cache_dir\n",
    "        SC['OUTPUT_DIRECTORY'] = new_output_dir\n",
    "        print(\"System configuration updated in memory.\")\n",
    "        print(f\"  - Data Dir: {SC['AUDIO_DATA_DIRECTORY']}\")\n",
    "        print(f\"  - Cache Dir: {SC['CACHE_DIRECTORY']}\")\n",
    "        print(f\"  - Output Dir: {SC['OUTPUT_DIRECTORY']}\")\n",
    "\n", 
    "        # Ensure directories exist\n",
    "        for path in [new_data_dir, new_cache_dir, new_output_dir]:\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "\n",
    "        selected_experiments = list(experiment_widget.value)\n",
    "        if not selected_experiments:\n",
    "            print(\"No experiment selected. Please select at least one experiment.\")\n",
    "            return\n",
    "\n",
    "        for exp_name in selected_experiments:\n",
    "            exp_config = next((exp for exp in EXPERIMENTS if exp[\"name\"] == exp_name), None)\n",
    "            if exp_config is None:\n",
    "                print(f\"Experiment {exp_name} not found in EXPERIMENTS.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\nRunning experiment: {exp_config['name']}\")\n",
    "            try:\n",
    "                model, history = train_model(\n",
    "                    model_name=exp_config['model'],\n",
    "                    epochs=exp_config.get('epochs'),\n",
    "                    batch_size=exp_config.get('batch_size')\n",
    "                )\n",
    "                print(f\"✅ Training completed for experiment: {exp_config['name']}\")\n",
    "                if model:\n",
    "                    model.summary(print_fn=lambda x: print(x))\n",
    "            except Exception as e:\n",
    "                import traceback\n",
    "                print(f\"❌ An error occurred during training for experiment {exp_config['name']}:\")\n",
    "                traceback.print_exc()\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "# Bind button\n",
    "run_selected_button.on_click(run_selected_experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. View Previous Results (under development)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def load_results(output_dir=OUTPUT_DIR):\n",
    "    if not os.path.exists(output_dir):\n",
    "        print(f\"Results directory does not exist: {output_dir}\")\n",
    "        return None\n",
    "    csv_files = [f for f in os.listdir(output_dir) if f.startswith(\"comparison_results_\") and f.endswith(\".csv\")]\n",
    "    if not csv_files:\n",
    "        print(\"No comparison results found. Run experiments or generate a report first.\")\n",
    "        return None\n",
    "    latest_csv = max(csv_files)\n",
    "    csv_path = os.path.join(output_dir, latest_csv)\n",
    "    results_df = pd.read_csv(csv_path)\n",
    "    print(f\"Loaded results from: {csv_path}\")\n",
    "    return results_df\n",
    "\n",
    "results_df = load_results()\n",
    "if results_df is not None:\n",
    "    display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualise Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def visualize_results(results_df):\n",
    "    if results_df is None or len(results_df) == 0:\n",
    "        print(\"No results available to visualize.\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.barplot(x='Experiment', y='Test Accuracy', data=results_df)\n",
    "    plt.title('Test Accuracy by Experiment')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # F1\n",
    "    plt.subplot(2, 2, 2)\n",
    "    sns.barplot(x='Experiment', y='F1 Score', data=results_df)\n",
    "    plt.title('F1 Score by Experiment')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Training time\n",
    "    plt.subplot(2, 2, 3)\n",
    "    sns.barplot(x='Experiment', y='Training Time (min)', data=results_df)\n",
    "    plt.title('Training Time by Experiment (minutes)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Average by Model\n",
    "    plt.subplot(2, 2, 4)\n",
    "    model_comparison = results_df.groupby('Model')['Test Accuracy'].mean().reset_index()\n",
    "    sns.barplot(x='Model', y='Test Accuracy', data=model_comparison)\n",
    "    plt.title('Average Accuracy by Model')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.tight_layout(pad=3.0)\n",
    "    plt.show()\n",
    "\n",
    "if results_df is not None:\n",
    "    visualize_results(results_df)"
   ]

# === Section 8: Experiment Analysis, Env Check, TensorBoard Fix & Training (single cell replacement) ===
import os, sys, datetime, shutil, warnings

# 1) 环境安静 & 版本检查（可选依赖不会中断）
warnings.filterwarnings("ignore")
os.environ.setdefault("TF_CPP_MIN_LOG_LEVEL", "2")

def _vers(mod, attr="__version__"):
    try:
        m = __import__(mod)
        v = getattr(m, attr, "?")
        print(f"✅ {mod}: {v}")
    except Exception as e:
        print(f"⚠️ {mod}: not available ({e.__class__.__name__})")

_vers("tensorflow")
_vers("tensorflow_hub")
_vers("numpy")
_vers("pandas")
_vers("matplotlib")
_vers("librosa")
_vers("sklearn")
_vers("soundfile")

import tensorflow as tf

# 2) 自动定位项目根目录（包含 config/experiment_configs.py）
def _add_project_root_to_path(max_up=5):
    here = os.getcwd()
    for _ in range(max_up + 1):
        candidate_cfg = os.path.join(here, "config", "experiment_configs.py")
        if os.path.isfile(candidate_cfg):
            if here not in sys.path:
                sys.path.append(here)
            return here
        parent = os.path.dirname(here)
        if parent == here:
            break
        here = parent
    if os.getcwd() not in sys.path:
        sys.path.append(os.getcwd())
    return os.getcwd()

PROJECT_ROOT = _add_project_root_to_path()

# 3) 项目内导入
from config.experiment_configs import EXPERIMENTS
from config.system_config import SC
from utils.optimised_engine_pipeline import train_model

# 4) 关键修复：确保 TensorBoard 日志“是目录且存在”
def ensure_tb_dir_ok(base_dir: str = None) -> str:
    """
    确保 TensorBoard 日志目录存在且为目录。
    - 若存在同名文件占位：自动改名备份为 *.bak_时间戳，并创建目录
    - 若目录不存在：创建目录
    - 返回：本次运行的子目录路径（tensorboard_logs/run_时间戳）
    """
    if base_dir is None:
        base_dir = SC.get("TENSORBOARD_LOG_DIR", os.path.join(os.getcwd(), "tensorboard_logs"))

    # 同名“文件” -> 备份并改为目录
    if os.path.exists(base_dir) and not os.path.isdir(base_dir):
        bak = base_dir + ".bak_" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
        shutil.move(base_dir, bak)
        print(f"⚠️ 发现与日志目录同名的文件，已重命名为: {bak}")

    os.makedirs(base_dir, exist_ok=True)

    run_dir = os.path.join(base_dir, "run_" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
    os.makedirs(run_dir, exist_ok=True)
    return run_dir

tb_run_dir = ensure_tb_dir_ok()

# 做一次 ping 测试（TensorBoard 可见）
writer = tf.summary.create_file_writer(tb_run_dir)
with writer.as_default():
    tf.summary.scalar("ping", 1.0, step=0)
print("✅ TensorBoard 日志写入成功：", tb_run_dir)

# 5) 选择 baseline 实验并训练
# 优先精确名匹配；若不存在，回退到包含关键字的第一个实验
target_name = "mobilenet_v3_small_baseline"
exp_cfg = None
for e in EXPERIMENTS:
    if e.get("name") == target_name:
        exp_cfg = e
        break
if exp_cfg is None:
    exp_cfg = next((e for e in EXPERIMENTS if "mobilenet_v3_small" in e.get("name", "").lower()), None)
    if exp_cfg is None:
        raise RuntimeError("未找到 mobilenet_v3_small_baseline 实验配置，请检查 EXPERIMENTS。")

print("Project root:", PROJECT_ROOT)
print("Data dir:", SC.get("AUDIO_DATA_DIRECTORY", "<unset>"))
print("Starting training for model:", exp_cfg["model"])

trained_model, history = train_model(
    model_name=exp_cfg["model"],
    epochs=SC["MAX_EPOCHS"],
    batch_size=SC["BATCH_SIZE"]
)

# 6) 简要结果输出
final_acc = history.history.get("accuracy", [None])[-1] if hasattr(history, "history") else None
val_final_acc = None
for k in ("val_accuracy", "val_acc"):
    if k in getattr(history, "history", {}):
        val_final_acc = history.history[k][-1]
        break

print("✅ Training finished.")
print("📊 Final train acc:", final_acc)
print("📊 Final val acc:", val_final_acc)
print("ℹ️ 你可以运行: `tensorboard --logdir \"{}\"` 查看可视化".format(os.path.dirname(tb_run_dir)))


  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_echo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": { "name": "ipython", "version": 3 },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
    "version": "3.10.18"

  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
