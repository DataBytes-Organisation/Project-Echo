{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Echo - Experiment Benchmarking Framework\n",
    "\n",
    "This notebook provides an interactive interface to the benchmarking framework. It allows you to run various experiments with different model architectures and augmentation strategies, and compare their performance.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The benchmarking framework is designed to systematically evaluate different combinations of:\n",
    "- Model architectures (EfficientNet, MobileNet, ResNet, etc.)\n",
    "- Audio augmentation strategies\n",
    "- Image/spectrogram augmentation strategies\n",
    "\n",
    "Results are collected and visualized to help identify the best performing configurations for bird sound classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1 Install Required Libraries\n",
    "The following cell is to install required libraries if you are running this notebook remotly, such as on an instance from Vast.ai or google colab.\n",
    "Ensure you have a clean python 3.9.21 kernal to start.\n",
    "Details on how to set this up are contained within the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntSlider\n",
    "from IPython.display import display\n",
    "slider = IntSlider()\n",
    "display(slider)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION FOR DEVCONTAINER ---\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# When running in devcontainer, the workspace is mounted to /workspace\n",
    "if os.path.exists('/workspace') and os.path.exists('/workspace/config'):\n",
    "    # Running in devcontainer with proper mount\n",
    "    base_path = \"/workspace\"\n",
    "    print(\"✓ Running in devcontainer environment\")\n",
    "elif os.path.exists('./config'):\n",
    "    # Running locally\n",
    "    base_path = os.getcwd()\n",
    "    print(\"✓ Running in local environment\")\n",
    "else:\n",
    "    # Fallback - try to find config directory\n",
    "    current_dir = os.getcwd()\n",
    "    parent_dir = os.path.dirname(current_dir)\n",
    "    \n",
    "    if os.path.exists(os.path.join(current_dir, 'config')):\n",
    "        base_path = current_dir\n",
    "    elif os.path.exists(os.path.join(parent_dir, 'config')):\n",
    "        base_path = parent_dir\n",
    "    else:\n",
    "        print(\"❌ ERROR: Cannot find config directory\")\n",
    "        print(f\"Current directory: {current_dir}\")\n",
    "        print(f\"Available files/dirs: {os.listdir(current_dir)}\")\n",
    "        base_path = current_dir\n",
    "\n",
    "print(f\"Using base path: {base_path}\")\n",
    "\n",
    "# Add to Python path\n",
    "if base_path not in sys.path:\n",
    "    sys.path.insert(0, base_path)\n",
    "\n",
    "# Verify required directories exist\n",
    "required_dirs = ['config', 'utils']\n",
    "for dir_name in required_dirs:\n",
    "    dir_path = os.path.join(base_path, dir_name)\n",
    "    exists = os.path.exists(dir_path)\n",
    "    print(f\"{dir_name} directory: {'✓' if exists else '❌'} {dir_path}\")\n",
    "\n",
    "# --- END CONFIGURATION ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "\n",
    "# --- CONFIGURATION FOR DEVCONTAINER ---\n",
    "# When running in devcontainer, use the mounted workspace path\n",
    "# The devcontainer.json mounts the workspace to /workspace\n",
    "if os.path.exists('/workspace'):\n",
    "    # Running in devcontainer\n",
    "    actual_module_path_inside_container = \"/workspace\"\n",
    "    print(\"Running in devcontainer environment\")\n",
    "else:\n",
    "    # Fallback for local development\n",
    "    actual_module_path_inside_container = os.getcwd()\n",
    "    print(\"Running in local environment\")\n",
    "\n",
    "print(f\"Using module path: {actual_module_path_inside_container}\")\n",
    "\n",
    "if not os.path.isdir(actual_module_path_inside_container):\n",
    "    print(f\"ERROR: The path '{actual_module_path_inside_container}' does NOT exist or is not a directory.\")\n",
    "    print(f\"Current CWD: {os.getcwd()}\")\n",
    "    print(f\"Available directories: {os.listdir('.')}\")\n",
    "else:\n",
    "    if actual_module_path_inside_container not in sys.path:\n",
    "        sys.path.insert(0, actual_module_path_inside_container)\n",
    "    print(f\"Successfully added to sys.path: {actual_module_path_inside_container}\")\n",
    "    \n",
    "    # Verify the required directories exist\n",
    "    config_path = os.path.join(actual_module_path_inside_container, 'config')\n",
    "    utils_path = os.path.join(actual_module_path_inside_container, 'utils')\n",
    "    print(f\"Config directory exists: {os.path.exists(config_path)}\")\n",
    "    print(f\"Utils directory exists: {os.path.exists(utils_path)}\")\n",
    "\n",
    "# --- END CONFIGURATION ---\n",
    "\n",
    "# Import framework components\n",
    "from config.experiment_configs import EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import re\n",
    "import importlib\n",
    "\n",
    "# Add the current directory to path for imports\n",
    "module_path = os.getcwd() # Gets the current working directory of the notebook\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Import framework components\n",
    "from config.experiment_configs import EXPERIMENTS\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Available Experiments\n",
    "\n",
    "Here you can view and select experiments to run. Each experiment represents a combination of model architecture and augmentation strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Set up the directories and options for benchmarking. \n",
    "\n",
    "Ensure to update these in the system_config.py file in the config folder.\n",
    "\n",
    "The default directories are as follows:\n",
    "\n",
    "DATA_DIR = \"D:\\Echo\\Audio_data\"  # Directory containing audio data\n",
    "\n",
    "CACHE_DIR = \"D:\\Echo\\Training_cache\"  # Directory for caching pipeline results\n",
    "\n",
    "OUTPUT_DIR = \"D:\\Echo\\results\"  # Directory to save experiment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import directories from system_config\n",
    "from config.system_config import SC\n",
    "\n",
    "# Get directory paths from system config\n",
    "DATA_DIR = SC['AUDIO_DATA_DIRECTORY']\n",
    "CACHE_DIR = SC['CACHE_DIRECTORY']\n",
    "OUTPUT_DIR = SC['OUTPUT_DIRECTORY']\n",
    "\n",
    "print(f\"Using directories from system_config:\")\n",
    "print(f\"Data Directory: {DATA_DIR}\")\n",
    "print(f\"Cache Directory: {CACHE_DIR}\")\n",
    "print(f\"Output Directory: {OUTPUT_DIR}\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "\n",
    "print(\"Physical GPUs:\", tf.config.list_physical_devices(\"GPU\"))\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU name:\", tf.test.gpu_device_name())\n",
    "\n",
    "\n",
    "# Configure GPU memory if available\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(f\"GPU support enabled: {len(gpus)} GPU(s) found\")\n",
    "else:\n",
    "    print(\"No GPU support found, running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display available experiments\n",
    "experiment_data = []\n",
    "for exp in EXPERIMENTS:\n",
    "    experiment_data.append({\n",
    "        \"name\": exp[\"name\"],\n",
    "        \"model\": exp[\"model\"],\n",
    "        \"audio_augmentation\": exp[\"audio_augmentation\"],\n",
    "        \"image_augmentation\": exp[\"image_augmentation\"],\n",
    "        \"epochs\": exp[\"epochs\"],\n",
    "        \"batch_size\": exp[\"batch_size\"]\n",
    "    })\n",
    "\n",
    "experiments_df = pd.DataFrame(experiment_data)\n",
    "display(experiments_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interactive Experiment Selection\n",
    "\n",
    "Use the widgets below to select experiments and set directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create widgets for directory selection\n",
    "data_dir_widget = widgets.Text(\n",
    "    value=DATA_DIR,\n",
    "    description='Data Directory:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "cache_dir_widget = widgets.Text(\n",
    "    value=CACHE_DIR,\n",
    "    description='Cache Directory:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "output_dir_widget = widgets.Text(\n",
    "    value=OUTPUT_DIR,\n",
    "    description='Output Directory:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "# Group directory widgets\n",
    "dir_widgets_box = widgets.VBox([data_dir_widget, cache_dir_widget, output_dir_widget])\n",
    "\n",
    "# Create widget for experiment selection\n",
    "experiment_options = [(exp[\"name\"], exp[\"name\"]) for exp in EXPERIMENTS]\n",
    "experiment_widget = widgets.SelectMultiple(\n",
    "    options=experiment_options,\n",
    "    description='Select Experiments:',\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='50%', height='200px')\n",
    ")\n",
    "\n",
    "# Buttons for actions\n",
    "run_selected_button = widgets.Button(\n",
    "    description='Run Selected Experiments',\n",
    "    button_style='primary',\n",
    "    tooltip='Run the selected experiments'\n",
    ")\n",
    "\n",
    "run_all_button = widgets.Button(\n",
    "    description='Run All Experiments',\n",
    "    tooltip='Run all experiments'\n",
    ")\n",
    "\n",
    "generate_report_button = widgets.Button(\n",
    "    description='Generate Report Only',\n",
    "    button_style='info',\n",
    "    tooltip='Generate a report from existing results'\n",
    ")\n",
    "\n",
    "# Group buttons\n",
    "buttons_box = widgets.HBox([run_selected_button, run_all_button, generate_report_button])\n",
    "\n",
    "# Output area for logs\n",
    "output_area = widgets.Output(layout={'border': '1px solid black', 'width': '90%', 'height': '300px'}) # Adjusted width and added height\n",
    "\n",
    "# Main container for all control widgets\n",
    "controls_box = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Directory Configuration:</h3>\"), # Optional title\n",
    "    dir_widgets_box,\n",
    "    widgets.HTML(\"<hr><h3>Experiment Selection:</h3>\"), # Optional separator and title\n",
    "    experiment_widget,\n",
    "    widgets.HTML(\"<hr><h3>Actions:</h3>\"), # Optional separator and title\n",
    "    buttons_box\n",
    "])\n",
    "\n",
    "# Display main controls container and then the output area\n",
    "display(controls_box)\n",
    "display(output_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Experiment Runner Functions\n",
    "\n",
    "These functions handle the execution of experiments and report generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.optimised_engine_pipeline import train_model\n",
    "import importlib\n",
    "import config.system_config # Ensure the module is imported\n",
    "\n",
    "def run_selected_experiments(b):\n",
    "    \"\"\"\n",
    "    Runs experiments based on widget selections.\n",
    "    Updates configuration in memory instead of writing to file.\n",
    "    \"\"\"\n",
    "    output_area.clear_output(wait=True)\n",
    "    with output_area:\n",
    "        print(\"Starting experiment run...\")\n",
    "\n",
    "        # Get new directory paths from widgets\n",
    "        new_data_dir = data_dir_widget.value\n",
    "        new_cache_dir = cache_dir_widget.value\n",
    "        new_output_dir = output_dir_widget.value\n",
    "\n",
    "        # --- FIX: Update config directly in memory ---\n",
    "        # This is safer and more reliable than reloading modules.\n",
    "        from config.system_config import SC\n",
    "        SC['AUDIO_DATA_DIRECTORY'] = new_data_dir\n",
    "        SC['CACHE_DIRECTORY'] = new_cache_dir\n",
    "        SC['OUTPUT_DIRECTORY'] = new_output_dir\n",
    "        print(\"System configuration updated in memory.\")\n",
    "        print(f\"  - Data Dir: {SC['AUDIO_DATA_DIRECTORY']}\")\n",
    "        print(f\"  - Cache Dir: {SC['CACHE_DIRECTORY']}\")\n",
    "\n",
    "        # Ensure directories exist\n",
    "        for path in [new_data_dir, new_cache_dir, new_output_dir]:\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path, exist_ok=True)\n",
    "                print(f\"Created directory: {path}\")\n",
    "\n",
    "        selected_experiments = list(experiment_widget.value)\n",
    "        if not selected_experiments:\n",
    "            print(\"No experiment selected. Please select at least one experiment.\")\n",
    "            return\n",
    "\n",
    "        for exp_name in selected_experiments:\n",
    "            exp_config = next((exp for exp in EXPERIMENTS if exp[\"name\"] == exp_name), None)\n",
    "            if exp_config is None:\n",
    "                print(f\"Experiment {exp_name} not found in EXPERIMENTS.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\nRunning experiment: {exp_config['name']}\")\n",
    "            try:\n",
    "                model, history = train_model(\n",
    "                    model_name=exp_config['model'],\n",
    "                    epochs=exp_config.get('epochs'),\n",
    "                    batch_size=exp_config.get('batch_size')\n",
    "                )\n",
    "                print(f\"✅ Training completed for experiment: {exp_config['name']}\")\n",
    "                if model:\n",
    "                    model.summary(print_fn=lambda x: print(x))\n",
    "\n",
    "            except Exception as e:\n",
    "                import traceback\n",
    "                print(f\"❌ An error occurred during training for experiment {exp_config['name']}:\")\n",
    "                traceback.print_exc() # Print the full traceback for better debugging\n",
    "\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "# Bind the corrected function to the button\n",
    "run_selected_button.on_click(run_selected_experiments)\n",
    "\n",
    "print(\"Experiment runner function has been updated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from utils.data_pipeline import create_datasets, build_datasets\n",
    "from config.system_config import SC\n",
    "from config.model_configs import MODELS\n",
    "\n",
    "with output_area:\n",
    "    print(\"🔬 Starting corrected augmentation diagnostics...\")\n",
    "    try:\n",
    "        # 1. Get the initial datasets (paths and labels)\n",
    "        train_ds_init, val_ds_init, test_ds_init, class_names = create_datasets(SC['AUDIO_DATA_DIRECTORY'])\n",
    "        num_classes = len(class_names)\n",
    "        print(\"✅ Initial dataset created.\")\n",
    "\n",
    "        # 2. Get the model's expected input shape\n",
    "        model_config = MODELS['EfficientNetV2B0'] # Using baseline as an example\n",
    "        input_shape = model_config['expected_input_shape']\n",
    "        print(f\"✅ Using model input shape: {input_shape}\")\n",
    "\n",
    "        # 3. Build the full data pipeline.\n",
    "        # This will use the default augmentation strategy defined inside the function.\n",
    "        train_dataset, _, _ = build_datasets(\n",
    "            train_ds_init, val_ds_init, test_ds_init, num_classes, input_shape\n",
    "        )\n",
    "        print(\"✅ Full data pipeline built.\")\n",
    "\n",
    "        # 4. Try to pull one batch and see if it fails\n",
    "        print(\"⏳ Attempting to get one batch from the augmented dataset...\")\n",
    "        for images, labels in train_dataset.take(1):\n",
    "            print(f\"✅ Successfully retrieved one batch!\")\n",
    "            print(f\"   - Image batch shape: {images.shape}\")\n",
    "            print(f\"   - Image batch dtype: {images.dtype}\")\n",
    "            print(f\"   - Labels batch shape: {labels.shape}\")\n",
    "        print(\"\\n🎉 Diagnostic PASSED. The augmentation pipeline seems to work in isolation.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(\"\\n❌ Diagnostic FAILED. The error was reproduced. See traceback below.\")\n",
    "        print(\"   This confirms the issue is within the default image augmentation pipeline.\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.optimised_engine_pipeline import train_model\n",
    "\n",
    "# Update the run_selected_experiments function in your notebook\n",
    "def run_selected_experiments(b):\n",
    "    from IPython.display import clear_output\n",
    "    import importlib\n",
    "    import config.system_config\n",
    "    \n",
    "    output_area.clear_output(wait=True) \n",
    "    with output_area:\n",
    "        print(\"Starting experiment run...\")\n",
    "        \n",
    "        # Get new directory paths from widgets\n",
    "        new_data_dir = data_dir_widget.value\n",
    "        new_cache_dir = cache_dir_widget.value\n",
    "        new_output_dir = output_dir_widget.value\n",
    "        \n",
    "        # Update the paths directly in the SC dictionary\n",
    "        from config.system_config import SC\n",
    "        SC['AUDIO_DATA_DIRECTORY'] = new_data_dir\n",
    "        SC['CACHE_DIRECTORY'] = new_cache_dir\n",
    "        SC['OUTPUT_DIRECTORY'] = new_output_dir\n",
    "        \n",
    "        # Create directories if they don't exist\n",
    "        for directory in [new_data_dir, new_cache_dir, new_output_dir]:\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory, exist_ok=True)\n",
    "                print(f\"Created directory: {directory}\")\n",
    "        \n",
    "        print(f\"Updated directories:\")\n",
    "        print(f\"  Data: {new_data_dir}\")\n",
    "        print(f\"  Cache: {new_cache_dir}\")\n",
    "        print(f\"  Output: {new_output_dir}\")\n",
    "\n",
    "        selected_experiments = list(experiment_widget.value)\n",
    "        if not selected_experiments:\n",
    "            print(\"No experiment selected. Please select at least one experiment.\")\n",
    "            return\n",
    "        \n",
    "        for exp_name in selected_experiments:\n",
    "            exp_config = next((exp for exp in EXPERIMENTS if exp[\"name\"] == exp_name), None)\n",
    "            if exp_config is None:\n",
    "                print(f\"Experiment {exp_name} not found in EXPERIMENTS.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Running experiment: {exp_config['name']}\")\n",
    "            \n",
    "            try:\n",
    "                # Temporarily disable image augmentation to test if that's the issue\n",
    "                model, history = train_model(\n",
    "                    model_name=exp_config['model'],\n",
    "                    epochs=exp_config.get('epochs', 10),\n",
    "                    batch_size=exp_config.get('batch_size', 16)\n",
    "                )\n",
    "                print(f\"Training completed for experiment: {exp_config['name']}\")\n",
    "                if model:\n",
    "                    model.summary(print_fn=lambda x: print(x))\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error running experiment {exp_config['name']}: {str(e)}\")\n",
    "                print(\"This might be due to image augmentation configuration issues.\")\n",
    "                print(\"Trying with reduced batch size...\")\n",
    "                \n",
    "                try:\n",
    "                    # Try again with smaller batch size\n",
    "                    model, history = train_model(\n",
    "                        model_name=exp_config['model'],\n",
    "                        epochs=exp_config.get('epochs', 10),\n",
    "                        batch_size=8  # Smaller batch size\n",
    "                    )\n",
    "                    print(f\"✅ Training completed with reduced batch size for: {exp_config['name']}\")\n",
    "                except Exception as e2:\n",
    "                    print(f\"❌ Still failed with reduced batch size: {str(e2)}\")\n",
    "                    \n",
    "            print(\"-\" * 40)\n",
    "\n",
    "# Re-bind the button\n",
    "run_selected_button.on_click(run_selected_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.optimised_engine_pipeline import train_model\n",
    "\n",
    "# Original function to run selected experiments\n",
    "\n",
    "def run_selected_experiments(b):\n",
    "\n",
    "    from IPython.display import clear_output # Moved import here for clarity\n",
    "    # clear_output(wait=True) # Clear previous output first\n",
    "    output_area.clear_output(wait=True) \n",
    "    with output_area:\n",
    "        print(\"Starting experiment run...\")\n",
    "        # Get new directory paths from widgets\n",
    "        new_data_dir = data_dir_widget.value\n",
    "        new_cache_dir = cache_dir_widget.value\n",
    "        \n",
    "        # Define path to system_config.py (relative to notebook directory)\n",
    "        # Assumes 'config' is a subdirectory of the notebook's directory\n",
    "        config_file_path = os.path.join('config', 'system_config.py')\n",
    "        \n",
    "        try:\n",
    "            print(f\"Attempting to update {config_file_path}...\")\n",
    "            with open(config_file_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            new_lines = []\n",
    "            config_updated = False\n",
    "            for line in lines:\n",
    "                if \"'AUDIO_DATA_DIRECTORY':\" in line:\n",
    "                    # Use r-string for replacement to handle backslashes in path correctly\n",
    "                    new_line = re.sub(r\"('AUDIO_DATA_DIRECTORY':\\s*r\\\")[^\\\"]*(\\\")\", rf'\\1{new_data_dir}\\2', line)\n",
    "                    if new_line != line:\n",
    "                        config_updated = True\n",
    "                    new_lines.append(new_line)\n",
    "                elif \"'CACHE_DIRECTORY':\" in line: \n",
    "                    new_line = re.sub(r\"('CACHE_DIRECTORY':\\s*r\\\")[^\\\"]*(\\\")\", rf'\\1{new_cache_dir}\\2', line)\n",
    "                    if new_line != line:\n",
    "                        config_updated = True\n",
    "                    new_lines.append(new_line)\n",
    "                else:\n",
    "                    new_lines.append(line)\n",
    "            \n",
    "            if config_updated:\n",
    "                with open(config_file_path, 'w') as f:\n",
    "                    f.writelines(new_lines)\n",
    "                print(f\"Successfully updated {config_file_path} with new directory paths.\")\n",
    "            else:\n",
    "                print(f\"{config_file_path} already up-to-date or keys not found.\")\n",
    "            \n",
    "            # Reload the system_config module to apply changes\n",
    "            importlib.reload(config.system_config)\n",
    "            # Re-import SC if it's used directly in this notebook, or ensure train_model gets the fresh one.\n",
    "            # from config.system_config import SC \n",
    "            print(\"System configuration reloaded.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error updating or reloading system_config.py: {e}\")\n",
    "            print(\"Proceeding with potentially outdated configuration.\")\n",
    "            # Decide if you want to return or proceed if config update fails\n",
    "            # return \n",
    "\n",
    "        selected_experiments = list(experiment_widget.value)\n",
    "        if not selected_experiments:\n",
    "            print(\"No experiment selected. Please select at least one experiment.\")\n",
    "            return\n",
    "        \n",
    "        for exp_name in selected_experiments:\n",
    "            exp_config = next((exp for exp in EXPERIMENTS if exp[\"name\"] == exp_name), None)\n",
    "            if exp_config is None:\n",
    "                print(f\"Experiment {exp_name} not found in EXPERIMENTS.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Running experiment: {exp_config['name']}\")\n",
    "            # Pass configuration values to the train_model function.\n",
    "            # train_model will use the reloaded system_config.SC for DATA_DIR and CACHE_DIR\n",
    "            model, history = train_model(\n",
    "                model_name=exp_config['model'],\n",
    "                epochs=exp_config.get('epochs'),\n",
    "                batch_size=exp_config.get('batch_size')\n",
    "            )\n",
    "            print(f\"Training completed for experiment: {exp_config['name']}\")\n",
    "            if model:\n",
    "                 model.summary(print_fn=lambda x: print(x)) # Ensure summary prints to output_area\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "run_selected_button.on_click(run_selected_experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. View Previous Results (From here down, notebook is under development)\n",
    "\n",
    "If you've already run experiments, you can view and analyse the results here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under development\n",
    "def load_results(output_dir=OUTPUT_DIR):\n",
    "    # Check if results directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        print(f\"Results directory does not exist: {output_dir}\")\n",
    "        return None\n",
    "    \n",
    "    # Look for comparison report CSV\n",
    "    csv_files = [f for f in os.listdir(output_dir) if f.startswith(\"comparison_results_\") and f.endswith(\".csv\")]\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(\"No comparison results found. Run experiments or generate a report first.\")\n",
    "        return None\n",
    "    \n",
    "    # Load the latest CSV file\n",
    "    latest_csv = max(csv_files)\n",
    "    csv_path = os.path.join(output_dir, latest_csv)\n",
    "    results_df = pd.read_csv(csv_path)\n",
    "    \n",
    "    print(f\"Loaded results from: {csv_path}\")\n",
    "    return results_df\n",
    "\n",
    "# Load and display results if available\n",
    "results_df = load_results()\n",
    "if results_df is not None:\n",
    "    display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualise Results\n",
    "\n",
    "Create various visualisations to compare experiment results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under Development\n",
    "# Taken from previously developed notebooks in Machine Learing course\n",
    "\n",
    "def visualize_results(results_df):\n",
    "    if results_df is None or len(results_df) == 0:\n",
    "        print(\"No results available to visualize.\")\n",
    "        return\n",
    "    \n",
    "    # Set the figure size for better visibility\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Create accuracy comparison bar chart\n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.barplot(x='Experiment', y='Test Accuracy', data=results_df)\n",
    "    plt.title('Test Accuracy by Experiment')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Create F1 score comparison bar chart\n",
    "    plt.subplot(2, 2, 2)\n",
    "    sns.barplot(x='Experiment', y='F1 Score', data=results_df)\n",
    "    plt.title('F1 Score by Experiment')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Training time comparison\n",
    "    plt.subplot(2, 2, 3)\n",
    "    sns.barplot(x='Experiment', y='Training Time (min)', data=results_df)\n",
    "    plt.title('Training Time by Experiment (minutes)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Model comparison\n",
    "    plt.subplot(2, 2, 4)\n",
    "    model_comparison = results_df.groupby('Model')['Test Accuracy'].mean().reset_index()\n",
    "    sns.barplot(x='Model', y='Test Accuracy', data=model_comparison)\n",
    "    plt.title('Average Accuracy by Model')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.tight_layout(pad=3.0)\n",
    "    plt.show()\n",
    "    \n",
    "    # Create a separate visualization for augmentation impact\n",
    "    plt.figure(figsize=(12, 6))\n",
    "       \n",
    "    aug_df = pd.DataFrame(aug_data)\n",
    "    sns.barplot(x='Augmentation', y='Accuracy', hue='Augmentation Type', data=aug_df)\n",
    "    plt.title('Accuracy by Augmentation Type')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize results if available\n",
    "if results_df is not None:\n",
    "    visualize_results(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Experiment Analysis and Conclusions\n",
    "(if required)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import librosa\n",
    "import sklearn\n",
    "import soundfile as sf\n",
    "\n",
    "print(\"✅ TensorFlow:\", tf.__version__)\n",
    "print(\"✅ TensorFlow Hub:\", hub.__version__)\n",
    "print(\"✅ NumPy:\", np.__version__)\n",
    "print(\"✅ Pandas:\", pd.__version__)\n",
    "print(\"✅ Matplotlib:\", matplotlib.__version__)\n",
    "print(\"✅ Librosa:\", librosa.__version__)\n",
    "print(\"✅ Scikit-learn:\", sklearn.__version__)\n",
    "print(\"✅ Soundfile:\", sf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tianc\\anaconda3\\envs\\project_echo_env\\lib\\site-packages\\tensorflow_hub\\__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dir: C:\\Users\\tianc\\OneDrive\\桌面\\Project-Echo\\Project-Echo\\uploads_for_training\n",
      "Starting training for model: MobileNetV3-Small\n",
      "Building datasets for MobileNetV3-Small...\n",
      "Train dataset size (batches): 1\n",
      "Validation dataset size (batches): 0\n",
      "Test dataset size (batches): 1\n",
      "Datasets built successfully!\n",
      "Model configuration: {'hub_url': 'https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/classification/5', 'trainable': True, 'dense_layers': [8, 4], 'dropout': 0.5, 'learning_rate': 0.0001, 'expected_input_shape': (224, 224, 3)}\n",
      "Building model: MobileNetV3-Small with expected input shape: (224, 224, 3)\n",
      "WARNING:tensorflow:From c:\\Users\\tianc\\anaconda3\\envs\\project_echo_env\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\tianc\\anaconda3\\envs\\project_echo_env\\lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tianc\\anaconda3\\envs\\project_echo_env\\lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tianc\\anaconda3\\envs\\project_echo_env\\lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tianc\\anaconda3\\envs\\project_echo_env\\lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for model: MobileNetV3-Small\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "{{function_node __wrapped__CreateSummaryFileWriter_device_/job:localhost/replica:0/task:0/device:CPU:0}} tensorboard_logs is not a directory [Op:CreateSummaryFileWriter] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training for model:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exp_cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# === 训练 ===\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m trained_model, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp_cfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSC\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMAX_EPOCHS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSC\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBATCH_SIZE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# === 快速报告 ===\u001b[39;00m\n\u001b[0;32m     20\u001b[0m final_acc \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;28;01mNone\u001b[39;00m])[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(history, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tianc\\OneDrive\\桌面\\Project-Echo\\src\\Prototypes\\engine\\Benchmarking_and_Experimentation\\utils\\optimised_engine_pipeline.py:211\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model_name, epochs, batch_size, l2_regularization, l2_coefficient)\u001b[0m\n\u001b[0;32m    208\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training for model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 211\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSC\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMAX_EPOCHS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# End training timer and print duration\u001b[39;00m\n\u001b[0;32m    219\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\tianc\\anaconda3\\envs\\project_echo_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\tianc\\anaconda3\\envs\\project_echo_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:5883\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   5881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   5882\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 5883\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: {{function_node __wrapped__CreateSummaryFileWriter_device_/job:localhost/replica:0/task:0/device:CPU:0}} tensorboard_logs is not a directory [Op:CreateSummaryFileWriter] name: "
     ]
    }
   ],
   "source": [
    "from config.experiment_configs import EXPERIMENTS\n",
    "from config.system_config import SC\n",
    "from utils.optimised_engine_pipeline import train_model\n",
    "import tensorflow as tf\n",
    "\n",
    "# 选择 baseline 实验\n",
    "exp_cfg = next(e for e in EXPERIMENTS if e[\"name\"] == \"mobilenet_v3_small_baseline\")\n",
    "\n",
    "print(\"Data dir:\", SC[\"AUDIO_DATA_DIRECTORY\"])\n",
    "print(\"Starting training for model:\", exp_cfg[\"model\"])\n",
    "\n",
    "# === 训练 ===\n",
    "trained_model, history = train_model(\n",
    "    model_name=exp_cfg[\"model\"],\n",
    "    epochs=SC[\"MAX_EPOCHS\"],\n",
    "    batch_size=SC[\"BATCH_SIZE\"]\n",
    ")\n",
    "\n",
    "# === 快速报告 ===\n",
    "final_acc = history.history.get(\"accuracy\", [None])[-1] if hasattr(history, \"history\") else None\n",
    "print(\"Training finished.\")\n",
    "print(\"Final acc:\", final_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "{{function_node __wrapped__CreateSummaryFileWriter_device_/job:localhost/replica:0/task:0/device:CPU:0}} C:\\Users\\tianc\\OneDrive\\桌面\\Project-Echo\\src\\Prototypes\\engine\\Benchmarking_and_Experimentation\\tensorboard_logs is not a directory [Op:CreateSummaryFileWriter] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[0;32m      4\u001b[0m log_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtianc\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m桌面\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProject-Echo\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPrototypes\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mBenchmarking_and_Experimentation\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtensorboard_logs\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtest_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m writer \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_file_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m writer\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[0;32m      8\u001b[0m     tf\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39mscalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mping\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\tianc\\anaconda3\\envs\\project_echo_env\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:583\u001b[0m, in \u001b[0;36mcreate_file_writer_v2\u001b[1;34m(logdir, max_queue, flush_millis, filename_suffix, name, experimental_trackable, experimental_mesh)\u001b[0m\n\u001b[0;32m    579\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _TrackableResourceSummaryWriter(\n\u001b[0;32m    580\u001b[0m       create_fn\u001b[38;5;241m=\u001b[39mcreate_fn, init_op_fn\u001b[38;5;241m=\u001b[39minit_op_fn, mesh\u001b[38;5;241m=\u001b[39mexperimental_mesh\n\u001b[0;32m    581\u001b[0m   )\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 583\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ResourceSummaryWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcreate_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_op_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_op_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperimental_mesh\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tianc\\anaconda3\\envs\\project_echo_env\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:320\u001b[0m, in \u001b[0;36m_ResourceSummaryWriter.__init__\u001b[1;34m(self, create_fn, init_op_fn, mesh)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resource \u001b[38;5;241m=\u001b[39m create_fn()\n\u001b[1;32m--> 320\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_op \u001b[38;5;241m=\u001b[39m \u001b[43minit_op_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n",
      "File \u001b[1;32mc:\\Users\\tianc\\anaconda3\\envs\\project_echo_env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_summary_ops.py:147\u001b[0m, in \u001b[0;36mcreate_summary_file_writer\u001b[1;34m(writer, logdir, max_queue, flush_millis, filename_suffix, name)\u001b[0m\n\u001b[0;32m    145\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 147\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m    149\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tianc\\anaconda3\\envs\\project_echo_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:5883\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   5881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   5882\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 5883\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: {{function_node __wrapped__CreateSummaryFileWriter_device_/job:localhost/replica:0/task:0/device:CPU:0}} C:\\Users\\tianc\\OneDrive\\桌面\\Project-Echo\\src\\Prototypes\\engine\\Benchmarking_and_Experimentation\\tensorboard_logs is not a directory [Op:CreateSummaryFileWriter] name: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "log_dir = r\"C:\\Users\\tianc\\OneDrive\\桌面\\Project-Echo\\src\\Prototypes\\engine\\Benchmarking_and_Experimentation\\tensorboard_logs\\test_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "with writer.as_default():\n",
    "    tf.summary.scalar(\"ping\", 1.0, step=0)\n",
    "\n",
    "print(\"日志写入成功:\", log_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_echo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
