{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZGQUKFAzqnK"
      },
      "source": [
        "Overview\n",
        "\n",
        "Author: stephankokkas\n",
        "\n",
        "Modified by: rohit\n",
        "\n",
        "This notebook defines a pipeline that tasks an input directory of audio files and converts them to images using mel-spectrogram transofrmation and preprocessing techniques."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLsod5K1zqnO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "execution": {
          "iopub.execute_input": "2023-04-22T07:06:03.957977Z",
          "iopub.status.busy": "2023-04-22T07:06:03.957558Z",
          "iopub.status.idle": "2023-04-22T07:06:04.066947Z",
          "shell.execute_reply": "2023-04-22T07:06:04.064419Z",
          "shell.execute_reply.started": "2023-04-22T07:06:03.957943Z"
        },
        "id": "ZLwfC8v_zqnO",
        "outputId": "8b9938c3-638c-47d6-c03c-93735a9cd9d3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:90% !important; }</style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python Version     :  3.9.16\n",
            "TensorFlow Version :  2.12.0\n"
          ]
        }
      ],
      "source": [
        "# disable warnings to tidy up output\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# some basic libraries \n",
        "from platform import python_version\n",
        "#import pandas as pd\n",
        "#import seaborn as sns\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import shutil\n",
        "import torch\n",
        "from IPython.display import Audio\n",
        "import pandas as pd\n",
        "import os\n",
        "import argparse\n",
        "import logmmse\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "#import noisereduce as nr\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# tensorflow support\n",
        "import tensorflow as tf\n",
        "#import tensorflow_transform as tft\n",
        "import tensorflow_io as tfio\n",
        "#from tensorflow.contrib.framework.python.ops import audio_ops\n",
        "\n",
        "# scipy\n",
        "import scipy\n",
        "from pydub import AudioSegment, effects\n",
        "\n",
        "# turn off tensorflow warnings\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "# turn off absl warnings\n",
        "import absl.logging\n",
        "absl.logging.set_verbosity(absl.logging.ERROR)\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
        "\n",
        "# print system information\n",
        "print('Python Version     : ', python_version())\n",
        "print('TensorFlow Version : ', tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-22T07:06:04.069120Z",
          "iopub.status.idle": "2023-04-22T07:06:04.070185Z",
          "shell.execute_reply": "2023-04-22T07:06:04.069886Z",
          "shell.execute_reply.started": "2023-04-22T07:06:04.069848Z"
        },
        "id": "XsxfwGzpzqnR"
      },
      "outputs": [],
      "source": [
        "# below code adapted from:\n",
        "# https://keras.io/getting_started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\n",
        "\n",
        "# The below is necessary for starting Numpy generated random numbers\n",
        "# in a well-defined initial state.\n",
        "np.random.seed(123)\n",
        "\n",
        "# The below is necessary for starting core Python generated random numbers\n",
        "# in a well-defined state.\n",
        "random.seed(123)\n",
        "\n",
        "# The below set_seed() will make random number generation\n",
        "# in the TensorFlow backend have a well-defined initial state.\n",
        "# For further details, see:\n",
        "# https://www.tensorflow.org/api_docs/python/tf/random/set_seed\n",
        "tf.random.set_seed(1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-22T07:06:04.072103Z",
          "iopub.status.idle": "2023-04-22T07:06:04.073087Z",
          "shell.execute_reply": "2023-04-22T07:06:04.072804Z",
          "shell.execute_reply.started": "2023-04-22T07:06:04.072770Z"
        },
        "id": "bFISGmmXzqnS"
      },
      "outputs": [],
      "source": [
        "def enforce_memory_limit(mem_mb):\n",
        "  # enforce memory limit on GPU\n",
        "\n",
        "  gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "  if gpus:\n",
        "    try:\n",
        "      tf.config.experimental.set_virtual_device_configuration(\n",
        "          gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=mem_mb)])\n",
        "      print(f\"vram limit set to {mem_mb}MB\")\n",
        "    except RuntimeError as e:\n",
        "      print(e)\n",
        "      \n",
        "# enforce max 5GB memory on GPU for this notebook\n",
        "enforce_memory_limit(5120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TApejh-yzqnS"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bw0i_nqzqnT"
      },
      "source": [
        "# 1. Preprocessing Pipeline\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7JUN_ptzqnW"
      },
      "source": [
        "## **Removing silence & static noise from data** \n",
        "\n",
        "**You have to change the paths of your diresctories here**\n",
        "\n",
        "\n",
        "First, we get audio files of all format from `/content/drive/MyDrive/birdclef2022`, then we use libraries to remove silence and noise from each audio file. then saves it to `/content/OUTPUT_cleaned` \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-22T07:06:04.075276Z",
          "iopub.status.idle": "2023-04-22T07:06:04.075875Z",
          "shell.execute_reply": "2023-04-22T07:06:04.075588Z",
          "shell.execute_reply.started": "2023-04-22T07:06:04.075557Z"
        },
        "id": "wrzqaa9czqnX"
      },
      "outputs": [],
      "source": [
        "def envelope(y, rate, threshold):\n",
        "    mask = []\n",
        "    y = pd.Series(y).apply(np.abs)\n",
        "    y_mean = y.rolling(window=int(rate/20),\n",
        "                       min_periods=1,\n",
        "                       center=True).max()\n",
        "    for mean in y_mean:\n",
        "        if mean > threshold:\n",
        "            mask.append(True)\n",
        "        else:\n",
        "            mask.append(False)\n",
        "    return mask\n",
        "\n",
        "\n",
        "\n",
        "def process_audio_file(src_path, dst_path, threshold, sr=16000):\n",
        "    y, rate = librosa.load(src_path, sr=sr)\n",
        "    y_reduced_noise = logmmse.logmmse(y, rate, output_file=None)\n",
        "    mask = envelope(y_reduced_noise, rate, threshold)\n",
        "    y = y_reduced_noise[mask]\n",
        "    sf.write(dst_path, y, rate, subtype='VORBIS')\n",
        "\n",
        "    return y, rate\n",
        "\n",
        "\n",
        "def plot_audio_comparison(original_audio, processed_audio, rate):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(original_audio)\n",
        "    plt.title('Original Audio')\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(processed_audio)\n",
        "    plt.title('Processed Audio')\n",
        "    plt.tight_layout()\n",
        "    #plt.show()\n",
        "\n",
        "def remove_silence(src_root, dst_root, threshold):\n",
        "    if not os.path.exists(dst_root):\n",
        "        os.makedirs(dst_root)\n",
        "\n",
        "    ogg_paths = glob('{}/**/*.ogg'.format(src_root), recursive=True)\n",
        "\n",
        "    # Add a counter\n",
        "    counter = 0\n",
        "\n",
        "    for src_path in tqdm(ogg_paths):\n",
        "        relative_path = os.path.relpath(src_path, src_root)\n",
        "        dst_path = os.path.join(dst_root, relative_path)\n",
        "\n",
        "        dst_dir = os.path.dirname(dst_path)\n",
        "        if not os.path.exists(dst_dir):\n",
        "            os.makedirs(dst_dir)\n",
        "\n",
        "        original_audio, rate = librosa.load(src_path, sr=16000)\n",
        "        processed_audio, _ = process_audio_file(src_path, dst_path, threshold)\n",
        "\n",
        "        # Add a conditional statement to only plot the first audio dataset comparison\n",
        "        if counter == 0:\n",
        "            plot_audio_comparison(original_audio, processed_audio, rate)\n",
        "\n",
        "        # Increment the counter\n",
        "        counter += 1\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  src_root = 'birdclef2022'\n",
        "  dst_root = 'OUTPUT_cleaned' #Directory to save processed bird audio files\n",
        "  threshold = 0.01 #Threshold for detecting silence in the audio\n",
        "\n",
        "  remove_silence(src_root, dst_root, threshold)    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Then on next step, we delete the duplicates, and trip the clips, then split it to test, train and validation data.**\n",
        "\n",
        "  This pipeline will go through a root directory and find all the audio files that exist and are of accepted format. Then, depending on the params set, it with normalise, trim and split the data. Please ensure you specify the self.DATASET_PATH with the directory of the data, and the self._SET_OUTPUT_DIR with the location you want the output files to end up in.\n",
        "\n",
        "**Make sure to change your paths according to your setup**\n",
        "\n",
        "here, we gets the Cleaned data from `'/content/drive/MyDrive/OUTPUT_cleaned'` and save everything to `'/content/'`\n"
      ],
      "metadata": {
        "id": "DMG0PDQWq5_Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-22T07:06:04.095387Z",
          "iopub.status.busy": "2023-04-22T07:06:04.094865Z",
          "iopub.status.idle": "2023-04-22T07:06:04.145147Z",
          "shell.execute_reply": "2023-04-22T07:06:04.143465Z",
          "shell.execute_reply.started": "2023-04-22T07:06:04.095345Z"
        },
        "id": "uTjDaBUrzqna"
      },
      "outputs": [],
      "source": [
        "class raw_file_pre_processing():\n",
        "    def __init__(self) -> None:\n",
        "        self.CLIP_LENGTH   = 5000   # only look at 5000 milliseconds of clip at the start of loaded audio file\n",
        "        self.BITRATE = \"160k\"        # all the samples are converted to bit rate of 32000 (Samples/Second)\n",
        "        self.labels = []\n",
        "        self.raw_dirs = {}\n",
        "        self.dataset = pd.DataFrame(columns=['Label', 'FileName', 'FileType', 'Directory'])\n",
        "        self.TARGET_FORMAT = 'flac'\n",
        "        self.ACCEPTED_FORMAT = ['.mp3', '.flac', '.aiff', '.mp4', '.m4a', '.wav', '.ogg']\n",
        "        self.CLEAN_DIR_ = True\n",
        "        self.TRAIN_SPLIT      = 0.80\n",
        "        self.TEST_SPLIT       = 0.01\n",
        "        self.VALIDATION_SPLIT = 0.19\n",
        "        self.split_file_names = {}\n",
        "\n",
        "        # WIN\n",
        "        #self.DATASET_PATH = 'C:\\\\Users\\\\steph\\\\Documents\\\\birdclef2022\\\\'\n",
        "        # MAC\n",
        "        self.DATASET_PATH  = '/content/drive/MyDrive/OUTPUT_cleaned'\n",
        "        \n",
        "        # make sure this is in the same format for either window or mac\n",
        "        #WIN\n",
        "        #self._SET_OUTPUT_DIR = 'C:\\\\Users\\\\steph\\\\Downloads\\\\'\n",
        "        #MAC\n",
        "        self._SET_OUTPUT_DIR = '/content/'\n",
        "        \n",
        "        \n",
        "        if '/' in self.DATASET_PATH:\n",
        "            self.DATASET_PATH = os.path.join('/', *self.DATASET_PATH.split('/'))\n",
        "            self.OUTPUT_DIR = os.path.join('/', *self._SET_OUTPUT_DIR.split('/'), 'OUTPUT_raw_flac')\n",
        "            if not os.path.exists(self.OUTPUT_DIR):\n",
        "                os.mkdir(self.OUTPUT_DIR)\n",
        "        elif '\\\\' in str(self.DATASET_PATH):\n",
        "            self.DATASET_PATH = str(os.path.join(*self.DATASET_PATH.split('\\\\'))).replace(':', ':\\\\')\n",
        "            self.OUTPUT_DIR = str(os.path.join(*self._SET_OUTPUT_DIR.split('\\\\'), 'OUTPUT_raw_flac')).replace(':', ':\\\\')\n",
        "            if not os.path.exists(self.OUTPUT_DIR):\n",
        "                os.makedirs(self.OUTPUT_DIR)   \n",
        "                \n",
        "\n",
        "        self.TRAIN_DIR = os.path.join(str(self.OUTPUT_DIR).replace('OUTPUT_raw_flac', ''), 'TRAIN_raw_flac')\n",
        "        self.TEST_DIR = os.path.join(str(self.OUTPUT_DIR).replace('OUTPUT_raw_flac', ''), 'TEST_raw_flac')\n",
        "        self.VALIDATION_DIR = os.path.join(str(self.OUTPUT_DIR).replace('OUTPUT_raw_flac', ''), 'VALIDATION_raw_flac')\n",
        "\n",
        "        def clean_dir(self):\n",
        "            if os.path.exists(self.OUTPUT_DIR):\n",
        "                shutil.rmtree(self.OUTPUT_DIR)\n",
        "            if os.path.exists(self.TRAIN_DIR):\n",
        "                shutil.rmtree(self.TRAIN_DIR)\n",
        "            if os.path.exists(self.TEST_DIR):\n",
        "                shutil.rmtree(self.TEST_DIR)\n",
        "            if os.path.exists(self.VALIDATION_DIR):\n",
        "                shutil.rmtree(self.VALIDATION_DIR)\n",
        "        if self.CLEAN_DIR_: \n",
        "            clean_dir(self)\n",
        "\n",
        "    def handle_duplicate_files(self) -> bool:\n",
        "        try:\n",
        "            for root, dir, files in os.walk(self.DATASET_PATH):\n",
        "                for _class_ in dir:\n",
        "                    _file_ = [f.split('.')[0] for f in listdir(os.path.join(root, _class_)) if isfile(join(os.path.join(root, _class_), f))]\n",
        "                    _set_ = set([x for x in _file_ if _file_.count(x) > 1])\n",
        "\n",
        "                    if len(_set_) > 0:\n",
        "                        print(f'Class {_class_} has the following duplicates: {_set_}. Will remove dupliactes...')\n",
        "                        for _elem_ in _set_:\n",
        "                            for dir_file in [f for f in listdir(os.path.join(root, _class_)) if isfile(join(os.path.join(root, _class_), f))]:\n",
        "                                if _elem_ in dir_file:\n",
        "                                    os.remove(os.path.join(root, _class_, dir_file))      \n",
        "                break\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            print('Terminating...')\n",
        "            return False\n",
        "                    \n",
        "    def get_raw_file_paths(self):\n",
        "        if self.handle_duplicate_files():\n",
        "            print(f'Looking for files... acceptable formats include: {self.ACCEPTED_FORMAT}')\n",
        "            for root, dir, files in os.walk(self.DATASET_PATH):\n",
        "                if dir == []:\n",
        "                    tmp_lable = os.path.split(root)[-1]\n",
        "                    tmp_file_dir = []\n",
        "                    tmp_filename_ = []\n",
        "                    for file in files:\n",
        "                        for ext in self.ACCEPTED_FORMAT:\n",
        "                            if ext in str(file):\n",
        "                                tmp_file_dir.append(os.path.join(root, file))\n",
        "                                tmp_filename_.append(str(str(os.path.split(os.path.join(root, file))[-1]).split('.')[0]).replace('_', ''))\n",
        "\n",
        "                            \n",
        "                    self.raw_dirs.update({tmp_lable:tmp_file_dir})\n",
        "                    self.split_file_names.update({tmp_lable:tmp_filename_})\n",
        "\n",
        "            for key in self.raw_dirs:\n",
        "                print(f'FOUND: {key} -> {len(self.raw_dirs[key])}')\n",
        "\n",
        "    def audio_preprocessing(self, TRIM_AUDIO:bool = False, \n",
        "                                  NORM_AUDIO:bool = False):\n",
        "        print('\\nConvering audio files....\\n')\n",
        "        if not os.path.exists(self.OUTPUT_DIR):\n",
        "            os.makedirs(self.OUTPUT_DIR)\n",
        "\n",
        "        \n",
        "        for key, item in self.split_file_names.items():\n",
        "            train = item[int(len(item) * .00) : int(len(item) * self.TRAIN_SPLIT)]\n",
        "            vali = item[int(len(item) * self.TRAIN_SPLIT) : int(len(item) * (self.TRAIN_SPLIT + self.VALIDATION_SPLIT))]\n",
        "            test = item[int(len(item) * (self.TRAIN_SPLIT + self.VALIDATION_SPLIT)) : int(len(item) * 1.00)]\n",
        "            self.split_file_names.update({key: [train, vali, test]})\n",
        "\n",
        "        for key, item in self.raw_dirs.items():\n",
        "            print(f'Converting {key} data ->> ...')\n",
        "            tmp_dir_key = os.path.join(self.OUTPUT_DIR, key)\n",
        "            if not os.path.exists(tmp_dir_key):\n",
        "                os.makedirs(tmp_dir_key)\n",
        "\n",
        "            for dir in item:\n",
        "                try:\n",
        "                    # read file\n",
        "                    tmp_file_name = str(os.path.split(dir)[-1].split('.')[0]).replace('_', '')\n",
        "                    raw_sound = AudioSegment.from_file(dir, format=dir.split('.')[-1])\n",
        "\n",
        "                    if NORM_AUDIO:\n",
        "                        # normalise file\n",
        "                        raw_sound = effects.normalize(raw_sound)\n",
        "\n",
        "                    # trim file\n",
        "                    if TRIM_AUDIO:\n",
        "                        arr_split_file = [raw_sound[idx:idx + self.CLIP_LENGTH] for idx in range(0, len(raw_sound), self.CLIP_LENGTH)]             \n",
        "                        for count_sample, sample in enumerate(arr_split_file):\n",
        "                            # padding audio < 5s\n",
        "                            if len(sample) < self.CLIP_LENGTH:\n",
        "                                silence = AudioSegment.silent(duration=((self.CLIP_LENGTH-len(sample))))\n",
        "                                sample = sample + silence  # Adding silence after the audio\n",
        "\n",
        "                            # export raw file\n",
        "                            tmp_raw_new_dir = os.path.join(tmp_dir_key, tmp_file_name + '_raw_trim_sample_' + str(count_sample) + '.' + self.TARGET_FORMAT)\n",
        "                            sample.export(tmp_raw_new_dir, format=self.TARGET_FORMAT, bitrate=self.BITRATE, parameters = [])\n",
        "\n",
        "                            new_row = pd.Series({\"Label\": key,\n",
        "                                        \"FileName\": tmp_file_name + '_raw_trim_sample_' + str(count_sample) + '.' + self.TARGET_FORMAT,\n",
        "                                        \"FileType\": self.TARGET_FORMAT,\n",
        "                                        \"Directory\": tmp_raw_new_dir})\n",
        "                            self.dataset = pd.concat([self.dataset, new_row.to_frame().T], ignore_index=True)\n",
        "                    else:\n",
        "                        tmp_raw_new_dir = os.path.join(tmp_dir_key, tmp_file_name + '_raw_' + '.' + self.TARGET_FORMAT)\n",
        "                        raw_sound.export(tmp_raw_new_dir, format=self.TARGET_FORMAT, bitrate=self.BITRATE, parameters = [])\n",
        "\n",
        "                        new_row = pd.Series({\"Label\": key,\n",
        "                                    \"FileName\": tmp_file_name + '_raw_' + '.' + self.TARGET_FORMAT,\n",
        "                                    \"FileType\": self.TARGET_FORMAT,\n",
        "                                    \"Directory\": tmp_raw_new_dir})\n",
        "                        self.dataset = pd.concat([self.dataset, new_row.to_frame().T], ignore_index=True)\n",
        "                except Exception as e:\n",
        "                    print(e)\n",
        "\n",
        "    def train_test_split_fun(self):\n",
        "        print(f'\\nSplitting data into sub-directories Train, Test and Validation...')\n",
        "\n",
        "        if not os.path.exists(self.TRAIN_DIR):\n",
        "            os.mkdir(self.TRAIN_DIR)\n",
        "        if not os.path.exists(self.TEST_DIR):\n",
        "            os.mkdir(self.TEST_DIR)\n",
        "        if not os.path.exists(self.VALIDATION_DIR):\n",
        "            os.mkdir(self.VALIDATION_DIR)\n",
        "\n",
        "\n",
        "        dict_keys = self.dataset['Label'].value_counts().to_dict()\n",
        "        for key, item in dict_keys.items():\n",
        "            if not os.path.exists(os.path.join(self.TRAIN_DIR, key)):\n",
        "                os.mkdir(os.path.join(self.TRAIN_DIR, key))\n",
        "            if not os.path.exists(os.path.join(self.TEST_DIR, key)):\n",
        "                os.mkdir(os.path.join(self.TEST_DIR, key))\n",
        "            if not os.path.exists(os.path.join(self.VALIDATION_DIR, key)):\n",
        "                os.mkdir(os.path.join(self.VALIDATION_DIR, key))\n",
        "\n",
        "\n",
        "        # self.dataset.to_csv(os.path.join(self.OUTPUT_DIR, 'raw_files.csv'))\n",
        "\n",
        "        for index, row in self.dataset.iterrows():\n",
        "            i = str(row.Directory)\n",
        "            for key, item in self.split_file_names.items():\n",
        "                if str(row.FileName).split('_')[0] in item[0]:\n",
        "                    os.replace(i, i.replace('OUTPUT_raw_flac', 'TRAIN_raw_flac'))\n",
        "                if str(row.FileName).split('_')[0] in item[1]:\n",
        "                    os.replace(i, i.replace('OUTPUT_raw_flac', 'VALIDATION_raw_flac'))\n",
        "                if str(row.FileName).split('_')[0] in item[2]:\n",
        "                    os.replace(i, i.replace('OUTPUT_raw_flac', 'TEST_raw_flac'))\n",
        "\n",
        "        shutil.rmtree(self.OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-22T07:06:04.148525Z",
          "iopub.status.busy": "2023-04-22T07:06:04.147395Z",
          "iopub.status.idle": "2023-04-22T07:06:04.983187Z",
          "shell.execute_reply": "2023-04-22T07:06:04.982195Z",
          "shell.execute_reply.started": "2023-04-22T07:06:04.148462Z"
        },
        "id": "VHUYGN1Lzqnb",
        "outputId": "e8fae135-126c-478d-a90b-d6f11ccb5ed9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking for files... acceptable formats include: ['.mp3', '.flac', '.aiff', '.mp4', '.m4a', '.wav', '.ogg']\n",
            "FOUND: sheowl -> 128\n",
            "FOUND: wiltur -> 76\n",
            "FOUND: brant -> 135\n",
            "FOUND: jabwar -> 78\n",
            "FOUND: spodov -> 107\n",
            "\n",
            "This next process will take approx 20 mins for the current bird dataset depending on the speed of your computer\n",
            "\n",
            "Convering audio files....\n",
            "\n",
            "Converting sheowl data ->> ...\n",
            "Decoding failed. ffmpeg returned error code: 1\n",
            "\n",
            "Output from ffmpeg/avlib:\n",
            "\n",
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "/content/drive/MyDrive/OUTPUT_cleaned/sheowl/XC295898.ogg: End of file\n",
            "\n",
            "Converting wiltur data ->> ...\n",
            "Converting brant data ->> ...\n",
            "Decoding failed. ffmpeg returned error code: 1\n",
            "\n",
            "Output from ffmpeg/avlib:\n",
            "\n",
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "/content/drive/MyDrive/OUTPUT_cleaned/brant/XC439019.ogg: End of file\n",
            "\n",
            "Converting jabwar data ->> ...\n",
            "Converting spodov data ->> ...\n",
            "\n",
            "Splitting data into sub-directories Train, Test and Validation...\n"
          ]
        }
      ],
      "source": [
        "data_preprocessing_pipeline = raw_file_pre_processing()\n",
        "\n",
        "data_preprocessing_pipeline.get_raw_file_paths()\n",
        "\n",
        "\n",
        "print('\\nThis next process will take approx 20 mins for the current bird dataset depending on the speed of your computer')\n",
        "data_preprocessing_pipeline.audio_preprocessing(TRIM_AUDIO=True, NORM_AUDIO=True)\n",
        "data_preprocessing_pipeline.train_test_split_fun()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBaNCBIkzqnc"
      },
      "source": [
        "## Melspectrogram Pipeline\n",
        "\n",
        "This pipeline will get all the new flac files, convert them to tfio tensors, convert to spectrograms, convert again to mel-spectrograms. It will then save the tensors as .pt files which can be read again\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class mel_spectrogram_pipeline():\n",
        "    def __init__(self, output_directory) -> None:\n",
        "        self.target_dir = ''\n",
        "        self.labels = []\n",
        "        self.augmented_dirs = {}\n",
        "        self.OUTPUT_DIR = {}\n",
        "        self.ACCEPTED_FORMAT = '.flac'\n",
        "\n",
        "        # do not change, this will be brought across from the previous pipeline\n",
        "        self._SET_OUTPUT_DIR = output_directory\n",
        "        if '/' in self._SET_OUTPUT_DIR:\n",
        "            self.DATASET_PATH = self._SET_OUTPUT_DIR\n",
        "            self.TENSOR_OUTPUT_DIR = os.path.join(self.DATASET_PATH, 'OUTPUT_tensors')\n",
        "        elif '\\\\' in self._SET_OUTPUT_DIR:\n",
        "            self.DATASET_PATH = self._SET_OUTPUT_DIR\n",
        "            self.TENSOR_OUTPUT_DIR = os.path.join(self.DATASET_PATH, 'OUTPUT_tensors')\n",
        "\n",
        "        self.NFFT = 512\n",
        "        self.WINDOW = 512\n",
        "        self.STRIDE = 512\n",
        "        self.SAMPLE_RATE = int(44100/2)\n",
        "        self.MELS = 128\n",
        "        self.FMIN = 0\n",
        "        self.FMAX = int(self.SAMPLE_RATE)/2\n",
        "        self.TOP_DB = 80\n",
        "\n",
        "    \n",
        "    def clean_dirs(self) -> None:\n",
        "        print('Cleaning tensor directory')\n",
        "        if os.path.exists(self.TENSOR_OUTPUT_DIR):\n",
        "            shutil.rmtree(self.TENSOR_OUTPUT_DIR)\n",
        "\n",
        "    def get_output_dir(self) -> None:\n",
        "        print('Finding all pre-processed files')\n",
        "        for root, dir, files in os.walk(self.DATASET_PATH):\n",
        "            if \"TRAIN_raw_flac\" not in dir:\n",
        "                if \"OUTPUT\" not in dir:\n",
        "                    raise ValueError('Cant find any directories with pre-processed data. Looking for OUTPUT or TRAIN, TEST, and VAIDATION')\n",
        "                else:\n",
        "                    self.OUTPUT_DIR.update({\"OUTPUT\": os.path.join(root, \"OUTPUT\")})\n",
        "            else:\n",
        "                if \"TEST_raw_flac\" in dir and \"VALIDATION_raw_flac\" in dir:\n",
        "                    self.OUTPUT_DIR.update({\"TRAIN\": os.path.join(root, \"TRAIN_raw_flac\")})\n",
        "                    self.OUTPUT_DIR.update({\"TEST\": os.path.join(root, \"TEST_raw_flac\")})\n",
        "                    self.OUTPUT_DIR.update({\"VALIDATION\": os.path.join(root, \"VALIDATION_raw_flac\")})\n",
        "            if not self.OUTPUT_DIR:\n",
        "                raise ValueError('Cant find any directories with pre-processed data. Looking for OUTPUT or TRAIN, TEST, and VAIDATION')\n",
        "\n",
        "            print(f'\\nFound the following directories {self.OUTPUT_DIR}\\n')\n",
        "            break\n",
        "            \n",
        "    def get_preprocessed_files(self) -> None:\n",
        "        self.get_output_dir()\n",
        "\n",
        "        for key, item in self.OUTPUT_DIR.items():\n",
        "            for root, dir, files in os.walk(item):\n",
        "                if dir == []:\n",
        "                    tmp_lable = str(os.path.split(root)[-1]) + \"~\" + key\n",
        "                    tmp_file_dir = []\n",
        "                    for file in files:\n",
        "                        if self.ACCEPTED_FORMAT in str(file):\n",
        "                            tmp_file_dir.append(os.path.join(root, file))\n",
        "                            \n",
        "                    self.augmented_dirs.update({tmp_lable:tmp_file_dir})\n",
        "\n",
        "        for key in self.augmented_dirs:\n",
        "            print(f'FOUND: {key} -> {len(self.augmented_dirs[key])}')\n",
        "\n",
        "    def generate_mel_spectrograms(self, MEL_SPECTRO:bool = False, \n",
        "                                        SHOW_PLOT:bool = False, \n",
        "                                        FREQ_MASK:bool = False, \n",
        "                                        TIME_MASK:bool = False,\n",
        "                                        TORCH_EXPORT:bool = False, \n",
        "                                        TFIO_EXPORT:bool = False) -> None:\n",
        "                                        \n",
        "        print(f'\\nGenerating tensors... \\n')\n",
        "        for key, item in self.augmented_dirs.items():\n",
        "            for dir in item:\n",
        "                tmp_label = key.split('~')[0]\n",
        "                tmp_set = key.split('~')[1]\n",
        "                if not os.path.exists(os.path.join(self.TENSOR_OUTPUT_DIR)):\n",
        "                    os.mkdir(os.path.join(self.TENSOR_OUTPUT_DIR))\n",
        "                if not os.path.exists(os.path.join(self.TENSOR_OUTPUT_DIR, tmp_set)):\n",
        "                    os.mkdir(os.path.join(self.TENSOR_OUTPUT_DIR, tmp_set))\n",
        "                if not os.path.exists(os.path.join(self.TENSOR_OUTPUT_DIR, tmp_set, tmp_label)):\n",
        "                    os.mkdir(os.path.join(self.TENSOR_OUTPUT_DIR, tmp_set, tmp_label))\n",
        "       \n",
        "                file_contents=tf.io.read_file(dir)\n",
        "                try:\n",
        "                    tmp_audio_t = tfio.audio.decode_flac(input=file_contents, dtype=tf.int16)\n",
        "                except:\n",
        "                    tmp_audio_t = tfio.audio.decode_flac(input=file_contents, dtype=tf.int32)\n",
        "                    \n",
        "                tmp_audio_t = tf.cast(tmp_audio_t, tf.float32)\n",
        "                    \n",
        "                tmp_audio_t = tfio.audio.resample(tmp_audio_t, tfio.audio.AudioIOTensor(dir)._rate.numpy(), self.SAMPLE_RATE)\n",
        "\n",
        "                # Convert to spectrogram\n",
        "                spectrogram = tfio.audio.spectrogram(\n",
        "                    tmp_audio_t[:, 0], nfft=self.NFFT, window=self.WINDOW, stride=self.STRIDE)\n",
        "\n",
        "                if SHOW_PLOT:\n",
        "                    plt.figure()\n",
        "                    plt.imshow(tf.math.log(spectrogram).numpy())\n",
        "\n",
        "                if MEL_SPECTRO:\n",
        "                    # # Convert to mel-spectrogram\n",
        "                    mel_spectrogram = tfio.audio.melscale(\n",
        "                        spectrogram, rate=self.SAMPLE_RATE, mels=self.MELS, fmin=self.FMIN, fmax=self.FMAX)\n",
        "\n",
        "                    if SHOW_PLOT:\n",
        "                        plt.figure()\n",
        "                        plt.imshow(tf.math.log(mel_spectrogram).numpy())\n",
        "\n",
        "                    if TORCH_EXPORT:\n",
        "                        torch.save(mel_spectrogram, str(os.path.join(self.TENSOR_OUTPUT_DIR, tmp_set, tmp_label, os.path.split(dir)[-1].split('.')[0])) + '_raw_mel_spectrogram.pt')\n",
        "                    if TFIO_EXPORT:\n",
        "                        tf.io.write_file(str(os.path.join(self.TENSOR_OUTPUT_DIR, tmp_set, tmp_label, os.path.split(dir)[-1].split('.')[0])) + '_raw_mel_spectrogram.pt', tf.io.serialize_tensor(mel_spectrogram))\n",
        "\n",
        "                    if FREQ_MASK and \"TEST\" not in dir and \"VALIDATION\" not in dir:\n",
        "                        freq_mask = tfio.audio.freq_mask(mel_spectrogram, param=10)\n",
        "                        if TORCH_EXPORT:\n",
        "                            torch.save(freq_mask, str(os.path.join(self.TENSOR_OUTPUT_DIR, tmp_set, tmp_label, os.path.split(dir)[-1].split('.')[0])) + '_freq_mask_mel_spectrogram.pt')\n",
        "                        if TFIO_EXPORT:\n",
        "                            tf.io.write_file(str(os.path.join(self.TENSOR_OUTPUT_DIR, tmp_set, tmp_label, os.path.split(dir)[-1].split('.')[0])) + '_freq_mask_mel_spectrogram.pt', tf.io.serialize_tensor(mel_spectrogram))\n",
        "                    \n",
        "                    if TIME_MASK and \"TEST\" not in dir and \"VALIDATION\" not in dir:\n",
        "                        time_mask = tfio.audio.time_mask(mel_spectrogram, param=10)\n",
        "                        if TORCH_EXPORT:\n",
        "                            torch.save(time_mask, str(os.path.join(self.TENSOR_OUTPUT_DIR, tmp_set, tmp_label, os.path.split(dir)[-1].split('.')[0])) + '_time_mask_mel_spectrogram.pt')\n",
        "                        if TFIO_EXPORT:\n",
        "                            tf.io.write_file(str(os.path.join(self.TENSOR_OUTPUT_DIR, tmp_set, tmp_label, os.path.split(dir)[-1].split('.')[0])) + '_time_mask_mel_spectrogram.pt', tf.io.serialize_tensor(mel_spectrogram))\n",
        "\n",
        "        print(\"\\nTensors complete.\\n\")"
      ],
      "metadata": {
        "id": "GY_BdrZDb9nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-22T07:06:05.025404Z",
          "iopub.status.busy": "2023-04-22T07:06:05.024142Z",
          "iopub.status.idle": "2023-04-22T07:06:05.067732Z",
          "shell.execute_reply": "2023-04-22T07:06:05.065473Z",
          "shell.execute_reply.started": "2023-04-22T07:06:05.025366Z"
        },
        "id": "HHtvpoZ2zqnd",
        "outputId": "dd968ba8-32a7-4655-e04b-5f4384782ab4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning tensor directory\n",
            "Finding all pre-processed files\n",
            "\n",
            "Found the following directories {'TRAIN': '/content/TRAIN_raw_flac', 'TEST': '/content/TEST_raw_flac', 'VALIDATION': '/content/VALIDATION_raw_flac'}\n",
            "\n",
            "FOUND: spodov~TRAIN -> 560\n",
            "FOUND: jabwar~TRAIN -> 493\n",
            "FOUND: sheowl~TRAIN -> 376\n",
            "FOUND: brant~TRAIN -> 680\n",
            "FOUND: wiltur~TRAIN -> 734\n",
            "FOUND: spodov~TEST -> 36\n",
            "FOUND: jabwar~TEST -> 12\n",
            "FOUND: sheowl~TEST -> 5\n",
            "FOUND: brant~TEST -> 26\n",
            "FOUND: wiltur~TEST -> 2\n",
            "FOUND: spodov~VALIDATION -> 161\n",
            "FOUND: jabwar~VALIDATION -> 101\n",
            "FOUND: sheowl~VALIDATION -> 62\n",
            "FOUND: brant~VALIDATION -> 143\n",
            "FOUND: wiltur~VALIDATION -> 121\n",
            "\n",
            "This process will take approx 5-10 mins to complete depending on the power of your PC\n",
            "\n",
            "Generating tensors... \n",
            "\n",
            "\n",
            "Tensors complete.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data_spectro_pipeline = mel_spectrogram_pipeline(data_preprocessing_pipeline._SET_OUTPUT_DIR)\n",
        "\n",
        "data_spectro_pipeline.clean_dirs()\n",
        "data_spectro_pipeline.get_preprocessed_files()\n",
        "\n",
        "print('\\nThis process will take approx 5-10 mins to complete depending on the power of your PC')\n",
        "data_spectro_pipeline.generate_mel_spectrograms(MEL_SPECTRO=True, SHOW_PLOT=False, FREQ_MASK=True, TIME_MASK=True, TORCH_EXPORT=False, TFIO_EXPORT=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0az-Xkzzqnd"
      },
      "source": [
        "## Pipeline to load data into memory for model training\n",
        "\n",
        "This pipeline will load all the tensors into a train, test, and validation data structure and prepare it for inputs into a model for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQAvqUcWzqne"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-22T07:06:05.069819Z",
          "iopub.status.idle": "2023-04-22T07:06:05.070831Z",
          "shell.execute_reply": "2023-04-22T07:06:05.070518Z",
          "shell.execute_reply.started": "2023-04-22T07:06:05.070482Z"
        },
        "id": "GmB5FdA_zqne"
      },
      "outputs": [],
      "source": [
        "class train_test_vali_pipeline():\n",
        "    def __init__(self, output_directory) -> None:\n",
        "        self.DATASET_PATH  = output_directory\n",
        "        self.TENSOR_OUTPUT_DIR  = None\n",
        "\n",
        "        if '/' in self.DATASET_PATH:\n",
        "            self.TENSOR_OUTPUT_DIR = os.path.join(self.DATASET_PATH, 'OUTPUT_tensors')\n",
        "        elif '\\\\' in self.DATASET_PATH:\n",
        "            self.TENSOR_OUTPUT_DIR = os.path.join(self.DATASET_PATH, 'OUTPUT_tensors')\n",
        "\n",
        "        self.VALID_FILES = False\n",
        "\n",
        "        self.PATHS = []\n",
        "        self.train_data = self.test_data = self.vali_data = pd.DataFrame(columns=['Label', 'Tensor'])\n",
        "\n",
        "    \n",
        "    def check_valid_dirs(self) -> None:\n",
        "        def contains_test(arr):\n",
        "            if any(\"TEST\" in item for item in arr): return True\n",
        "            return False\n",
        "        def contains_train(arr):\n",
        "            if any(\"TRAIN\" in item for item in arr): return True\n",
        "            return False\n",
        "        def contains_vali(arr):\n",
        "            if any(\"VALIDATION\" in item for item in arr): return True\n",
        "            return False\n",
        "\n",
        "        print('Checking to find train, test and vali directories inside tensors folder...')\n",
        "        for root, dir, files in os.walk(self.TENSOR_OUTPUT_DIR):\n",
        "            for i in dir:\n",
        "                self.PATHS.append(os.path.join(root, i))\n",
        "            if contains_test(dir) and contains_train(dir) and contains_vali(dir):\n",
        "                self.VALID_FILES = True\n",
        "                print('PASS')\n",
        "            else:\n",
        "                raise ValueError('Cannot find folders from previous pipline which include train, test and validation directories')\n",
        "            break\n",
        "\n",
        "    def load_data(self, LOAD_RAW:bool = False, \n",
        "                        LOAD_FREQ:bool = False, \n",
        "                        LOAD_TIME:bool = False, \n",
        "                        TO_CSV:bool = False, \n",
        "                        TORCH_LOAD:bool = False, \n",
        "                        TFIO_LOAD:bool = False) -> None:\n",
        "\n",
        "        for path in self.PATHS:\n",
        "            if 'TEST' in str(path) or 'TRAIN' in str(path) or 'VALIDATION' in str(path):\n",
        "                for root, dir, file in os.walk(path):\n",
        "                    for tmp_label in dir:  \n",
        "                        for file in [f for f in listdir(os.path.join(root, tmp_label)) if isfile(join(os.path.join(root, tmp_label), f))]:\n",
        "                            if '_raw_mel' in str(file) and LOAD_RAW:\n",
        "                                if TORCH_LOAD:\n",
        "                                    tmp_data = torch.load(os.path.join(path, tmp_label, file))\n",
        "                                if TFIO_LOAD:\n",
        "                                    tmp_data = tf.io.parse_tensor(tf.io.read_file(os.path.join(path, tmp_label, file)), tf.float32)\n",
        "                                    \n",
        "                                new_row = pd.Series({\"Label\": tmp_label,\n",
        "                                                    \"Tensor\": tmp_data})\n",
        "                                if \"TRAIN\" in path:\n",
        "                                    self.train_data = pd.concat([self.train_data, new_row.to_frame().T], ignore_index=True)\n",
        "                                elif \"TEST\" in path:\n",
        "                                    self.test_data = pd.concat([self.test_data, new_row.to_frame().T], ignore_index=True)\n",
        "                                elif \"VALIDATION\" in path:\n",
        "                                    self.vali_data = pd.concat([self.vali_data, new_row.to_frame().T], ignore_index=True)\n",
        "                            elif '_freq_mask' in str(file) and LOAD_FREQ:\n",
        "                                if TORCH_LOAD:\n",
        "                                    tmp_data = torch.load(os.path.join(path, tmp_label, file))\n",
        "                                if TFIO_LOAD:\n",
        "                                    tmp_data = tf.io.parse_tensor(tf.io.read_file(os.path.join(path, tmp_label, file)), tf.float32)\n",
        "\n",
        "                                new_row = pd.Series({\"Label\": tmp_label,\n",
        "                                                    \"Tensor\": tmp_data})\n",
        "                                if \"TRAIN\" in path:\n",
        "                                    self.train_data = pd.concat([self.train_data, new_row.to_frame().T], ignore_index=True)\n",
        "                                elif \"TEST\" in path:\n",
        "                                    self.test_data = pd.concat([self.test_data, new_row.to_frame().T], ignore_index=True)\n",
        "                                elif \"VALIDATION\" in path:\n",
        "                                    self.vali_data = pd.concat([self.vali_data, new_row.to_frame().T], ignore_index=True)\n",
        "                            elif '_time_mask' in str(file) and LOAD_TIME:\n",
        "                                if TORCH_LOAD:\n",
        "                                    tmp_data = torch.load(os.path.join(path, tmp_label, file))\n",
        "                                if TFIO_LOAD:\n",
        "                                    tmp_data = tf.io.parse_tensor(tf.io.read_file(os.path.join(path, tmp_label, file)), tf.float32)\n",
        "                                    \n",
        "                                new_row = pd.Series({\"Label\": tmp_label,\n",
        "                                                    \"Tensor\": tmp_data})\n",
        "                                if \"TRAIN\" in path:\n",
        "                                    self.train_data = pd.concat([self.train_data, new_row.to_frame().T], ignore_index=True)\n",
        "                                elif \"TEST\" in path:\n",
        "                                    self.test_data = pd.concat([self.test_data, new_row.to_frame().T], ignore_index=True)\n",
        "                                elif \"VALIDATION\" in path:\n",
        "                                    self.vali_data = pd.concat([self.vali_data, new_row.to_frame().T], ignore_index=True)\n",
        "\n",
        "        if TO_CSV:\n",
        "            self.train_data.to_csv(os.path.join(self.DATASET_PATH, 'train_df.csv'))\n",
        "            self.test_data.to_csv(os.path.join(self.DATASET_PATH, 'test_df.csv'))\n",
        "            self.vali_data.to_csv(os.path.join(self.DATASET_PATH, 'vali_df.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-22T07:06:05.072618Z",
          "iopub.status.idle": "2023-04-22T07:06:05.073852Z",
          "shell.execute_reply": "2023-04-22T07:06:05.073536Z",
          "shell.execute_reply.started": "2023-04-22T07:06:05.073500Z"
        },
        "id": "bRNpGF-Jzqne",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69275740-55e1-46b2-be7a-37135e45b5f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking to find train, test and vali directories inside tensors folder...\n",
            "PASS\n",
            "This process will take approx 1 minute\n",
            "Finished\n",
            "Train Shape: (8529, 2), Test Shape: (81, 2), Validation Shape: (588, 2)\n"
          ]
        }
      ],
      "source": [
        "model_data_pipeline = train_test_vali_pipeline(data_preprocessing_pipeline._SET_OUTPUT_DIR)\n",
        "\n",
        "model_data_pipeline.check_valid_dirs()\n",
        "\n",
        "print('This process will take approx 1 minute')\n",
        "model_data_pipeline.load_data(LOAD_RAW=True, LOAD_FREQ=True, LOAD_TIME=True, TO_CSV=False, TORCH_LOAD=False, TFIO_LOAD=True)\n",
        "\n",
        "print(\"Finished\")\n",
        "print(f'Train Shape: {model_data_pipeline.train_data.shape}, Test Shape: {model_data_pipeline.test_data.shape}, Validation Shape: {model_data_pipeline.vali_data.shape}') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-22T07:06:05.076281Z",
          "iopub.status.idle": "2023-04-22T07:06:05.076915Z",
          "shell.execute_reply": "2023-04-22T07:06:05.076619Z",
          "shell.execute_reply.started": "2023-04-22T07:06:05.076586Z"
        },
        "id": "lnApGFM6zqne"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fogK20VTzqnf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdLufMVqzqnf"
      },
      "source": [
        "# **Till now we got our pipeline and OUTPUT_tensors**\n",
        "the ablove code takes time to process:\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "2848388c1d7df64c5912f8c74b12cb2f63a5fbb869f66edadd9f1eda580b6df3"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}