{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ec77d33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Using cached torchvision-0.15.2-cp311-cp311-macosx_11_0_arm64.whl (1.4 MB)\n",
      "Requirement already satisfied: numpy in /Users/chenchen/miniconda3/lib/python3.11/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in /Users/chenchen/miniconda3/lib/python3.11/site-packages (from torchvision) (2.29.0)\n",
      "Requirement already satisfied: torch==2.0.1 in /Users/chenchen/miniconda3/lib/python3.11/site-packages (from torchvision) (2.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/chenchen/miniconda3/lib/python3.11/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: filelock in /Users/chenchen/miniconda3/lib/python3.11/site-packages (from torch==2.0.1->torchvision) (3.12.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/chenchen/miniconda3/lib/python3.11/site-packages (from torch==2.0.1->torchvision) (4.5.0)\n",
      "Requirement already satisfied: sympy in /Users/chenchen/miniconda3/lib/python3.11/site-packages (from torch==2.0.1->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/chenchen/miniconda3/lib/python3.11/site-packages (from torch==2.0.1->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/chenchen/miniconda3/lib/python3.11/site-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/chenchen/miniconda3/lib/python3.11/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/chenchen/miniconda3/lib/python3.11/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/chenchen/miniconda3/lib/python3.11/site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/chenchen/miniconda3/lib/python3.11/site-packages (from requests->torchvision) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/chenchen/miniconda3/lib/python3.11/site-packages (from jinja2->torch==2.0.1->torchvision) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/chenchen/miniconda3/lib/python3.11/site-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.15.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa87e66a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Imports\n",
    "##################################################\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import skimage.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8bfacc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cat.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Show the image\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcat.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(image)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/PIL/Image.py:3227\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3224\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   3226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3227\u001b[0m     fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3228\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3230\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cat.jpg'"
     ]
    }
   ],
   "source": [
    "# Show the image\n",
    "image = Image.open(\"cat.jpg\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85365c4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 18\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Scale to 224x224, convert to tensor, and normalize with mean/std for ImageNet\u001b[39;00m\n\u001b[1;32m     12\u001b[0m preprocess \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     13\u001b[0m    transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)),\n\u001b[1;32m     14\u001b[0m    transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m     15\u001b[0m    normalize,\n\u001b[1;32m     16\u001b[0m ])\n\u001b[0;32m---> 18\u001b[0m x_img \u001b[38;5;241m=\u001b[39m preprocess(image)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m t(img)\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torchvision/transforms/transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mnormalize(tensor, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstd, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minplace)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torchvision/transforms/functional.py:363\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mnormalize(tensor, mean\u001b[38;5;241m=\u001b[39mmean, std\u001b[38;5;241m=\u001b[39mstd, inplace\u001b[38;5;241m=\u001b[39minplace)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torchvision/transforms/_functional_tensor.py:928\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m std\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    927\u001b[0m     std \u001b[38;5;241m=\u001b[39m std\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 928\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39msub_(mean)\u001b[38;5;241m.\u001b[39mdiv_(std)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# Preprocessing\n",
    "##################################################\n",
    "\n",
    "# Imagenet mean/std\n",
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "# Scale to 224x224, convert to tensor, and normalize with mean/std for ImageNet\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Resize((224, 224)),\n",
    "   transforms.ToTensor(),\n",
    "   normalize,\n",
    "])\n",
    "\n",
    "x_img = preprocess(image).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "634dfd77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenchen/miniconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/chenchen/miniconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66c38390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the features from a model\n",
    "class SaveFeatures():\n",
    "    features = None\n",
    "    def __init__(self, module): \n",
    "        self.hook = module.register_forward_hook(self.hook_fn)\n",
    "\n",
    "    def hook_fn(self, module, input, output): \n",
    "        self.features = output.data.numpy()\n",
    "\n",
    "    def remove(self): \n",
    "        self.hook.remove()\n",
    "\n",
    "def getCAM(feature_conv, weight_fc, class_idx):\n",
    "    _, nc, h, w = feature_conv.shape\n",
    "    cam = weight_fc[class_idx].dot(feature_conv.reshape((nc, h * w)))\n",
    "    cam = cam.reshape(h, w)\n",
    "    cam = cam - np.min(cam)\n",
    "    cam_img = cam / np.max(cam)\n",
    "    return [cam_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3d7df13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[1;32m      6\u001b[0m _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m----> 7\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model(x_img)\n\u001b[1;32m      8\u001b[0m pred_probabilities \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(prediction)\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m      9\u001b[0m activated_features\u001b[38;5;241m.\u001b[39mremove()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_img' is not defined"
     ]
    }
   ],
   "source": [
    "# Get features from last conv layer\n",
    "final_layer = model._modules.get('layer4')\n",
    "activated_features = SaveFeatures(final_layer)\n",
    "\n",
    "# Inference\n",
    "_ = model.eval()\n",
    "prediction = model(x_img)\n",
    "pred_probabilities = F.softmax(prediction).data.squeeze()\n",
    "activated_features.remove()\n",
    "print('Top-1 prediction:', torch.topk(pred_probabilities, 1))\n",
    "\n",
    "# Take weights from the first linear layer\n",
    "weight_softmax_params = list(model._modules.get('fc').parameters())\n",
    "weight_softmax = np.squeeze(weight_softmax_params[0].data.numpy())\n",
    "\n",
    "# Get the top-1 prediction and get CAM\n",
    "class_idx = torch.topk(pred_probabilities, 1)[1].int()\n",
    "overlay = getCAM(activated_features.features, weight_softmax, class_idx )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02a76be3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'overlay' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass Activation Map\u001b[39m\u001b[38;5;124m'\u001b[39m, fontweight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(overlay[\u001b[38;5;241m0\u001b[39m], alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Show CAM on the image\u001b[39;00m\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'overlay' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show CAM\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.title('Class Activation Map', fontweight='bold')\n",
    "plt.imshow(overlay[0], alpha=0.5, cmap='jet')\n",
    "\n",
    "# Show CAM on the image\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.title('Class Activation Map on the Image', fontweight='bold')\n",
    "plt.imshow(image)\n",
    "plt.imshow(skimage.transform.resize(overlay[0], (image.size[1], image.size[0])), alpha=0.5, cmap='jet');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738dcb36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
