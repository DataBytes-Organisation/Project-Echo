{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbdddfed-47d7-418a-8126-621292d2b59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "14/14 [==============================] - 3s 157ms/step - loss: 1.9142 - type_output_loss: 0.8937 - sub_category_output_loss: 1.0205 - type_output_accuracy: 0.0750 - sub_category_output_accuracy: 0.0205 - val_loss: 0.3539 - val_type_output_loss: 0.1863 - val_sub_category_output_loss: 0.1677 - val_type_output_accuracy: 0.3727 - val_sub_category_output_accuracy: 0.0182\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.4806 - type_output_loss: 0.2499 - sub_category_output_loss: 0.2307 - type_output_accuracy: 0.0909 - sub_category_output_accuracy: 0.0455 - val_loss: 0.3273 - val_type_output_loss: 0.1806 - val_sub_category_output_loss: 0.1467 - val_type_output_accuracy: 0.5000 - val_sub_category_output_accuracy: 0.1364\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 2s 141ms/step - loss: 0.4078 - type_output_loss: 0.2174 - sub_category_output_loss: 0.1903 - type_output_accuracy: 0.1409 - sub_category_output_accuracy: 0.0614 - val_loss: 0.3161 - val_type_output_loss: 0.1728 - val_sub_category_output_loss: 0.1432 - val_type_output_accuracy: 0.4182 - val_sub_category_output_accuracy: 0.1364\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.3734 - type_output_loss: 0.2003 - sub_category_output_loss: 0.1731 - type_output_accuracy: 0.1795 - sub_category_output_accuracy: 0.0818 - val_loss: 0.2854 - val_type_output_loss: 0.1479 - val_sub_category_output_loss: 0.1375 - val_type_output_accuracy: 0.5091 - val_sub_category_output_accuracy: 0.1909\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 2s 141ms/step - loss: 0.3357 - type_output_loss: 0.1787 - sub_category_output_loss: 0.1570 - type_output_accuracy: 0.2682 - sub_category_output_accuracy: 0.1386 - val_loss: 0.2563 - val_type_output_loss: 0.1282 - val_sub_category_output_loss: 0.1281 - val_type_output_accuracy: 0.5182 - val_sub_category_output_accuracy: 0.1909\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.3004 - type_output_loss: 0.1575 - sub_category_output_loss: 0.1429 - type_output_accuracy: 0.3591 - sub_category_output_accuracy: 0.1977 - val_loss: 0.2296 - val_type_output_loss: 0.1179 - val_sub_category_output_loss: 0.1117 - val_type_output_accuracy: 0.5727 - val_sub_category_output_accuracy: 0.2545\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.2634 - type_output_loss: 0.1374 - sub_category_output_loss: 0.1260 - type_output_accuracy: 0.4250 - sub_category_output_accuracy: 0.2568 - val_loss: 0.2057 - val_type_output_loss: 0.1032 - val_sub_category_output_loss: 0.1025 - val_type_output_accuracy: 0.5727 - val_sub_category_output_accuracy: 0.3091\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.2469 - type_output_loss: 0.1300 - sub_category_output_loss: 0.1169 - type_output_accuracy: 0.4682 - sub_category_output_accuracy: 0.3205 - val_loss: 0.1915 - val_type_output_loss: 0.0930 - val_sub_category_output_loss: 0.0985 - val_type_output_accuracy: 0.6091 - val_sub_category_output_accuracy: 0.3909\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 2s 158ms/step - loss: 0.2225 - type_output_loss: 0.1169 - sub_category_output_loss: 0.1057 - type_output_accuracy: 0.5341 - sub_category_output_accuracy: 0.4182 - val_loss: 0.1887 - val_type_output_loss: 0.0936 - val_sub_category_output_loss: 0.0952 - val_type_output_accuracy: 0.6364 - val_sub_category_output_accuracy: 0.4000\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.1978 - type_output_loss: 0.1022 - sub_category_output_loss: 0.0956 - type_output_accuracy: 0.6250 - sub_category_output_accuracy: 0.4568 - val_loss: 0.1743 - val_type_output_loss: 0.0847 - val_sub_category_output_loss: 0.0896 - val_type_output_accuracy: 0.7273 - val_sub_category_output_accuracy: 0.4273\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.1775 - type_output_loss: 0.0924 - sub_category_output_loss: 0.0851 - type_output_accuracy: 0.6568 - sub_category_output_accuracy: 0.4932 - val_loss: 0.1514 - val_type_output_loss: 0.0706 - val_sub_category_output_loss: 0.0809 - val_type_output_accuracy: 0.7818 - val_sub_category_output_accuracy: 0.5636\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 2s 145ms/step - loss: 0.1663 - type_output_loss: 0.0854 - sub_category_output_loss: 0.0809 - type_output_accuracy: 0.6955 - sub_category_output_accuracy: 0.5364 - val_loss: 0.1449 - val_type_output_loss: 0.0701 - val_sub_category_output_loss: 0.0748 - val_type_output_accuracy: 0.7909 - val_sub_category_output_accuracy: 0.6182\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 2s 144ms/step - loss: 0.1544 - type_output_loss: 0.0788 - sub_category_output_loss: 0.0757 - type_output_accuracy: 0.7318 - sub_category_output_accuracy: 0.5795 - val_loss: 0.1508 - val_type_output_loss: 0.0686 - val_sub_category_output_loss: 0.0821 - val_type_output_accuracy: 0.8091 - val_sub_category_output_accuracy: 0.6636\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 2s 158ms/step - loss: 0.1386 - type_output_loss: 0.0678 - sub_category_output_loss: 0.0708 - type_output_accuracy: 0.7841 - sub_category_output_accuracy: 0.6341 - val_loss: 0.1391 - val_type_output_loss: 0.0654 - val_sub_category_output_loss: 0.0737 - val_type_output_accuracy: 0.8545 - val_sub_category_output_accuracy: 0.6364\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.1336 - type_output_loss: 0.0659 - sub_category_output_loss: 0.0676 - type_output_accuracy: 0.7841 - sub_category_output_accuracy: 0.6795 - val_loss: 0.1294 - val_type_output_loss: 0.0622 - val_sub_category_output_loss: 0.0672 - val_type_output_accuracy: 0.8455 - val_sub_category_output_accuracy: 0.6273\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 2s 156ms/step - loss: 0.1183 - type_output_loss: 0.0591 - sub_category_output_loss: 0.0592 - type_output_accuracy: 0.8205 - sub_category_output_accuracy: 0.7227 - val_loss: 0.1334 - val_type_output_loss: 0.0629 - val_sub_category_output_loss: 0.0705 - val_type_output_accuracy: 0.8364 - val_sub_category_output_accuracy: 0.6727\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.1148 - type_output_loss: 0.0586 - sub_category_output_loss: 0.0562 - type_output_accuracy: 0.8159 - sub_category_output_accuracy: 0.7318 - val_loss: 0.1166 - val_type_output_loss: 0.0524 - val_sub_category_output_loss: 0.0642 - val_type_output_accuracy: 0.8636 - val_sub_category_output_accuracy: 0.7273\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 2s 145ms/step - loss: 0.1000 - type_output_loss: 0.0500 - sub_category_output_loss: 0.0500 - type_output_accuracy: 0.8545 - sub_category_output_accuracy: 0.7500 - val_loss: 0.1335 - val_type_output_loss: 0.0643 - val_sub_category_output_loss: 0.0692 - val_type_output_accuracy: 0.8545 - val_sub_category_output_accuracy: 0.7273\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 2s 154ms/step - loss: 0.0961 - type_output_loss: 0.0519 - sub_category_output_loss: 0.0441 - type_output_accuracy: 0.8341 - sub_category_output_accuracy: 0.7909 - val_loss: 0.1345 - val_type_output_loss: 0.0673 - val_sub_category_output_loss: 0.0672 - val_type_output_accuracy: 0.8818 - val_sub_category_output_accuracy: 0.7455\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 2s 143ms/step - loss: 0.0897 - type_output_loss: 0.0467 - sub_category_output_loss: 0.0429 - type_output_accuracy: 0.8545 - sub_category_output_accuracy: 0.7909 - val_loss: 0.1058 - val_type_output_loss: 0.0510 - val_sub_category_output_loss: 0.0548 - val_type_output_accuracy: 0.8727 - val_sub_category_output_accuracy: 0.8545\n",
      "4/4 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[\n",
      "    {\n",
      "        \"chunk\": 1,\n",
      "        \"results\": [\n",
      "            {\n",
      "                \"label\": \"tasmanian\",\n",
      "                \"type\": \"type\",\n",
      "                \"confidence\": \"0.49\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"chunk\": 2,\n",
      "        \"results\": [\n",
      "            {\n",
      "                \"label\": \"tasmanian\",\n",
      "                \"type\": \"type\",\n",
      "                \"confidence\": \"0.50\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"chunk\": 3,\n",
      "        \"results\": []\n",
      "    },\n",
      "    {\n",
      "        \"chunk\": 4,\n",
      "        \"results\": [\n",
      "            {\n",
      "                \"label\": \"Devil\",\n",
      "                \"type\": \"sub_category\",\n",
      "                \"confidence\": \"0.38\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"chunk\": 5,\n",
      "        \"results\": [\n",
      "            {\n",
      "                \"label\": \"tasmanian\",\n",
      "                \"type\": \"type\",\n",
      "                \"confidence\": \"0.56\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Devil\",\n",
      "                \"type\": \"sub_category\",\n",
      "                \"confidence\": \"0.84\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"chunk\": 6,\n",
      "        \"results\": [\n",
      "            {\n",
      "                \"label\": \"tasmanian\",\n",
      "                \"type\": \"type\",\n",
      "                \"confidence\": \"0.57\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"chunk\": 7,\n",
      "        \"results\": [\n",
      "            {\n",
      "                \"label\": \"tasmanian\",\n",
      "                \"type\": \"type\",\n",
      "                \"confidence\": \"0.59\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"chunk\": 8,\n",
      "        \"results\": [\n",
      "            {\n",
      "                \"label\": \"tasmanian\",\n",
      "                \"type\": \"type\",\n",
      "                \"confidence\": \"0.73\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Devil\",\n",
      "                \"type\": \"sub_category\",\n",
      "                \"confidence\": \"0.66\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"chunk\": 9,\n",
      "        \"results\": [\n",
      "            {\n",
      "                \"label\": \"tasmanian\",\n",
      "                \"type\": \"type\",\n",
      "                \"confidence\": \"0.80\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Devil\",\n",
      "                \"type\": \"sub_category\",\n",
      "                \"confidence\": \"0.69\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"chunk\": 10,\n",
      "        \"results\": [\n",
      "            {\n",
      "                \"label\": \"tasmanian\",\n",
      "                \"type\": \"type\",\n",
      "                \"confidence\": \"0.53\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Devil\",\n",
      "                \"type\": \"sub_category\",\n",
      "                \"confidence\": \"0.51\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# MAEC - Multilabel Audio Event Classification\n",
    "\n",
    "# Function to chunk audio\n",
    "def chunk_audio(audio_path, chunk_duration=2.0, sr=22050, allow_partial=True):\n",
    "    y, sr = librosa.load(audio_path, sr=sr)\n",
    "    chunk_length = int(chunk_duration * sr)\n",
    "    if allow_partial:\n",
    "        chunks = [y[i:i + chunk_length] for i in range(0, len(y), chunk_length)]\n",
    "    else:\n",
    "        chunks = [y[i:i + chunk_length] for i in range(0, len(y), chunk_length) if len(y[i:i + chunk_length]) == chunk_length]\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# Function to convert chunks to spectrograms\n",
    "def chunks_to_spectrograms(chunks, sr=22050):\n",
    "    spectrograms = []\n",
    "    for chunk in chunks:\n",
    "        S = librosa.feature.melspectrogram(y=chunk, sr=sr, n_mels=128)\n",
    "        S_DB = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "        # Make sure it’s exactly (128, 128)\n",
    "        if S_DB.shape[1] < 128:\n",
    "            pad = 128 - S_DB.shape[1]\n",
    "            S_DB = np.pad(S_DB, ((0, 0), (0, pad)), mode='constant')\n",
    "        elif S_DB.shape[1] > 128:\n",
    "            S_DB = S_DB[:, :128]\n",
    "\n",
    "        spectrograms.append(S_DB)\n",
    "    return np.array(spectrograms)\n",
    "\n",
    "\n",
    "# Function to create the model\n",
    "def create_model(input_shape, num_types, num_sub_categories):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    type_output = Dense(num_types, activation='sigmoid', name='type_output')(x)\n",
    "    sub_category_output = Dense(num_sub_categories, activation='sigmoid', name='sub_category_output')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=[type_output, sub_category_output])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics={'type_output': 'accuracy', 'sub_category_output': 'accuracy'})\n",
    "    return model\n",
    "\n",
    "# Example labels for each chunk\n",
    "# Load real labels from training_data.json (generated from your audio folders)\n",
    "with open(r\"C:\\Users\\User\\Downloads\\Animal Sounds 5\\Animal Sounds\\training_data.json\", \"r\") as f:\n",
    "    training_data = json.load(f)\n",
    "\n",
    "# Extract one label per file (for now we treat each file as a \"chunk\")\n",
    "# Use MultiLabelBinarizer for one-hot encoding\n",
    "mlb_types = MultiLabelBinarizer()\n",
    "mlb_sub_categories = MultiLabelBinarizer()\n",
    "\n",
    "spectrograms = []\n",
    "y_types_aligned = []\n",
    "y_sub_categories_aligned = []\n",
    "\n",
    "for item in training_data:\n",
    "    audio_path = os.path.join(r\"C:\\Users\\User\\Downloads\\Animal Sounds 5\\Animal Sounds\", item[\"file\"])\n",
    "\n",
    "    try:\n",
    "        chunks = chunk_audio(audio_path)\n",
    "        specs = chunks_to_spectrograms(chunks)\n",
    "\n",
    "        for spec in specs:\n",
    "            padded = np.pad(spec, ((0, 0), (0, max(128 - spec.shape[1], 0))), mode='constant')\n",
    "            spectrograms.append(padded)\n",
    "\n",
    "            y_types_aligned.append([item[\"type\"]])\n",
    "            y_sub_categories_aligned.append([item[\"sub_category\"]])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Skipped {audio_path}: {e}\")\n",
    "\n",
    "# Convert to arrays and encode labels\n",
    "spectrograms = np.array(spectrograms)\n",
    "spectrograms = np.expand_dims(spectrograms, axis=-1)\n",
    "\n",
    "y_types = mlb_types.fit_transform(y_types_aligned)\n",
    "y_sub_categories = mlb_sub_categories.fit_transform(y_sub_categories_aligned)\n",
    "\n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, y_train_types, y_val_types, y_train_sub_categories, y_val_sub_categories = train_test_split(\n",
    "    spectrograms, y_types, y_sub_categories, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create and train the model\n",
    "input_shape = (128, 128, 1)  # adjust according to your spectrogram dimensions\n",
    "num_types = len(mlb_types.classes_)\n",
    "num_sub_categories = len(mlb_sub_categories.classes_)\n",
    "model = create_model(input_shape, num_types, num_sub_categories)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    {'type_output': y_train_types, 'sub_category_output': y_train_sub_categories},\n",
    "    epochs=20, \n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, {'type_output': y_val_types, 'sub_category_output': y_val_sub_categories})\n",
    ")\n",
    "\n",
    "# Predict on validation data\n",
    "type_predictions, sub_category_predictions = model.predict(X_val)\n",
    "\n",
    "threshold = 0.3  # Lower the threshold to capture more predictions\n",
    "\n",
    "def interpret_predictions(type_preds, sub_category_preds, type_labels, sub_category_labels, threshold=0.3):\n",
    "    results = []\n",
    "    for t_pred, s_pred in zip(type_preds, sub_category_preds):\n",
    "        chunk_results = []\n",
    "        for i, type_prob in enumerate(t_pred):\n",
    "            if type_prob > threshold:\n",
    "                chunk_results.append({\"label\": type_labels[i], \"type\": \"type\", \"confidence\": f\"{type_prob:.2f}\"})\n",
    "        for i, sub_category_prob in enumerate(s_pred):\n",
    "            if sub_category_prob > threshold:\n",
    "                chunk_results.append({\"label\": sub_category_labels[i], \"type\": \"sub_category\", \"confidence\": f\"{sub_category_prob:.2f}\"})\n",
    "        results.append(chunk_results)\n",
    "    return results\n",
    "\n",
    "def process_audio_file(audio_path, model, mlb_types, mlb_sub_categories, chunk_duration=2.0, sr=22050, threshold=0.3):\n",
    "    chunks = chunk_audio(audio_path, chunk_duration, sr, allow_partial=True)\n",
    "    if not chunks:\n",
    "        print(f\"❌ No valid chunks found in {audio_path}\")\n",
    "        return None\n",
    "\n",
    "    spectrograms = chunks_to_spectrograms(chunks, sr)\n",
    "    if spectrograms.size == 0:\n",
    "        print(f\"❌ No spectrograms generated from {audio_path}\")\n",
    "        return None\n",
    "\n",
    "    spectrograms = np.array([np.pad(s, ((0, 0), (0, max(128 - s.shape[1], 0))), mode='constant') for s in spectrograms])\n",
    "    spectrograms = np.expand_dims(spectrograms, axis=-1)  # Add channel dimension for CNN\n",
    "\n",
    "    type_predictions, sub_category_predictions = model.predict(spectrograms)\n",
    "\n",
    "    results = interpret_predictions(type_predictions, sub_category_predictions, mlb_types.classes_, mlb_sub_categories.classes_, threshold)\n",
    "\n",
    "    formatted_results = []\n",
    "    for i, chunk_results in enumerate(results):\n",
    "        chunk_formatted = []\n",
    "        for result in chunk_results:\n",
    "            chunk_formatted.append(result)\n",
    "        formatted_results.append({\"chunk\": i + 1, \"results\": chunk_formatted})\n",
    "\n",
    "    return json.dumps(formatted_results, indent=4)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "audio_path = r'C:\\Users\\User\\Downloads\\Animal Sounds 5\\Animal Sounds\\Tasmanian Devil.wav'\n",
    "json_output = process_audio_file(audio_path, model, mlb_types, mlb_sub_categories)\n",
    "print(json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ff0fb4-7196-49f9-a89a-80ac089c9407",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (projectecho)",
   "language": "python",
   "name": "projectecho"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
