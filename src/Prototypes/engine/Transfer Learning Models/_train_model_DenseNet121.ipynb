{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AqYbtehvlUZ"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvE0rM9uyfah",
        "outputId": "108b7e72-a33a-4bed-a70c-4b124f922207"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-yUdZLWyPDD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/Othercomputers/My laptop/Project-Echo/src/Prototypes/engine/Transfer Learning Models\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Oxyu9lnRnqD"
      },
      "outputs": [],
      "source": [
        "from _model_config import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_U2dr35UxpQe",
        "outputId": "a68934d3-2b03-4d02-fdf5-051c17d49cbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.1/66.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.0/578.0 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.19.2 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.4 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 3.19.6 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install diskcache -q\n",
        "%pip install audiomentations==0.29.0 -q\n",
        "%pip install tensorflow==2.10.0 -q\n",
        "%pip install keras==2.10.0 -q\n",
        "%pip install tensorflow_addons -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0r1crUevlUb",
        "outputId": "8873cfb2-c0e7-4839-ae27-cb44e4aae61e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python Version           :  3.10.12\n",
            "TensorFlow Version       :  2.10.0\n",
            "Keras Version            :  2.10.0\n",
            "Librosa Version          :  0.9.2\n",
            "Audiomentations Version  :  0.29.0\n",
            "Found 7514 files belonging to 118 classes.\n",
            "Class names:  ['Acanthiza chrysorrhoa', 'Acanthiza lineata', 'Acanthiza nana', 'Acanthiza pusilla', 'Acanthiza reguloides', 'Acanthiza uropygialis', 'Acanthorhynchus tenuirostris', 'Accipiter cirrocephalus', 'Aidemosyne modesta', 'Alauda arvensis', 'Anhinga novaehollandiae', 'Anthochaera phrygia', 'Antigone rubicunda', 'Artamus cinereus', 'Artamus cyanopterus', 'Artamus minor', 'Artamus superciliosus', 'Barnardius zonarius', 'Callocephalon fimbriatum', 'Calyptorhynchus banksii', 'Calyptorhynchus lathami', 'Capra Hircus', 'Carduelis carduelis', 'Carterornis leucotis', 'Cervus Unicolour', 'Ceyx azureus', 'Chenonetta jubata', 'Chlamydera nuchalis', 'Cincloramphus mathewsi', 'Cinclosoma punctatum', 'Cisticola exilis', 'Climacteris picumnus', 'Colluricincla harmonica', 'Conopophila albogularis', 'Cophixalus exiguus', 'Cophixalus infacetus', 'Cophixalus ornatus', 'Coracina novaehollandiae', 'Coracina papuensis', 'Corcorax melanorhamphos', 'Cormobates leucophaea', 'Corvus mellori', 'Coturnix pectoralis', 'Cygnus atratus', 'Dama Dama', 'Daphoenositta chrysoptera', 'Dasyurus maculatus', 'Dicaeum hirundinaceum', 'Egretta novaehollandiae', 'Elseyornis melanops', 'Entomyzon cyanotis', 'Eurostopodus argus', 'Eurostopodus mystacalis', 'Eurystomus orientalis', 'Falco berigora', 'Falco cenchroides', 'Falco peregrinus', 'Falcunculus frontatus', 'Felis Catus', 'Fulica atra', 'Gallinula tenebrosa', 'Geopelia cuneata', 'Gerygone mouki', 'Haliastur sphenurus', 'Irediparra gallinacea', 'Lalage leucomela', 'Litoria inermis', 'Manorina melanophrys', 'Megapodius reinwardt', 'Melithreptus brevirostris', 'Melithreptus gularis', 'Melithreptus lunatus', 'Microeca flavigaster', 'Neophema pulchella', 'Nesoptilotis leucotis', 'Pachycephala simplex', 'Pardalotus rubricatus', 'Parvipsitta pusilla', 'Pelecanus conspicillatus', 'Petrochelidon ariel', 'Petrochelidon nigricans', 'Petroica boodang', 'Petroica goodenovii', 'Petroica phoenicea', 'Petroica rosea', 'Pezoporus wallicus', 'Phaps elegans', 'Philemon citreogularis', 'Philemon corniculatus', 'Phylidonyris niger', 'Pitta iris', 'Pitta versicolor', 'Platycercus elegans', 'Plectorhyncha lanceolata', 'Psophodes cristatus', 'Ptilinopus regina', 'Pycnoptilus floccosus', 'Ramsayornis fasciatus', 'Ranoidea caerulea', 'Rattus Norvegicus', 'Rhinella marina', 'Rhipidura albiscapa', 'Rhipidura leucophrys', 'Rhipidura rufifrons', 'Rhipidura rufiventris', 'Scythrops novaehollandiae', 'Spilopelia chinensis', 'Stizoptera bichenovii', 'Stomiopera unicolor', 'Strepera versicolor', 'Sus Scrofa', 'Symposiachrus trivirgatus', 'Tregellasia capito', 'Trichosurus vulpecula', 'Uperoleia altissima', 'Uperoleia mimula', 'Vanellus miles', 'Vulpes vulpes']\n",
            "Training dataset length: 6011\n",
            "Validation dataset length: 1427\n",
            "Test dataset length: 76\n"
          ]
        }
      ],
      "source": [
        "exec(f\"from {MODEL_NAME} import *\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INkqi6buvlUd",
        "outputId": "964efd18-29da-4985-9400-dbeaa78e1c30"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29084464/29084464 [==============================] - 2s 0us/step\n",
            "Model: \"model\"\n",
            "____________________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   Trainable  \n",
            "============================================================================\n",
            " input_2 (InputLayer)        [(None, 299, 299, 3)]     0         Y          \n",
            "                                                                            \n",
            " densenet121 (Functional)    (None, 9, 9, 1024)        7037504   N          \n",
            "                                                                            \n",
            " global_average_pooling2d (G  (None, 1024)             0         Y          \n",
            " lobalAveragePooling2D)                                                     \n",
            "                                                                            \n",
            " dropout (Dropout)           (None, 1024)              0         Y          \n",
            "                                                                            \n",
            " dense (Dense)               (None, 118)               120950    Y          \n",
            "                                                                            \n",
            "============================================================================\n",
            "Total params: 7,158,454\n",
            "Trainable params: 120,950\n",
            "Non-trainable params: 7,037,504\n",
            "____________________________________________________________________________\n",
            "Epoch 1/5000\n",
            "376/376 [==============================] - 1048s 3s/step - loss: 4.2070 - accuracy: 0.0607 - val_loss: 3.9060 - val_accuracy: 0.1128 - lr: 1.0000e-04\n",
            "Epoch 2/5000\n",
            "376/376 [==============================] - 820s 2s/step - loss: 3.9021 - accuracy: 0.1053 - val_loss: 3.7742 - val_accuracy: 0.1682 - lr: 1.0000e-04\n",
            "Epoch 3/5000\n",
            "376/376 [==============================] - 771s 2s/step - loss: 3.8003 - accuracy: 0.1441 - val_loss: 3.6640 - val_accuracy: 0.1997 - lr: 1.0000e-04\n",
            "Epoch 4/5000\n",
            "376/376 [==============================] - 720s 2s/step - loss: 3.6990 - accuracy: 0.1582 - val_loss: 3.5729 - val_accuracy: 0.2172 - lr: 1.0000e-04\n",
            "Epoch 5/5000\n",
            "376/376 [==============================] - 677s 2s/step - loss: 3.6049 - accuracy: 0.1758 - val_loss: 3.4805 - val_accuracy: 0.2488 - lr: 1.0000e-04\n",
            "Epoch 6/5000\n",
            "376/376 [==============================] - 663s 2s/step - loss: 3.5430 - accuracy: 0.1913 - val_loss: 3.4065 - val_accuracy: 0.2600 - lr: 1.0000e-04\n",
            "Epoch 7/5000\n",
            "376/376 [==============================] - 644s 2s/step - loss: 3.4606 - accuracy: 0.2131 - val_loss: 3.3311 - val_accuracy: 0.2747 - lr: 1.0000e-04\n",
            "Epoch 8/5000\n",
            "376/376 [==============================] - 643s 2s/step - loss: 3.3927 - accuracy: 0.2258 - val_loss: 3.2659 - val_accuracy: 0.2852 - lr: 1.0000e-04\n",
            "Epoch 9/5000\n",
            "376/376 [==============================] - 623s 2s/step - loss: 3.3463 - accuracy: 0.2391 - val_loss: 3.2057 - val_accuracy: 0.2908 - lr: 1.0000e-04\n",
            "Epoch 10/5000\n",
            "376/376 [==============================] - 627s 2s/step - loss: 3.2758 - accuracy: 0.2517 - val_loss: 3.1541 - val_accuracy: 0.2887 - lr: 1.0000e-04\n",
            "Epoch 11/5000\n",
            "376/376 [==============================] - 616s 2s/step - loss: 3.2280 - accuracy: 0.2514 - val_loss: 3.1031 - val_accuracy: 0.2950 - lr: 1.0000e-04\n",
            "Epoch 12/5000\n",
            "376/376 [==============================] - 614s 2s/step - loss: 3.1746 - accuracy: 0.2655 - val_loss: 3.0574 - val_accuracy: 0.3055 - lr: 1.0000e-04\n",
            "Epoch 13/5000\n",
            "376/376 [==============================] - 600s 2s/step - loss: 3.1397 - accuracy: 0.2720 - val_loss: 3.0086 - val_accuracy: 0.3231 - lr: 1.0000e-04\n",
            "Epoch 14/5000\n",
            "376/376 [==============================] - 603s 2s/step - loss: 3.0890 - accuracy: 0.2861 - val_loss: 2.9702 - val_accuracy: 0.3189 - lr: 1.0000e-04\n",
            "Epoch 15/5000\n",
            "376/376 [==============================] - 593s 2s/step - loss: 3.0546 - accuracy: 0.2885 - val_loss: 2.9279 - val_accuracy: 0.3322 - lr: 1.0000e-04\n",
            "Epoch 16/5000\n",
            "376/376 [==============================] - 595s 2s/step - loss: 3.0148 - accuracy: 0.2923 - val_loss: 2.8928 - val_accuracy: 0.3357 - lr: 1.0000e-04\n",
            "Epoch 17/5000\n",
            "376/376 [==============================] - 604s 2s/step - loss: 2.9730 - accuracy: 0.3074 - val_loss: 2.8595 - val_accuracy: 0.3413 - lr: 1.0000e-04\n",
            "Epoch 18/5000\n",
            "376/376 [==============================] - 600s 2s/step - loss: 2.9295 - accuracy: 0.3133 - val_loss: 2.8225 - val_accuracy: 0.3546 - lr: 1.0000e-04\n",
            "Epoch 19/5000\n",
            "376/376 [==============================] - 593s 2s/step - loss: 2.9155 - accuracy: 0.3118 - val_loss: 2.7939 - val_accuracy: 0.3609 - lr: 1.0000e-04\n",
            "Epoch 20/5000\n",
            "376/376 [==============================] - 605s 2s/step - loss: 2.8763 - accuracy: 0.3261 - val_loss: 2.7663 - val_accuracy: 0.3651 - lr: 1.0000e-04\n",
            "Epoch 21/5000\n",
            "376/376 [==============================] - 590s 2s/step - loss: 2.8443 - accuracy: 0.3337 - val_loss: 2.7356 - val_accuracy: 0.3735 - lr: 1.0000e-04\n",
            "Epoch 22/5000\n",
            "376/376 [==============================] - 593s 2s/step - loss: 2.8217 - accuracy: 0.3282 - val_loss: 2.7097 - val_accuracy: 0.3770 - lr: 1.0000e-04\n",
            "Epoch 23/5000\n",
            "376/376 [==============================] - 590s 2s/step - loss: 2.7994 - accuracy: 0.3337 - val_loss: 2.6844 - val_accuracy: 0.3847 - lr: 1.0000e-04\n",
            "Epoch 24/5000\n",
            "376/376 [==============================] - 591s 2s/step - loss: 2.7751 - accuracy: 0.3439 - val_loss: 2.6612 - val_accuracy: 0.3854 - lr: 1.0000e-04\n",
            "Epoch 25/5000\n",
            "376/376 [==============================] - 601s 2s/step - loss: 2.7508 - accuracy: 0.3465 - val_loss: 2.6352 - val_accuracy: 0.3980 - lr: 1.0000e-04\n",
            "Epoch 26/5000\n",
            "376/376 [==============================] - 588s 2s/step - loss: 2.7246 - accuracy: 0.3582 - val_loss: 2.6155 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
            "Epoch 27/5000\n",
            "376/376 [==============================] - 591s 2s/step - loss: 2.6902 - accuracy: 0.3605 - val_loss: 2.5934 - val_accuracy: 0.4128 - lr: 1.0000e-04\n",
            "Epoch 28/5000\n",
            "376/376 [==============================] - 605s 2s/step - loss: 2.6786 - accuracy: 0.3652 - val_loss: 2.5693 - val_accuracy: 0.4114 - lr: 1.0000e-04\n",
            "Epoch 29/5000\n",
            "376/376 [==============================] - 594s 2s/step - loss: 2.6677 - accuracy: 0.3607 - val_loss: 2.5499 - val_accuracy: 0.4198 - lr: 1.0000e-04\n",
            "Epoch 30/5000\n",
            "376/376 [==============================] - 600s 2s/step - loss: 2.6308 - accuracy: 0.3765 - val_loss: 2.5286 - val_accuracy: 0.4247 - lr: 1.0000e-04\n",
            "Epoch 31/5000\n",
            "376/376 [==============================] - 591s 2s/step - loss: 2.6180 - accuracy: 0.3758 - val_loss: 2.5183 - val_accuracy: 0.4135 - lr: 1.0000e-04\n",
            "Epoch 32/5000\n",
            "376/376 [==============================] - 583s 2s/step - loss: 2.5881 - accuracy: 0.3801 - val_loss: 2.4941 - val_accuracy: 0.4331 - lr: 1.0000e-04\n",
            "Epoch 33/5000\n",
            "376/376 [==============================] - 589s 2s/step - loss: 2.5632 - accuracy: 0.3911 - val_loss: 2.4841 - val_accuracy: 0.4359 - lr: 1.0000e-04\n",
            "Epoch 34/5000\n",
            "376/376 [==============================] - 594s 2s/step - loss: 2.5482 - accuracy: 0.3875 - val_loss: 2.4622 - val_accuracy: 0.4352 - lr: 1.0000e-04\n",
            "Epoch 35/5000\n",
            "376/376 [==============================] - 605s 2s/step - loss: 2.5382 - accuracy: 0.3934 - val_loss: 2.4470 - val_accuracy: 0.4506 - lr: 1.0000e-04\n",
            "Epoch 36/5000\n",
            "376/376 [==============================] - 598s 2s/step - loss: 2.5086 - accuracy: 0.4033 - val_loss: 2.4356 - val_accuracy: 0.4366 - lr: 1.0000e-04\n",
            "Epoch 37/5000\n",
            "376/376 [==============================] - 603s 2s/step - loss: 2.5144 - accuracy: 0.4019 - val_loss: 2.4188 - val_accuracy: 0.4464 - lr: 1.0000e-04\n",
            "Epoch 38/5000\n",
            "376/376 [==============================] - 591s 2s/step - loss: 2.4907 - accuracy: 0.3989 - val_loss: 2.4016 - val_accuracy: 0.4520 - lr: 1.0000e-04\n",
            "Epoch 39/5000\n",
            "376/376 [==============================] - 594s 2s/step - loss: 2.4810 - accuracy: 0.4053 - val_loss: 2.3857 - val_accuracy: 0.4590 - lr: 1.0000e-04\n",
            "Epoch 40/5000\n",
            "376/376 [==============================] - 586s 2s/step - loss: 2.4531 - accuracy: 0.4167 - val_loss: 2.3811 - val_accuracy: 0.4485 - lr: 1.0000e-04\n",
            "Epoch 41/5000\n",
            "376/376 [==============================] - 591s 2s/step - loss: 2.4464 - accuracy: 0.4179 - val_loss: 2.3635 - val_accuracy: 0.4667 - lr: 1.0000e-04\n",
            "Epoch 42/5000\n",
            "376/376 [==============================] - 584s 2s/step - loss: 2.4380 - accuracy: 0.4174 - val_loss: 2.3536 - val_accuracy: 0.4555 - lr: 1.0000e-04\n",
            "Epoch 43/5000\n",
            "376/376 [==============================] - 586s 2s/step - loss: 2.4158 - accuracy: 0.4209 - val_loss: 2.3366 - val_accuracy: 0.4667 - lr: 1.0000e-04\n",
            "Epoch 44/5000\n",
            "376/376 [==============================] - 580s 2s/step - loss: 2.3987 - accuracy: 0.4231 - val_loss: 2.3234 - val_accuracy: 0.4674 - lr: 1.0000e-04\n",
            "Epoch 45/5000\n",
            "376/376 [==============================] - 582s 2s/step - loss: 2.4030 - accuracy: 0.4196 - val_loss: 2.3172 - val_accuracy: 0.4667 - lr: 1.0000e-04\n",
            "Epoch 46/5000\n",
            "376/376 [==============================] - 587s 2s/step - loss: 2.3815 - accuracy: 0.4249 - val_loss: 2.3015 - val_accuracy: 0.4702 - lr: 1.0000e-04\n",
            "Epoch 47/5000\n",
            "376/376 [==============================] - 589s 2s/step - loss: 2.3700 - accuracy: 0.4264 - val_loss: 2.2912 - val_accuracy: 0.4702 - lr: 1.0000e-04\n",
            "Epoch 48/5000\n",
            "376/376 [==============================] - 592s 2s/step - loss: 2.3643 - accuracy: 0.4289 - val_loss: 2.2794 - val_accuracy: 0.4800 - lr: 1.0000e-04\n",
            "Epoch 49/5000\n",
            "376/376 [==============================] - 592s 2s/step - loss: 2.3483 - accuracy: 0.4352 - val_loss: 2.2662 - val_accuracy: 0.4772 - lr: 1.0000e-04\n",
            "Epoch 50/5000\n",
            "376/376 [==============================] - 587s 2s/step - loss: 2.3238 - accuracy: 0.4377 - val_loss: 2.2614 - val_accuracy: 0.4772 - lr: 1.0000e-04\n",
            "Epoch 51/5000\n",
            "376/376 [==============================] - 597s 2s/step - loss: 2.3232 - accuracy: 0.4379 - val_loss: 2.2507 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
            "Epoch 52/5000\n",
            "376/376 [==============================] - 591s 2s/step - loss: 2.2949 - accuracy: 0.4452 - val_loss: 2.2411 - val_accuracy: 0.4814 - lr: 1.0000e-04\n",
            "Epoch 53/5000\n",
            "376/376 [==============================] - 591s 2s/step - loss: 2.3079 - accuracy: 0.4385 - val_loss: 2.2300 - val_accuracy: 0.4905 - lr: 1.0000e-04\n",
            "Epoch 54/5000\n",
            "376/376 [==============================] - 595s 2s/step - loss: 2.2784 - accuracy: 0.4485 - val_loss: 2.2185 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
            "Epoch 55/5000\n",
            "376/376 [==============================] - 598s 2s/step - loss: 2.2847 - accuracy: 0.4472 - val_loss: 2.2101 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
            "Epoch 56/5000\n",
            "376/376 [==============================] - 604s 2s/step - loss: 2.2626 - accuracy: 0.4623 - val_loss: 2.2019 - val_accuracy: 0.4933 - lr: 1.0000e-04\n",
            "Epoch 57/5000\n",
            "376/376 [==============================] - 600s 2s/step - loss: 2.2606 - accuracy: 0.4563 - val_loss: 2.1955 - val_accuracy: 0.4926 - lr: 1.0000e-04\n",
            "Epoch 58/5000\n",
            "376/376 [==============================] - 595s 2s/step - loss: 2.2482 - accuracy: 0.4558 - val_loss: 2.1817 - val_accuracy: 0.5004 - lr: 1.0000e-04\n",
            "Epoch 59/5000\n",
            "376/376 [==============================] - 601s 2s/step - loss: 2.2301 - accuracy: 0.4648 - val_loss: 2.1764 - val_accuracy: 0.4954 - lr: 1.0000e-04\n",
            "Epoch 60/5000\n",
            "376/376 [==============================] - 606s 2s/step - loss: 2.2455 - accuracy: 0.4562 - val_loss: 2.1689 - val_accuracy: 0.4961 - lr: 1.0000e-04\n",
            "Epoch 61/5000\n",
            "376/376 [==============================] - 618s 2s/step - loss: 2.2056 - accuracy: 0.4620 - val_loss: 2.1621 - val_accuracy: 0.5039 - lr: 1.0000e-04\n",
            "Epoch 62/5000\n",
            "376/376 [==============================] - 631s 2s/step - loss: 2.2147 - accuracy: 0.4675 - val_loss: 2.1547 - val_accuracy: 0.5018 - lr: 1.0000e-04\n",
            "Epoch 63/5000\n",
            "376/376 [==============================] - 631s 2s/step - loss: 2.1954 - accuracy: 0.4603 - val_loss: 2.1517 - val_accuracy: 0.4954 - lr: 1.0000e-04\n",
            "Epoch 64/5000\n",
            "376/376 [==============================] - 676s 2s/step - loss: 2.2013 - accuracy: 0.4613 - val_loss: 2.1407 - val_accuracy: 0.5011 - lr: 1.0000e-04\n",
            "Epoch 65/5000\n",
            "376/376 [==============================] - 611s 2s/step - loss: 2.1849 - accuracy: 0.4710 - val_loss: 2.1273 - val_accuracy: 0.5088 - lr: 1.0000e-04\n",
            "Epoch 66/5000\n",
            "376/376 [==============================] - 667s 2s/step - loss: 2.1936 - accuracy: 0.4636 - val_loss: 2.1322 - val_accuracy: 0.5018 - lr: 1.0000e-04\n",
            "Epoch 67/5000\n",
            "376/376 [==============================] - 607s 2s/step - loss: 2.1643 - accuracy: 0.4690 - val_loss: 2.1199 - val_accuracy: 0.5081 - lr: 1.0000e-04\n",
            "Epoch 68/5000\n",
            "376/376 [==============================] - 609s 2s/step - loss: 2.1587 - accuracy: 0.4771 - val_loss: 2.1123 - val_accuracy: 0.5123 - lr: 1.0000e-04\n",
            "Epoch 69/5000\n",
            "376/376 [==============================] - 604s 2s/step - loss: 2.1426 - accuracy: 0.4801 - val_loss: 2.1029 - val_accuracy: 0.5074 - lr: 1.0000e-04\n",
            "Epoch 70/5000\n",
            "376/376 [==============================] - 604s 2s/step - loss: 2.1492 - accuracy: 0.4803 - val_loss: 2.1020 - val_accuracy: 0.5116 - lr: 1.0000e-04\n",
            "Epoch 71/5000\n",
            "376/376 [==============================] - 602s 2s/step - loss: 2.1527 - accuracy: 0.4740 - val_loss: 2.0946 - val_accuracy: 0.5109 - lr: 1.0000e-04\n",
            "Epoch 72/5000\n",
            "376/376 [==============================] - 599s 2s/step - loss: 2.1204 - accuracy: 0.4801 - val_loss: 2.0863 - val_accuracy: 0.5137 - lr: 1.0000e-04\n",
            "Epoch 73/5000\n",
            "376/376 [==============================] - 600s 2s/step - loss: 2.1172 - accuracy: 0.4864 - val_loss: 2.0776 - val_accuracy: 0.5193 - lr: 1.0000e-04\n",
            "Epoch 74/5000\n",
            "376/376 [==============================] - 593s 2s/step - loss: 2.1206 - accuracy: 0.4866 - val_loss: 2.0725 - val_accuracy: 0.5249 - lr: 1.0000e-04\n",
            "Epoch 75/5000\n",
            "376/376 [==============================] - 600s 2s/step - loss: 2.1299 - accuracy: 0.4793 - val_loss: 2.0654 - val_accuracy: 0.5207 - lr: 1.0000e-04\n",
            "Epoch 76/5000\n",
            "376/376 [==============================] - 601s 2s/step - loss: 2.0927 - accuracy: 0.4853 - val_loss: 2.0645 - val_accuracy: 0.5186 - lr: 1.0000e-04\n",
            "Epoch 77/5000\n",
            "376/376 [==============================] - 601s 2s/step - loss: 2.0880 - accuracy: 0.4931 - val_loss: 2.0486 - val_accuracy: 0.5249 - lr: 1.0000e-04\n",
            "Epoch 78/5000\n",
            "376/376 [==============================] - 597s 2s/step - loss: 2.0861 - accuracy: 0.4969 - val_loss: 2.0488 - val_accuracy: 0.5235 - lr: 1.0000e-04\n",
            "Epoch 79/5000\n",
            "376/376 [==============================] - 598s 2s/step - loss: 2.0696 - accuracy: 0.4969 - val_loss: 2.0398 - val_accuracy: 0.5256 - lr: 1.0000e-04\n",
            "Epoch 80/5000\n",
            "376/376 [==============================] - 599s 2s/step - loss: 2.0716 - accuracy: 0.4963 - val_loss: 2.0275 - val_accuracy: 0.5291 - lr: 1.0000e-04\n",
            "Epoch 81/5000\n",
            "376/376 [==============================] - 601s 2s/step - loss: 2.0793 - accuracy: 0.4828 - val_loss: 2.0241 - val_accuracy: 0.5333 - lr: 1.0000e-04\n",
            "Epoch 82/5000\n",
            "376/376 [==============================] - 598s 2s/step - loss: 2.0870 - accuracy: 0.4911 - val_loss: 2.0219 - val_accuracy: 0.5368 - lr: 1.0000e-04\n",
            "Epoch 83/5000\n",
            "376/376 [==============================] - 602s 2s/step - loss: 2.0537 - accuracy: 0.4999 - val_loss: 2.0166 - val_accuracy: 0.5354 - lr: 1.0000e-04\n",
            "Epoch 84/5000\n",
            "376/376 [==============================] - 603s 2s/step - loss: 2.0456 - accuracy: 0.5001 - val_loss: 2.0127 - val_accuracy: 0.5305 - lr: 1.0000e-04\n",
            "Epoch 85/5000\n",
            " 25/376 [>.............................] - ETA: 7:54 - loss: 1.9866 - accuracy: 0.5075"
          ]
        }
      ],
      "source": [
        "train_model()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}