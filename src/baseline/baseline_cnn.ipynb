{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# basic imports\n",
    "import tensorflow as tf \n",
    "import torch\n",
    "import io\n",
    "import numpy as np\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.utils import dataset_utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import baseline_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12132 files belonging to 5 classes.\n",
      "Found 505 files belonging to 5 classes.\n",
      "Found 450 files belonging to 5 classes.\n",
      "class names:  ['brant', 'jabwar', 'sheowl', 'spodov', 'wiltur']\n"
     ]
    }
   ],
   "source": [
    "def paths_and_labels_to_dataset(image_paths,labels,num_classes):\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "    img_ds = path_ds.map(\n",
    "        lambda path: tf.io.read_file(path), \n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    label_ds = dataset_utils.labels_to_dataset(\n",
    "        labels, \n",
    "        'categorical', \n",
    "        num_classes)\n",
    "    img_ds = tf.data.Dataset.zip((img_ds, label_ds))\n",
    "    return img_ds\n",
    "\n",
    "def create_dataset(subset):\n",
    "    image_paths, labels, class_names = dataset_utils.index_directory(\n",
    "            baseline_config.dataset_path + subset,\n",
    "            labels=\"inferred\",\n",
    "            formats=('.pt'),\n",
    "            class_names=None,\n",
    "            shuffle=False,\n",
    "            seed=42,\n",
    "            follow_links=False)\n",
    "\n",
    "    dataset = paths_and_labels_to_dataset(\n",
    "        image_paths=image_paths,\n",
    "        labels=labels,\n",
    "        num_classes=len(class_names))\n",
    "    \n",
    "    return dataset, class_names\n",
    "\n",
    "train_dataset, class_names = create_dataset('TRAIN/')\n",
    "test_dataset, _            = create_dataset('TEST/')\n",
    "validation_dataset, _      = create_dataset('VALIDATION/')\n",
    "print(\"class names: \", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_transforms(image,label):\n",
    "    image = tf.io.parse_tensor(image, tf.float32)\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    image = tf.repeat(image, 3, 2)\n",
    "    return image,label\n",
    "\n",
    "train_dataset_b = ( \n",
    "                  train_dataset\n",
    "                  .shuffle(20000)\n",
    "                  .map(dataset_transforms)\n",
    "                  .batch(baseline_config.batch_size)\n",
    "                  .cache()\n",
    "                  .repeat()            \n",
    "                )\n",
    "\n",
    "validation_dataset_b = ( \n",
    "                  validation_dataset\n",
    "                  .map(dataset_transforms)\n",
    "                  .batch(baseline_config.batch_size)\n",
    "                  .cache()\n",
    "                )\n",
    "\n",
    "test_dataset_b = ( \n",
    "                  test_dataset\n",
    "                  .map(dataset_transforms)\n",
    "                  .batch(baseline_config.batch_size)\n",
    "                  .cache()\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 313, 128, 3) (8, 5)\n"
     ]
    }
   ],
   "source": [
    "for item,lbl in train_dataset_b.take(1):\n",
    "    print(item.shape, lbl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resizing_1 (Resizing)       (None, 299, 299, 3)       0         \n",
      "                                                                 \n",
      " keras_layer (KerasLayer)    (None, 2048)              21802784  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                65568     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,868,517\n",
      "Trainable params: 65,733\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build a really simple classification model using a pre-training Efficientnet V2\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        # use the model as a feature generator only\n",
    "        # need to resize here, as the efficientnet_v2_imagenet21k_s model expects it\n",
    "        tf.keras.layers.InputLayer(input_shape=(313,128,3)),\n",
    "        tf.keras.layers.Resizing(299, 299, interpolation=\"lanczos5\", crop_to_aspect_ratio=False),\n",
    "        \n",
    "        # downloaded from: https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_m/feature_vector/2\n",
    "        # downloaded from: https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5\n",
    "        hub.KerasLayer(\"https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5\", trainable=False),        \n",
    "\n",
    "        # add the classification layer here       \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dropout(0.60),\n",
    "        layers.Dense(len(class_names), activation=None),\n",
    "    ]\n",
    ")\n",
    "# need to tell the model what the input shape is\n",
    "model.build([None, 299, 299, 3])\n",
    "\n",
    "# show the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.5997 - accuracy: 0.2730\n",
      "Epoch 1: val_loss improved from inf to 1.58988, saving model to checkpoints/\n",
      "250/250 [==============================] - 203s 766ms/step - loss: 1.5997 - accuracy: 0.2730 - val_loss: 1.5899 - val_accuracy: 0.2600\n",
      "Epoch 2/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.5540 - accuracy: 0.2600\n",
      "Epoch 2: val_loss improved from 1.58988 to 1.54265, saving model to checkpoints/\n",
      "250/250 [==============================] - 238s 949ms/step - loss: 1.5540 - accuracy: 0.2600 - val_loss: 1.5426 - val_accuracy: 0.2889\n",
      "Epoch 3/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.5287 - accuracy: 0.2630\n",
      "Epoch 3: val_loss did not improve from 1.54265\n",
      "250/250 [==============================] - 195s 779ms/step - loss: 1.5287 - accuracy: 0.2630 - val_loss: 1.5536 - val_accuracy: 0.2889\n",
      "Epoch 4/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.5275 - accuracy: 0.2735\n",
      "Epoch 4: val_loss did not improve from 1.54265\n",
      "250/250 [==============================] - 156s 623ms/step - loss: 1.5275 - accuracy: 0.2735 - val_loss: 1.5840 - val_accuracy: 0.2867\n",
      "Epoch 5/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.5099 - accuracy: 0.2680\n",
      "Epoch 5: val_loss did not improve from 1.54265\n",
      "250/250 [==============================] - 156s 624ms/step - loss: 1.5099 - accuracy: 0.2680 - val_loss: 1.5754 - val_accuracy: 0.3556\n",
      "Epoch 6/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.5081 - accuracy: 0.2805\n",
      "Epoch 6: val_loss did not improve from 1.54265\n",
      "250/250 [==============================] - 164s 655ms/step - loss: 1.5081 - accuracy: 0.2805 - val_loss: 1.6236 - val_accuracy: 0.3333\n",
      "Epoch 7/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.4898 - accuracy: 0.2866\n",
      "Epoch 7: val_loss did not improve from 1.54265\n",
      "250/250 [==============================] - 180s 722ms/step - loss: 1.4898 - accuracy: 0.2866 - val_loss: 1.5551 - val_accuracy: 0.3267\n",
      "Epoch 8/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.4876 - accuracy: 0.2980\n",
      "Epoch 8: val_loss did not improve from 1.54265\n",
      "250/250 [==============================] - 153s 613ms/step - loss: 1.4876 - accuracy: 0.2980 - val_loss: 1.6046 - val_accuracy: 0.3644\n",
      "Epoch 9/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.4806 - accuracy: 0.3095\n",
      "Epoch 9: val_loss did not improve from 1.54265\n",
      "250/250 [==============================] - 155s 621ms/step - loss: 1.4806 - accuracy: 0.3095 - val_loss: 1.5498 - val_accuracy: 0.3578\n",
      "Epoch 10/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.4697 - accuracy: 0.3010\n",
      "Epoch 10: val_loss did not improve from 1.54265\n",
      "250/250 [==============================] - 149s 596ms/step - loss: 1.4697 - accuracy: 0.3010 - val_loss: 1.6679 - val_accuracy: 0.3889\n",
      "Epoch 11/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.4717 - accuracy: 0.3220\n",
      "Epoch 11: val_loss did not improve from 1.54265\n",
      "250/250 [==============================] - 151s 604ms/step - loss: 1.4717 - accuracy: 0.3220 - val_loss: 1.5792 - val_accuracy: 0.3889\n",
      "Epoch 12/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.4455 - accuracy: 0.3310\n",
      "Epoch 12: val_loss did not improve from 1.54265\n",
      "250/250 [==============================] - 208s 831ms/step - loss: 1.4455 - accuracy: 0.3310 - val_loss: 1.5814 - val_accuracy: 0.3711\n",
      "Epoch 13/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.4689 - accuracy: 0.3302\n",
      "Epoch 13: val_loss did not improve from 1.54265\n",
      "250/250 [==============================] - 229s 917ms/step - loss: 1.4689 - accuracy: 0.3302 - val_loss: 1.5904 - val_accuracy: 0.3844\n",
      "Epoch 14/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.4480 - accuracy: 0.3325\n",
      "Epoch 14: val_loss did not improve from 1.54265\n",
      "250/250 [==============================] - 246s 986ms/step - loss: 1.4480 - accuracy: 0.3325 - val_loss: 1.5530 - val_accuracy: 0.4244\n",
      "Epoch 15/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.4347 - accuracy: 0.3425\n",
      "Epoch 15: val_loss improved from 1.54265 to 1.52503, saving model to checkpoints/\n",
      "250/250 [==============================] - 256s 1s/step - loss: 1.4347 - accuracy: 0.3425 - val_loss: 1.5250 - val_accuracy: 0.4289\n",
      "Epoch 16/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.4381 - accuracy: 0.3220\n",
      "Epoch 16: val_loss did not improve from 1.52503\n",
      "250/250 [==============================] - 270s 1s/step - loss: 1.4381 - accuracy: 0.3220 - val_loss: 1.5886 - val_accuracy: 0.4444\n",
      "Epoch 17/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.4228 - accuracy: 0.3500\n",
      "Epoch 17: val_loss did not improve from 1.52503\n",
      "250/250 [==============================] - 253s 1s/step - loss: 1.4228 - accuracy: 0.3500 - val_loss: 1.5733 - val_accuracy: 0.3778\n",
      "Epoch 18/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.4124 - accuracy: 0.3655\n",
      "Epoch 18: val_loss did not improve from 1.52503\n",
      "250/250 [==============================] - 286s 1s/step - loss: 1.4124 - accuracy: 0.3655 - val_loss: 1.5976 - val_accuracy: 0.4289\n",
      "Epoch 19/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.4136 - accuracy: 0.3647\n",
      "Epoch 19: val_loss did not improve from 1.52503\n",
      "250/250 [==============================] - 252s 1s/step - loss: 1.4136 - accuracy: 0.3647 - val_loss: 1.5579 - val_accuracy: 0.3733\n",
      "Epoch 20/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.4194 - accuracy: 0.3415\n",
      "Epoch 20: val_loss did not improve from 1.52503\n",
      "250/250 [==============================] - 277s 1s/step - loss: 1.4194 - accuracy: 0.3415 - val_loss: 1.5272 - val_accuracy: 0.3933\n",
      "Epoch 21/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3887 - accuracy: 0.3810\n",
      "Epoch 21: val_loss improved from 1.52503 to 1.51814, saving model to checkpoints/\n",
      "250/250 [==============================] - 276s 1s/step - loss: 1.3887 - accuracy: 0.3810 - val_loss: 1.5181 - val_accuracy: 0.3622\n",
      "Epoch 22/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.4028 - accuracy: 0.3595\n",
      "Epoch 22: val_loss improved from 1.51814 to 1.51574, saving model to checkpoints/\n",
      "250/250 [==============================] - 309s 1s/step - loss: 1.4028 - accuracy: 0.3595 - val_loss: 1.5157 - val_accuracy: 0.4267\n",
      "Epoch 23/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3754 - accuracy: 0.3905\n",
      "Epoch 23: val_loss did not improve from 1.51574\n",
      "250/250 [==============================] - 271s 1s/step - loss: 1.3754 - accuracy: 0.3905 - val_loss: 1.5180 - val_accuracy: 0.4111\n",
      "Epoch 24/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3722 - accuracy: 0.3960\n",
      "Epoch 24: val_loss improved from 1.51574 to 1.46582, saving model to checkpoints/\n",
      "250/250 [==============================] - 304s 1s/step - loss: 1.3722 - accuracy: 0.3960 - val_loss: 1.4658 - val_accuracy: 0.4600\n",
      "Epoch 25/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3735 - accuracy: 0.3903\n",
      "Epoch 25: val_loss improved from 1.46582 to 1.46251, saving model to checkpoints/\n",
      "250/250 [==============================] - 277s 1s/step - loss: 1.3735 - accuracy: 0.3903 - val_loss: 1.4625 - val_accuracy: 0.4644\n",
      "Epoch 26/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3637 - accuracy: 0.3815\n",
      "Epoch 26: val_loss improved from 1.46251 to 1.46020, saving model to checkpoints/\n",
      "250/250 [==============================] - 295s 1s/step - loss: 1.3637 - accuracy: 0.3815 - val_loss: 1.4602 - val_accuracy: 0.4778\n",
      "Epoch 27/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3491 - accuracy: 0.4000\n",
      "Epoch 27: val_loss did not improve from 1.46020\n",
      "250/250 [==============================] - 277s 1s/step - loss: 1.3491 - accuracy: 0.4000 - val_loss: 1.5122 - val_accuracy: 0.4244\n",
      "Epoch 28/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3661 - accuracy: 0.3850\n",
      "Epoch 28: val_loss did not improve from 1.46020\n",
      "250/250 [==============================] - 285s 1s/step - loss: 1.3661 - accuracy: 0.3850 - val_loss: 1.5373 - val_accuracy: 0.3533\n",
      "Epoch 29/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3591 - accuracy: 0.3915\n",
      "Epoch 29: val_loss did not improve from 1.46020\n",
      "250/250 [==============================] - 316s 1s/step - loss: 1.3591 - accuracy: 0.3915 - val_loss: 1.5155 - val_accuracy: 0.4511\n",
      "Epoch 30/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3170 - accuracy: 0.4330\n",
      "Epoch 30: val_loss did not improve from 1.46020\n",
      "250/250 [==============================] - 294s 1s/step - loss: 1.3170 - accuracy: 0.4330 - val_loss: 1.5036 - val_accuracy: 0.3844\n",
      "Epoch 31/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3541 - accuracy: 0.3963\n",
      "Epoch 31: val_loss did not improve from 1.46020\n",
      "250/250 [==============================] - 258s 1s/step - loss: 1.3541 - accuracy: 0.3963 - val_loss: 1.4716 - val_accuracy: 0.4356\n",
      "Epoch 32/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3478 - accuracy: 0.3975\n",
      "Epoch 32: val_loss did not improve from 1.46020\n",
      "250/250 [==============================] - 289s 1s/step - loss: 1.3478 - accuracy: 0.3975 - val_loss: 1.5426 - val_accuracy: 0.4200\n",
      "Epoch 33/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3303 - accuracy: 0.4150\n",
      "Epoch 33: val_loss improved from 1.46020 to 1.44064, saving model to checkpoints/\n",
      "250/250 [==============================] - 259s 1s/step - loss: 1.3303 - accuracy: 0.4150 - val_loss: 1.4406 - val_accuracy: 0.4622\n",
      "Epoch 34/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3411 - accuracy: 0.3940\n",
      "Epoch 34: val_loss did not improve from 1.44064\n",
      "250/250 [==============================] - 313s 1s/step - loss: 1.3411 - accuracy: 0.3940 - val_loss: 1.4605 - val_accuracy: 0.4022\n",
      "Epoch 35/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3206 - accuracy: 0.4245\n",
      "Epoch 35: val_loss did not improve from 1.44064\n",
      "250/250 [==============================] - 249s 996ms/step - loss: 1.3206 - accuracy: 0.4245 - val_loss: 1.4899 - val_accuracy: 0.4844\n",
      "Epoch 36/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3109 - accuracy: 0.4215\n",
      "Epoch 36: val_loss did not improve from 1.44064\n",
      "250/250 [==============================] - 282s 1s/step - loss: 1.3109 - accuracy: 0.4215 - val_loss: 1.4625 - val_accuracy: 0.4667\n",
      "Epoch 37/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3237 - accuracy: 0.4213\n",
      "Epoch 37: val_loss did not improve from 1.44064\n",
      "250/250 [==============================] - 276s 1s/step - loss: 1.3237 - accuracy: 0.4213 - val_loss: 1.4909 - val_accuracy: 0.4022\n",
      "Epoch 38/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3110 - accuracy: 0.4085\n",
      "Epoch 38: val_loss did not improve from 1.44064\n",
      "250/250 [==============================] - 247s 991ms/step - loss: 1.3110 - accuracy: 0.4085 - val_loss: 1.5961 - val_accuracy: 0.4378\n",
      "Epoch 39/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3025 - accuracy: 0.4190\n",
      "Epoch 39: val_loss improved from 1.44064 to 1.39022, saving model to checkpoints/\n",
      "250/250 [==============================] - 292s 1s/step - loss: 1.3025 - accuracy: 0.4190 - val_loss: 1.3902 - val_accuracy: 0.5000\n",
      "Epoch 40/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3233 - accuracy: 0.4155\n",
      "Epoch 40: val_loss did not improve from 1.39022\n",
      "250/250 [==============================] - 293s 1s/step - loss: 1.3233 - accuracy: 0.4155 - val_loss: 1.5743 - val_accuracy: 0.3533\n",
      "Epoch 41/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3221 - accuracy: 0.4150\n",
      "Epoch 41: val_loss did not improve from 1.39022\n",
      "250/250 [==============================] - 263s 1s/step - loss: 1.3221 - accuracy: 0.4150 - val_loss: 1.5563 - val_accuracy: 0.4556\n",
      "Epoch 42/100000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3003 - accuracy: 0.4290\n",
      "Epoch 42: val_loss did not improve from 1.39022\n",
      "250/250 [==============================] - 250s 1000ms/step - loss: 1.3003 - accuracy: 0.4290 - val_loss: 1.5345 - val_accuracy: 0.3867\n",
      "Epoch 43/100000\n",
      "193/250 [======================>.......] - ETA: 58s - loss: 1.2877 - accuracy: 0.4422"
     ]
    }
   ],
   "source": [
    "# the form_logits means the loss function has the 'softmax' buillt in.  This approach is numerically more stable\n",
    "# than including the softmax activation on the last layer of the classifier\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=baseline_config.learning_rate), \n",
    "              metrics=[\"accuracy\"],\n",
    "              )\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='checkpoints/',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    save_best_only=True)\n",
    "\n",
    "model.fit(train_dataset_b, \n",
    "          validation_data=validation_dataset_b,\n",
    "          steps_per_epoch=250,\n",
    "          callbacks=[model_checkpoint_callback],\n",
    "          epochs=baseline_config.max_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4acbc442a267d9c039005cb6a4c551bfe6da3ea17529ec6bc5615c49cd80131"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
